{"meta":{"title":"壹叶知秋的博客","subtitle":"不要为恐惧所驾驭...","description":null,"author":"壹叶知秋","url":"http://wzhongke.github.io"},"pages":[{"title":"博客搭建流程","date":"2017-08-28T03:02:22.808Z","updated":"2017-08-28T03:02:22.476Z","comments":true,"path":"ReadMe.html","permalink":"http://wzhongke.github.io/ReadMe.html","excerpt":"","text":"hexo init [dir] 初始化hexo博客 npm install 安装nodejs依赖 从主题中选择主题，checkout到themes目录下 hexo g 会在 public 目录下生成相关静态文件 hexo d 会将博客部署到github上"},{"title":"父子组价通信","date":"2017-09-14T02:02:15.914Z","updated":"2017-09-14T02:02:15.914Z","comments":true,"path":"vue.html","permalink":"http://wzhongke.github.io/vue.html","excerpt":"","text":"123&lt;template&gt; &lt;/template&gt;"},{"title":"","date":"2017-09-14T02:02:15.912Z","updated":"2017-09-14T02:02:15.912Z","comments":true,"path":"vue.html","permalink":"http://wzhongke.github.io/vue.html","excerpt":"","text":"click export default { name: 'componentA', data: function() { return { msg: \"component a!\" } }, events: { 'addNew' : function (msg) { console.log(msg); } }, props: ['msgfromfather'], methods : { onClickMe: function() { this.$emit('children-tell', this.msg) } } } children tell: const STORAGE_KEY='todo-vue' export default { fetch: function() { return JSON.parse(window.location.getItem(STORAGE_KEY) || '[]') }, save: function (items) { window.location.setItem(STORAGE_KEY, JSON.stringify(items)) } } export default { data () { return { title: 'this is a todo list', items: store.fetch(), newItem: '', childWords: '' } }, watch: { items: { handler: function (items) { Store.save(items) } }, deep: true }, events: { 'children-tell' : function (){ this.childWords = msg; } }, methods: { toogleFinish: function(item) { item.isFinished = !item.isFinished; }, addNew: function() { this.items.push({ label: this.newItem, isFinished: false }) this.newItem = '' this.$broadcas('addNew', this.items); }, listenToChildren: function(msg) { this.childWords = msg; } } }"},{"title":"","date":"2017-08-21T11:19:28.943Z","updated":"2017-08-21T11:19:28.877Z","comments":false,"path":"categories/index.html","permalink":"http://wzhongke.github.io/categories/index.html","excerpt":"","text":""},{"title":"","date":"2017-08-21T11:19:36.054Z","updated":"2017-08-21T11:19:35.990Z","comments":false,"path":"tags/index.html","permalink":"http://wzhongke.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"jvm调优","slug":"java/jvm调优","date":"2017-10-23T04:08:55.321Z","updated":"2017-10-23T08:15:41.438Z","comments":true,"path":"2017/10/23/java/jvm调优/","link":"","permalink":"http://wzhongke.github.io/2017/10/23/java/jvm调优/","excerpt":"","text":"在常见的线上问题中，如下问题比较常见： 内存泄露 某个进程CPU突然飙升 线程死锁 响应变慢 如果遇到上述问题，我们可以基于监控工具来定位问题。java中常用的分析监控工具有： jps、jstat、jinfo、jmap、jhat、jstack jps: JVM进程状况jps用来查看进程的状况，语法如下： 1234567891011jps [options] [hostid]参数：-q: 不输出类名、jar名和传入main方法的参数-l: 输出main类或jar的全限名-m: 输出传入main方法的参数-v: 输出传入JVM的参数示例jps -l 7605 sun.tools.jps.Jps 13598 com.caucho.server.resin.Resin jstat: JVM 统计信息监控工具jstat 是用于查看虚拟机各种运行状态的命令行工具，它可以显示本地或远程虚拟机中的类装载、内存、垃圾收集、jit编译等运行数据。其具体用法如下： 123jstat [generalOption|outputOptions vmid [interval[s|ms] [count]]]generalOption: 单个常用的命令行选项，如 -help, -optionsoutputOptions: 一个或多个输出选项，由单个的statOption选项组成 option 用途 例子 class 用于查看类加载情况的统计 jstat -class pid : 显示加载class的数量，所占空间等信息 complier 查看HotSpot中即时编译情况统计 jstat -compiler pid: 显示VM实时编译数量等信息 gc 查看JVM中堆的垃圾收集情况的统计 jstat -gc pid gccapacity 查看新生代、老生代及持久代的存储容量情况 jstat -gccapacity: 可以显示VMware内存中三代对象的使用和占用大小 gccause 查看垃圾收集的统计情况，如果有发生垃圾收集，它还会显示最后一次及当前正在发生的垃圾收集原因 jstat -gccause: 显示gc原因 gcnew 查看新生代垃圾内含物的情况 jstat -gcnew pid: new 对象的信息 gcnewcapacity 用于查看新生代的存储容量情况 jstat -gcnewcapacity pid: new 对象的信息及其占用量 gcold 查看老生代及持久代GC情况 jstat -gcold pid: old 对象的信息 gcoldcapacity 用于查看老生代的容量 jstat -gcoldcapacity: old对象的信息及其占用量 gcpermacpacity 用于查看持久代的容量 jstat -gcpermcapacity pid: 持久代对象的信息 gcutil 查看新生代、老年代及持久代垃圾收集情况 jstat -util pid: 统计gc信息 示例1jstat -gc 17835 结果 S0C S1C S0U S1U EC EU OC OU MC MU CCSC CCSU YGC YGCT FGC FGCT GCT43520.0 43520.0 0.0 0.0 611840.0 371440.0 1398272.0 1077246.3 34816.0 33485.4 3584.0 3324.3 7 1.202 32 34.763 35.966 参数说明： jinfo: Java 配置信息jinfo 可以获取当前线程的jvm运行和启动信息，使用如下：1jinfo [option] pid jmap: Java 内存映射工具jmap 命令用于将堆转存成快照，","categories":[{"name":"java","slug":"java","permalink":"http://wzhongke.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://wzhongke.github.io/tags/java/"}]},{"title":"HTML 标签","slug":"front/HTML标签","date":"2017-10-12T04:02:41.702Z","updated":"2017-10-12T10:13:40.304Z","comments":true,"path":"2017/10/12/front/HTML标签/","link":"","permalink":"http://wzhongke.github.io/2017/10/12/front/HTML标签/","excerpt":"","text":"标签&lt;video&gt;标签是HTML5的新标签，其属性如下： 属性 值 描述 autoplay autoplay 视频就绪后马上播放 controls controls 向用户展示控件，比如播放按钮等 height pixels 视频播放器的高度 width pixels 视频播放器的宽度 loop loop 当媒介文件完成播放后再次开始播放 muted muted 规定视频的音频输出应该被静音 poster url 规定视频下载时显示的图像，或者用户在点击播放按钮前显示的图像 preload preload 视频在页面加载时进行加载，并预备播放 src url 要播放视频的url video 对象video 对象是HTML5 中的新对象，video对象表示HTML &lt;video&gt; 元素。 获取video元素: var video = document.getElementById(&quot;videoId&quot;); 创建video对象: var video = docuemnt.createElement(&quot;video&quot;); video 对象有如下属性： 属性 描述 audioTracks 返回表示可用音频轨道的 AudioTrackList 对象。 autoplay 设置或返回是否在就绪（加载完成）后随即播放视频。 buffered 返回表示视频已缓冲部分的 TimeRanges 对象。 controller 返回表示视频当前媒体控制器的 MediaController 对象。 controls 设置或返回视频是否应该显示控件（比如播放/暂停等）。 crossOrigin 设置或返回视频的 CORS 设置。 currentSrc 返回当前视频的 URL。 currentTime 设置或返回视频中的当前播放位置（以秒计）。 defaultMuted 设置或返回视频默认是否静音。 defaultPlaybackRate 设置或返回视频的默认播放速度。 duration 返回视频的长度（以秒计）。 ended 返回视频的播放是否已结束。 error 返回表示视频错误状态的 MediaError 对象。 height 设置或返回视频的 height 属性的值。 loop 设置或返回视频是否应在结束时再次播放。 mediaGroup 设置或返回视频所属媒介组合的名称。 muted 设置或返回是否关闭声音。 networkState 返回视频的当前网络状态。 paused 设置或返回视频是否暂停。 playbackRate 设置或返回视频播放的速度。 played 返回表示视频已播放部分的 TimeRanges 对象。 poster 设置或返回视频的 poster 属性的值。 preload 设置或返回视频的 preload 属性的值。 readyState 返回视频当前的就绪状态。 seekable 返回表示视频可寻址部分的 TimeRanges 对象。 seeking 返回用户当前是否正在视频中进行查找。 src 设置或返回视频的 src 属性的值。 startDate 返回表示当前时间偏移的 Date 对象。 textTracks 返回表示可用文本轨道的 TextTrackList 对象。 videoTracks 返回表示可用视频轨道的 VideoTrackList 对象。 volume 设置或返回视频的音量。 width 设置或返回视频的 width 属性的值。","categories":[],"tags":[]},{"title":"MySQL基础语句","slug":"mysql/MySQL基础语句","date":"2017-10-08T19:48:32.000Z","updated":"2017-10-12T04:04:00.433Z","comments":true,"path":"2017/10/09/mysql/MySQL基础语句/","link":"","permalink":"http://wzhongke.github.io/2017/10/09/mysql/MySQL基础语句/","excerpt":"MySQL数据库MySQL 是典型的关系型数据库，因为其免费开源，所以被广泛的应用数据库是按照数据结构来组织、存储和管理数据的仓库当然我们也可以将数据存储在文件中，但是文件中读写数据速度相对较慢所以，我们使用关系型数据库管理系统（RDBMS）来存储和管理数据关系型数据库，是建立在关系模型基础上的数据库，通过集合代数等数学概念和方法来处理数据库中的数据。","text":"MySQL数据库MySQL 是典型的关系型数据库，因为其免费开源，所以被广泛的应用数据库是按照数据结构来组织、存储和管理数据的仓库当然我们也可以将数据存储在文件中，但是文件中读写数据速度相对较慢所以，我们使用关系型数据库管理系统（RDBMS）来存储和管理数据关系型数据库，是建立在关系模型基础上的数据库，通过集合代数等数学概念和方法来处理数据库中的数据。RDBMS (Relational Database Management System)的特点： 数据以表格的形式出现 每行为各种记录名称 每列为记录名称所对应的数据域 许多行和列构成一张表 若干个表组成数据库 数据库术语 数据库： 数据库是关系型数据表的集合 数据表： 表示数据的矩阵 列： 一列包含了相同类型的数据 行： 一行是一组相关的数据 冗余： 存储两倍数据，冗余降低性能，但提高了数据的安全性 主键： 主键是唯一的，一个数据表中只能包含一个主键 外键： 外键用于将两个表关联起来 复合键： 复合键将多个列作为一个索引键，一般用于符合索引 索引： 使用索引可以快速访问数据表中的信息一般索引使用B+ Tree对数据表中的一列或多列进行排序 MySQL简单的命令 查看当前服务器版本： SELECT VERSION(); 显示当前日期： SELECT NOW(); 显示当前用户： SELECT USER(); 查看所有的数据库： SHOW DATABASES; 切换数据库： USE db_name; 查看警告信息： SHOW WARNINGS; 查看数据库表的创建信息： SHOW CREATE db_name; 查看当前打开的数据库： SHOW DATABASE(); 查看数据库中的表: SHOW TABLES [FROM db_name] [LIKE &#39;pattern&#39; | WHERE expr]; 查看数据库表的结构: SHOW COLUMNS FROM tb_name 查看数据表的创建语句： SHOW CREATE TABLE tb_name; 查看索引: SHOW INDEXES FROM tb_name; 删除表： DROP TABLE tb_name; 删除数据库： DROP DATABASE db_name; MySQL 数据类型数据类型是指列、存储过程参数、表达式和局部变量的数据特征，它决定了数据的存储格式，代表了不同的信息类型 整型可以根据下表选择需要的整型类型，既能保证能存储所需数值，又能节省空间 UNSIGNED 无符号值。 数据类型 存储范围 字节 tinyint 有符号值： -128到127 (-2^7 到 2^7-1) 无符号值： 0到255 (0到2^8-1) 1字节 samllint 有符号值： -32768到32767 (-2^15 到 2^15-1) 无符号值： 0到65535 (0到2^16-1) 2字节 mediumint 有符号值： -2^23 到 2^23-1 无符号值： 0到2^24-1 3 字节 (3*8) int 有符号值： -2^31 到 2^31 -1 无符号值： 0 到 2^32-1 4 字节 bigint 有符号值： -2^63 到 2^63 -1 无符号值： 0 到 2^64-1 8 字节 浮点型 数据类型 存储范围 float[(M,D)] -3.402823466E+38 到 -1.175494351E-38、0 和 1.175494351E-38 到 3.402823466E+38 M 是数字的总位数，D是小数点后边的位数如果没有M和D，那么根据硬件允许的限制来保存值单精度浮点数精确到大概7位小数 double[(M,D)] -1.7976931348623157E+308 到 -2.2250738585072014E-308、 0 和 2.2250738585072014E-308 到 1.7976931348623157E+308 日期类型 数据类型 存储需求 year 1 time 3 date 3 datetime 8 timestamp 4 字符型 数据类型 存储需求 char(M) M 个字节，定长类型， 0 &lt;= M &lt;= 255 varchar(M) L+1个字节(变长类型)，L&lt;=M &amp;&amp; 0 &lt;= M &lt;= 65536 tinytext L+1个字节，L &lt; 2^8 text L+2 个字节，L &lt; 2^16 mediumtext L+3 个字节，L &lt; 2^24 longtext L+4 个字节，L &lt; 2^32 enum(‘value1’, ‘value2’, …) 1或2个字节，取决于枚举值的个数 (最大65535个值) set(‘value1’,’value2’, …) 1,2,3,4或8个字节，取决于set成员的数目(最多64个成员) 创建表以下是MySQL创建数据表的通用语法：1234CREATE TABLE [IF NOT EXISTS] table_name ( column_name data_type, ...); 下例子中，我们创建了一张 tb_name 的表1234567CREATE TABLE IF NOT EXISTS `tb_name` ( `id` INT UNSIGNED AUTO_INCREMENT, `name` VARCHAR(20) NOT NULL, `birthday` DATE, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;-- 结果：受影响的行: 0，时间: 0.042s 解释： 如果不想将字段的值为NULL，可以设置字段的属性为 NOT NULL，这样在插入数据时，如果输入该字段为 NULL，那么数据库就会报错 AUTO_INCREMENT 定义列为自增属性，一般用于主键 PRIMARY KEY 用于定义列为主键，可以定义过个列为主键，用逗号分隔 ENGINE 用来设置存储引擎，CHARSET 设置编码 插入数据MySQL 通过 INSERT INTO 或者 REPLACE INTO 来插入数据，语法如下：123INSERT [INTO] ta_name [(field1, field2,...fieldN)] VALUES (val1, val2, ..., valN) [, (val1, val2, ..., valN)];-- 如果主键相同，则替换之REPLACE [INTO] ta_name [(field1, field2,...fieldN)] VALUES (val1, val2, ..., valN) [, (val1, val2, ..., valN)]; 如果数据是字符型，必须使用双引号或者单引号，如 “val”下例中，我们向数据表中插入一条数据：12INSERT INTO tb_name (`name`, `birthday`) VALUES (\"Jhon\", \"1991-11-23\");-- 结果: 受影响的行: 1，时间: 0.003s 如果 field 的名字同 MySQL 关键字的名字相同，需要使用 \\`` 来将field` 括起来 如果需要从另一张表中导入数据到一张表，可以用 INSERT INTO ... SELECT，其语法如下：123456789-- 将tb2中所有的列都拷贝到tb1中INSERT INTO tb1 SELECT * FROMT tb2WHERE condition;-- 将特定的列从tb1中拷贝到tb2中INSERT INTO tb1 (column1, column2,..., columnn) SELECT column1, column2,..., columnn FROM tb2 WHERE condition; 拷贝指定的列时，INSERT 后的列要一一对应。 简单查询数据MySQL 通过 SELECT 语句来查询数据，语法如下：1SELECT col_name, col_name,... FROM tb_name [WHERE clause] [OFFSET m] [LIMIT n]; SELECT 说明： 查询语句中可以使用一个或者多个表，表之间用逗号分隔， WHERE 用来设定查询语句 使用 * 来代替其他字段，SELECT 语句会返回表中所有的字段数据 使用 OFFSET 来指定 SELECT 语句开始查询的数据偏移量 使用 LIMIT 来设定返回的记录数 12345678SELECT * FROM tb_name;-- 结果： +----+------+------------+| id | name | birthday |+----+------+------------+| 1 | Jhon | 1991-11-23 |+----+------+------------+1 row in set (0.00 sec) CASE WHEN可以在 select 的列中使用 case when condition then val1 else val2 end 来进行查询操作 1234567INSERT INTO `db1`.`table1` (`keyword`, `match_type`, `type`, `create_time`, `modify_time`, `start_time`, `end_time`, `user`) SELECT sugg_word as keyword, (CASE WHEN fuzz=0 THEN 0 ELSE 1 end) AS match_type, (CASE WHEN sugg_case='' THEN 0 ELSE 1 END) AS type, create_time, modify_time, start_time, end_time, user from `db2`.`table2` where sugg_case=''; UPDATE 更新命令如果我们要更改MySQL中的数据，那么我们需要使用 UPDATE 命令，其语法如下：1UPDATE tb_name SET field1=newValue1, field2=newValue2, ... [WHERE clause]; UPDATE 语句说明： 可以同时更新多个字段； 可以在 WHERE 子句中指定任何条件 可以在一个单独表中同时更新数据 示例：1234UPDATE tb_name SET birthday='2000-10-01' WHERE name='Jhon';-- 结果如下Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0 DELETE 语句可以使用 DELETE 来删除 MySQL 表中的记录，语法如下：1DELETE FROM tb_name [WHERE clause]; DELETE 语句会删除所有命中 WHERE 条件的记录。DELETE 说明： 如果没有指定 WHERE 子句， MySQL 表中的所有记录都会被删除 可以在 WHERE 子句中指定任何条件 可以在表单中一次性删除记录 查询WHERE 子句WHERE 子句是有条件地从表中筛选数据，语法如下：12SELECT field1, field2,...fieldN FROM tb_name1, tb_name2...[WHERE condition1 [AND [OR]] condition2..... WHERE 子句说明： 查询语句中可以指定一个或多个表，表之间用逗号分隔 在 WHERE 子句中指定任何条件，使用 AND 或 OR 来分隔不同的条件 WHERE 可以用在 SQL 的 DELETE 或者 UPDATE 命令中 WHERE 子句中可以使用如下操作符，其中 A=10， B=20, s=’test’： 操作符 描述 实例 = 等号，检测两个值是否相等，如果相等返回true (A = B) 返回false &lt;&gt;, != 不等于，检测两个值是否相等，如果不相等返回true (A != B) 返回 true > 大于号，检测左边的值是否大于右边的值, 如果左边的值大于右边的值返回true (A &gt; B) 返回false &lt; 小于号，检测左边的值是否小于右边的值, 如果左边的值小于右边的值返回true (A &lt; B) 返回 true >= 大于等于号，检测左边的值是否大于或等于右边的值, 如果左边的值大于或等于右边的值返回true (A &gt;= B) 返回false &lt;= 小于等于号，检测左边的值是否小于于或等于右边的值, 如果左边的值小于或等于右边的值返回true (A &lt;= B) 返回 true IS [NOT] NULL 判断值是否为空 (s IS NOT NULL) 返回false LIKE 字符串模糊匹配 (s LIKE &#39;%es_&#39;) 返回 true REGEXP 正则匹配 (s REGEXP &#39;^t[aec]{1,3}$&#39;) 返回true LIKE 子句LIKE 子句如果没有 % 和 _， 其效果同 = 相同。在 LIKE 中，% 代表任意个数的任意字符； _ 代表任意一个字符。 示例：1234567SELECT * FROM tb_name WHERE NAME LIKE 'A%';-- 结果：+----+------+------------+| id | name | birthday |+----+------+------------+| 6 | Andy | 2009-09-01 |+----+------+------------+ WHERE 子句中的字符串不区分大小写，可以使用 BINARY 来设定字符串区分大小写： WHERE BINARY NAME LIKE &#39;A%&#39;; UNION 操作符UNION 操作符用于连接两个以上的 SELECT 语句，它将 SELECT 语句的结果组合到一个结果集中，多个 SELECT 语句会删除重复的数据。语法如下：12345SELECT exp1, exp2, ..., expn FROM tb_name [WHERE condition] UNION [ALL | DISTINCT]SELECT exp1, epx2, ..., expn FROM tb_name [WHERE condition]; 语句说明： DISTINCT: 可选，删除结果集中重复的数据，默认为 DISTINCT ALL: 可选，返回所有的结果集，包括重复数据 SELECT 所选的列的个数应该是相等的 123456789101112131415161718192021222324SELECT `name`, `birthday` FROM tb_name WHERE name LIKE 'D%'UNION ALLSELECT `name`, `birthday` FROM person WHERE name like 'D%';-- 结果+-------+------------+| name | birthday |+-------+------------+| Devon | 2009-09-01 || Dewey | 1990-12-01 || Devon | 1990-12-01 || Dewey | 1990-12-01 |+-------+------------+SELECT `name`, `birthday` FROM tb_name WHERE name LIKE 'D%'UNION SELECT `name`, `birthday` FROM person WHERE name like 'D%';-- 结果+-------+------------+| name | birthday |+-------+------------+| Devon | 2009-09-01 || Dewey | 1990-12-01 || Devon | 1990-12-01 |+-------+------------+ 排序可以通过 SELECT 将数据从数据库中取出，还可以通过 ORDER BY 子句对查询结果进行排序。语法如下：1SELECT field1, field2,..., fieldn FROM tb_name [WHERE condition] ORDER BY field1, [field2...] [ASC [DESC]]; ORDER BY 使用说明： 可以使用任何字段作为排序的条件 可以设定多个字段来排序，会按字段的先后顺序来对结果进行排序 ASC 是排列升序，DESC 是降序排列，默认情况下是升序 示例：12345678910111213141516SELECT `name`, `birthday` FROM tb_name WHERE NAME LIKE 'D%' ORDER BY birthday;-- 结果+-------+------------+| name | birthday |+-------+------------+| Dewey | 1990-12-01 || Devon | 2009-09-01 |+-------+------------+SELECT `name`, `birthday` FROM tb_name WHERE NAME LIKE 'D%' ORDER BY birthday DESC;+-------+------------+| name | birthday |+-------+------------+| Devon | 2009-09-01 || Dewey | 1990-12-01 |+-------+------------+ 分组查询我们可以使用 GROUP BY 语句根据一个或多个列队结果集进行分组。在列上我们可以使用 COUNT、SUN、AVG等聚合函数。语法如下：1234SELECT field1, function(field2), ... FROM tb_name [WHERE condition] GROUP BY field1 [WITH ROLLUP][ORDER BY field1]; 说明： WITH ROLLUP : 可以实现在分组统计的基础上在进行相同的统计(SUM, AVG, COUNT) COALESCE(a,b,c): 如果a==null,则选择b；如果b==null,则选择c；如果a!=null,则选择a；如果a b c 都为null ，则返回为null（没意义） 示例：12345678910111213141516171819202122SELECT COUNT(`name`), `birthday` FROM tb_name GROUP BY birthday ORDER BY birthday DESC;-- 结果+---------------+------------+| COUNT(`name`) | birthday |+---------------+------------+| 4 | 2009-09-01 || 1 | 2004-06-16 || 1 | 2000-10-01 || 1 | 1990-12-01 |+---------------+------------+SELECT COALESCE(birthday, '总数'), SUM(name) AS name_count FROM tb_name GROUP BY birthday WITH ROLLUP;-- 结果+------------------------------+------------+| COALESCE(birthday, '总数') | name_count |+------------------------------+------------+| 1990-12-01 | 1 || 2000-10-01 | 1 || 2004-06-16 | 1 || 2009-09-01 | 4 || 总数 | 7 |+------------------------------+------------+ MySQL NULL 值处理WHERE 子句在使用查询条件时，如果查询条件的字段为NULL，会有些特殊： IS NULL: 若当前列的值为 NULL，则返回true IS NOT NULL: 当前列的值不为NULL，返回true &lt;=&gt;: 比较操作符，当比较的两个值为 NULL 时返回true NULL 条件比较运算比较特殊，不能使用 =NULL 或 !=NULL 在列中查找 NULL 值。 在 MySQL中， NULL值与任何其他值的比较永远返回 false，NULL=NULL 也会返回false。 MySQL中处理 NULL 使用 IS NULL 和 IS NOT NULL MySQL 正则表达式MySQL 除了可以用 LIKE 来进行模糊匹配外，还可以用 REGEXP 来进行正则匹配。其正则匹配的模式同Perl正则匹配相似123456789-- 选出 以 D 或 J 开头的，并且以 n 结尾的姓名SELECT * FROM tb_name WHERE name regexp '^[DJ].*n$';-- 结果+----+-------+------------+| id | name | birthday |+----+-------+------------+| 1 | Jhon | 2000-10-01 || 2 | Devon | 2009-09-01 |+----+-------+------------+ 修改表结构当我们需要修改数据库的表明或者修改数据表字段时，可以通过MySQL的 ALTER 命令来修改。 删除表中的字段： ALTER TABLE tb_name DROP field; 使用 ADD 来向数据表中添加列： ALTER TABLE tb_name ADD sex INT; 修改字段类型及名称： ALTER TABLE tb_name MODIFY sex CHAR(2); 修改字段的默认值： ALTER TABLE tb_name MODIFY sex TIYINT NOT NULL DEFAULT 1; 修改表名： ALTER TABLE tb_name RENAME TO tb; 修改存储引擎： ALTER TABLE tb_name ENGINE=MYISAM; 删除外键约束：ALTER TABLE tb_name DROP FOREIGN KEY keyName; 索引表的索引就像书的目录，能够快速地找到找到数据，能够极大地提高以索引列为条件的查询的效率。索引分为单列索引和组合索引。单列索引只包含单个列，一个表可以有多个单列索引。组合索引是一个索引包含多个列。可以把索引看做一张有序表，保存了主键和索引字段，并指向实体表的记录。虽然索引能够极大地提高查询速度，但是却会降低更新表的速度，如对表进行 INSERT、UPDATE和DELETE。因为更新表时，也需要更新索引。索引分为 普通索引，唯一索引。 唯一索引列的值必须是唯一的，但允许有空置。如果是组合索引，则列的组合必须唯一。 创建索引: CREATE [UNIQUE] INDEX indexName NO tb_name(name(lenght))。如果是 CHAR，VARCHAR类型，length可以小于字段实际长度；如果是BLOB或TEXT类型，必须制定length 修改表结构(添加索引)： ALERT table tb_name ADD INDEX indexName(columnName) 创建表时直接指定： 123456CREATE TABLE tb_name ( id INT NOT NULL, username VARCHAR(16) NOT NULL, ... INDEX [indexName] (username(length))); 删除索引： DROP INDEX [indexName] ON tb_name; 显示索引信息： SHOW INDEX FROM tb_name; 临时表在我们需要保存一些临时数据时，可以使用临时表。临时表只在当前连接可见，关闭连接时，MySQL会自动删除表并释放空间。临时表的创建同表的创建类似，只是多了一个关键字：1CREATE TEMPORARY TABLE temporary_table(); 但是，使用 SHOW TABLES 命令时，无法看到临时表。 序列 在MySQL的客户端中，使用 LAST_INSERT_ID() 函数来获取最后插入表中的自增列的值 可以使用 auto_increment=100 来为序列指定一个开始值 重复数据的处理MySQL中允许存在重复的记录，但有些时候我们需要删除一些重复的数据。可以在MySQL表中，通过将相应的字段设置为 PRIMARY KEY 或者 UNIQUE 索引来保证数据的唯一性：1234567CREATE TABLE test1 ( first_name VARCHAR(20) NOT NULL, last_name VARCHAR(20) NOT NULL, PRIMARY KEY(last_name, first_name) -- 或者使用 UNIQUE UNIQUE (last_name, first_name)); 如果我们设置了唯一索引，那么在插入重复数据时，SQL语句会执行报错。可以使用 REPLACE INTO 或者 INSERT IGNORE INTO，这两种方式会忽略重复的数据。如果数据库没有数据，就插入新的数据，如果有数据的话就跳过这条数据。这样就可以保留数据库中已经存在数据，达到在间隙中插入数据的目的。 我们还可以统计表中重复的记录：123SELECT COUNT(*) AS cnt, last_name, first_name FROM test1GROUP BY last_name, first_nameHAVING cnt &gt; 1; 导出数据我们可以使用 SELECT ... INTO OUTFILE 来简单地导出数据到文本文件中：1SELECT * FROM test1 INTO OUTFILE '/tmp/test1.txt'; 还可以像下例中，指定文件格式：123SELECT * FROM test1 INTO OUTFILE '/tmp/test1.txt' FIELDS TERMINATED BY ',' ENCLOSED BY '\"' LINES TERMINATED BY '\\r\\n'","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://wzhongke.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://wzhongke.github.io/tags/MySQL/"}]},{"title":"MySQL技巧","slug":"mysql/MySQL技巧","date":"2017-10-08T18:51:00.000Z","updated":"2017-10-24T09:19:58.067Z","comments":true,"path":"2017/10/09/mysql/MySQL技巧/","link":"","permalink":"http://wzhongke.github.io/2017/10/09/mysql/MySQL技巧/","excerpt":"查询时间是今天的数据 12select * from table_name where to_days(create_time) = to_days(now());select * from table_name where date(create_time) = curdate();","text":"查询时间是今天的数据 12select * from table_name where to_days(create_time) = to_days(now());select * from table_name where date(create_time) = curdate(); 查询一周之内的数据 1select * from table_name where DATE_SUB(CURDATE(), INTERVAL 7 DAY) &lt;= date(create_time); 其中DATE_SUB(date,INTERVAL expr unit)是从日期中减去指定的时间间隔，date是合法的日期表达式，expr是时间间隔，unit可以是如下值 Type值| 说明 :—–|:——– MICROSECOND | 毫秒 SECOND | 秒 MINUTE | 分 HOUR | 时 DAY | 天 WEEK | 周 MONTH | 月 QUARTER | 刻 YEAR | 年 删除MySQL中的重复数据 1delete from table where id not in (select * from (select max(id) from table group by duplicate having count(duplicate) &gt; 1) as b) and id in (select * from (select id from table group by duplicate having count(duplicate) &gt; 1) as c);","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://wzhongke.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://wzhongke.github.io/tags/MySQL/"}]},{"title":"java 泛型","slug":"java/java 泛型","date":"2017-09-17T19:42:25.000Z","updated":"2017-09-27T08:31:15.923Z","comments":true,"path":"2017/09/18/java/java 泛型/","link":"","permalink":"http://wzhongke.github.io/2017/09/18/java/java 泛型/","excerpt":"","text":"在java中使用泛型，可以避免使用Object或者强制类型转换。泛型最适用于集合类，比如List。使用泛型编写代码增加了其可复用性，可以被许多不同类型的对象使用。举例来说，不想对String和File的集合分别编程，可以使用ArrayList来处理各种类型的集合。 使用泛型编程有三种技术层次： 只知道如何使用泛型，而不知道它们为什么可以这么使用； 当在使用泛型的过程中，遇到一些不能解决的问题，就需要了解泛型的具体使用法则； 可以自己实现泛型和其方法。 只有那些涉及到很多类型的通用代码，才适合用泛型来处理。 定义泛型类泛型类是含有一个或多个类型变量（如下例中T）的类。1234567891011121314public class Pair&lt;T&gt; &#123; private T first; private T second; public Pair(T first, T second) &#123; this.first = first; this.second = second; &#125; public T getFirst () &#123;return this.first;&#125; public T getSecond () &#123;return this.second;&#125; public void setFirst(T newValue) &#123; first = newValue; &#125; public void setSecond(T newValue) &#123; second = newValue; &#125;&#125; 当然了，我们可以定义多个类型变量，像 Pair&lt;T,U&gt;。 定义泛型方法可以在方法上中使用类型参数，该方法即可以在泛型类中定义，也可以在普通类中定义。其中T是在修饰符(public static)后，在返回类型前。12345class ArrayAlg &#123; public static &lt;T&gt; T getMiddle(T... a) &#123; return a[a.length/2]; &#125;&#125; 下面的方式避免了返回结果是 Object：123public static &lt;T&gt; T convertXmlStrToObject(Class&lt;T&gt; clazz, String xmlStr) &#123; // do something&#125; 该方法可以用如下方式调用：123String middle = ArrayAlg.&lt;String&gt;getMiddle(\"1\", \"2\", \"4\");// 因为编译器可以根据参数类型推断出 T 的类型，所以类型参数可以省略String middle2 = ArrayAlg.getMiddle(\"1\", \"2\", \"4\"); 像上述调用，依靠编译器推断类型时，尽量使用同一类型。 像Number middle = GenericMethod.getMiddle(3.14, 1729, 0); 这种调用，编译器会将参数自动装箱成(Double, Integer, Integer), 然后找到这些类型所共有的父类——Number或Comparable。 所以可以将结果赋给 Number 或者 Comparable. 否则会报错： 123Error:(10, 56) java: 不兼容的类型: 推断类型不符合上限 推断: java.lang.Number&amp;java.lang.Comparable&lt;? extends java.lang.Number&amp;java.lang.Comparable&lt;?&gt;&gt; 上限: java.lang.Double,java.lang.Object 类型变量的界限当我们想要寻找数组中最小值时，就需要泛型变量是继承了Comparable的，这时候就可以使用如下方法对类型变量进行类型限制。12345678public static &lt;T extends Comparable&gt; T min (T[] a) &#123; if (a == null || a.length == 0) return null; T smallest = a[0]; for (int i=1; i&lt;a.length; i++) &#123; if (smallest.compareTo(a[i]) &gt; 0) smallest = a[i]; &#125; return smallest;&#125; 虽然extends一般用在类上，而不是接口。但是类型变量界限使用的是关键字extends，只是因为它更适合表达子类型概念，这样就不用新增一个关键字来表示类型变量界限。当类型变量有多个界定，用&amp;分割： T extends Comparable &amp; Serializable。 类似java中的继承，可以有任意多个接口限定，但是只能有一个类限定。如果有类限定，那么这个类限定的位置必须是界限列表的第一个。 泛型代码和java虚拟机在java虚拟机中并没有泛型类型，所有的对象都是普通的类。编译器会对泛型类或方法进行类型擦除。 类型擦除当定义一个泛型后，对应的原始类型会被虚拟机自动创建。原始类型的类名同其对应的泛型的类型是一致的，只是将类型参数移除，并且用它们的限定类型代替类型参数。123456789public class Interval&lt;T extends Comparable &amp; Serializable, U&gt; implements Serializable &#123; private T lower; private T upper; private U other; public Interval(T first, U second) &#123; if (first.compareTo(second) &lt;= 0) &#123; lower = first; upper = second; &#125; else &#123; lower = second; upper = first; &#125; &#125;&#125; 上列中，类型擦除后，T 使用其第一个限定界限Comparable代替；U因为没有限定，所以用Object代替。类型擦除之后的代码如下：12345678public class Interval implements Serializable &#123; private Comparable lower; private Comparable upper; private Object other; public Interval(Comparable first, Obejct second) &#123; // do something &#125;&#125; 泛型表达式的擦除TY当调用一个泛型方法时，编译器会在返回类型擦除之后，插入类型转换的代码。12Pair&lt;Employee&gt; pairs = new Pair&lt;&gt;();Employee pair = pairs.getFirst(); getFirst()方法返回的类型经过类型擦除之后是 Object，编译器自动插入了Employee的类型转换： Employee pair = (Employee)pairs.getFirst().当然了，对于直接访问泛型属性，编译器的处理也是相似的。 泛型方法的擦除泛型方法的擦除方式同泛型类类似。 public static &lt;T extends Comparable&gt; T min (T[] a)方法擦除后是 public static Comparable T min(Comparable[] a).但是，当我们在继承泛型类时，只是擦除类型，泛型方法会有问题。例如下面的例子12345class DateInterval extends Pair&lt;LocalDate&gt; &#123; public void setSecond(LocalDate second) &#123; // do something &#125;&#125; 上述类执行类型擦除之后，如下：12345class DateInterval extends Pair &#123; // after erasure public void setSecond(LocalDate second) &#123; // do something &#125;&#125; 如果泛型类Pair&lt;LocalDate&gt;中，恰好有一个方法，类型擦除后是 public void setSecond(Object second)。显然，这两个方法因为参数签名不一致，是两个不同的方法。但是，这两个方式不应该不是一个方法。12Pair&lt;LocalDate&gt; pair = new DateInterval(. . .);; // OK--assignment to superclasspair.setSecond(aDate); 上述方法中，我们想要调用的是DateInterval中的setSecond(LocalDate second)。但是，类型擦除后，调用的应该会是setSecond(Object second)。为了修正这个问题，编译器会为DateInterval生成一个桥接(bridge method)方法： public void setSecond(Object second) { setSecond((Date) second); } 概括来说，Java中泛型的类型擦除会遵循以下原则： 虚拟机中并没有泛型类，只有普通类 所有的类型参数都会被其界限替代 合成桥接方法以保持多态 需要的时候，会插入类型转换 使用泛型的限制大多数的限制是类型擦除导致的。 类型参数不能是原始类型不能将原始类型作为参数类型，只能有Pair&lt;Double&gt;，而不能用Pair&lt;double&gt;。因为类型擦除之后，Pair类是Object类型的属性，不能用来存储double的值。 运行时类型查询仅适用于原始类型类型查询仅适用于原始类型，如a instanceof Pair&lt;String&gt;是错误的，只能判断a是否是Pair的实例，而不能判断a是否是Pair&lt;String&gt;类型的。123Pair&lt;String&gt; stringPair = ...;Pair&lt;Empolyee&gt; employeePair = ...;stringPair.getClass() == employeePair.getClass() // true, 他们是相等的，getClass都会返回 Pair.class 不能创建泛型类型的数组不能实例化泛型类型的数组，Pair&lt;String&gt;[] table = new Pair&lt;String&gt;[10]; 是错误的。当上述代码执行类型擦除之后，table的类型是Pair[]，我们可以将它转换成Object[]。但是，数组会记住其元素的类型，如果存储一个错误类型的元素，会抛出一个ArraySotreException异常。 如objectArr[0]=&quot;hello&quot;;只有数组的创建是不合法的，我们还是可以声明Pair&lt;String&gt;[] 类型的数组，但是不能用new Pair&lt;String&gt;[10]来将其初始化。 可以声明通配符类型数组，然后将其转换成对应的类型12&gt; Pair&lt;String&gt;[] table = (Pair&lt;String&gt;[]) new Pair&lt;?&gt;[10];&gt; 但是这种方式是不安全的，如果想调用Pair中的方法，会抛出ClassCastException.如果想用泛型的数组，可以使用ArrayList，它是安全并且有效的。 可使用可变参方法Java不支持泛型数组的初始化，但是可以使用可变参数作为方法的参数。代码可以正常运行，但是会有警告。123456@SafeVarargspublic static &lt;T&gt; void addAll(T... ts) &#123; for (t: ts) &#123; this.add(t); &#125;&#125; 不能实例化泛型变量不能用new T()方法创建实例。这是因为类型擦除会将T变成Object。显然new Object()并不是我们想要的结果。我们可以通过其他的方式来创建泛型实例：123456public static &lt;T&gt; Pair&lt;T&gt; makePair(Class&lt;T&gt; cl)&#123; try &#123; return new Pair&lt;&gt;(cl.newInstance(), cl.newInstance()); &#125; catch (Exception ex) &#123; return null; &#125;&#125;// 调用方式如下：Pair&lt;String&gt; p = Pair.makePair(String.class); 泛型类的静态变量或方法中不能使用类型变量我们不能在泛型类中的静态变量或者方法使用类型变量，下面的方式是错误的：12345678public class Singleton&lt;T&gt; &#123; private static T singleInstance; // Error public static T getSingleInstance() &#123; // Error if (singleInstance == null) construct new instance of T return singleInstance; &#125;&#125; 如果这样的方式是可以的，那么我们可以定义一个Singleton&lt;Random&gt;来共享一个随机数生成器，Singleton&lt;File&gt;来共享一个文件处理器。但这肯定是不可能的，类型擦除之后，只有一个Singleton类和一个singleInstance属性。 不能抛出或者捕获泛型类的实例定义一个继承Throwable的泛型类是不合法的：1public class GenericException&lt;T&gt; extends Exception &#123;&#125; // Error 但是我们可以用在异常处理中使用泛型：12345678public static &lt;T extends Throwable&gt; void doWork(T t) throws T &#123;// OK try &#123; // do work &#125; catch (Throwable realCause) &#123; t.initCause(realCause); throw t; &#125;&#125; 注意类型擦除后方法相同签名泛型类型被擦除之后，可能会导致方法签名一直。如果Pair类中添加eqauls方法：123456public class Pair&lt;T&gt; &#123; public boolean equals(T value) &#123; return first.equals(value) &amp;&amp; second.equals(value); &#125; ...&#125; 当Pair&lt;T&gt;类型擦除之后，其equals方法变为 boolean equals(Object o) 同Object中的equals方法一直。解决方法是命名成其他名字。为了防止擦除带来的方法冲突，我们强加了一个限制。即类或类型变量不能同时是同一个接口的不同参数化的两种子类型。12class Employee implements Comparable&lt;Employee&gt; &#123; . . . &#125;class Manager extends Employee implements Comparable&lt;Manager&gt;&#123; . . . &#125; // Error 上例子中，Manager 需要实现Comparable&lt;Manager&gt;和Comparable&lt;Employee&gt;，这两个接口就是同一接口的两个不同参数化的接口。虽然类型擦除之后，看起来是合法的：12class Employee implements Comparable &#123; . . . &#125;class Manager extends Employee implements Comparable &#123; . . . &#125; 但是桥接方法是冲突的，实现Comparable&lt;X&gt;接口的类，会有一个桥接方法：1public int comparTo(Object other) &#123;return compareTo((X) other);&#125; 泛型类中的继承规则在使用泛型类型的时候，需要了解一些继承的规则。如果有两个类： Employee和Manager，Manager是Employee子类。Pair&lt;Manager&gt;也是Pair&lt;Employee&gt;的子类么？实际上，在Pair&lt;S&gt;和Pair&lt;T&gt;之间没有任何的关系，不管S和T是什么关系。 通配符类型通配符类型是指可以有不同的类型参数。通配符类型使用方式为Pair&lt;? extends Employee&gt;，它表示类型参数是Employee的子类的任何通用Pair类型，比如： Pair&lt;Manager&gt;。我们可以把Pair&lt;Manager&gt;看做是Pair&lt;? extends Employee&gt; 的子类。因此，我们可以把Pair&lt;Manager&gt;的实例传入下面的方法中：123public static void print(Pair&lt;? extends Employee&gt; p) &#123; // do something&#125; 通配符类型的上界限通配符的界限同类型变量的界限相似，不过通配符界限可以指定一个下限： ? super Manager。该通配符表示所有Manager的父类。含有父类界限的通配符与上述的通配符类型正好相反。我们可以为方法提供参数，但是不能使用其返回值。比如Pair&lt;? super Manager&gt;的方法可以表述如下：12void setFirst(? super Manager);? super Manager getFirst(); 编译器不能知道setFirst参数准确的类型，因此不能接受具有Employee或Object类型的参数调用。该方法只能传递Manager或者其子类型的对象。对于调用getFirst将会返回一个Object对象，因为我们不知道它的返回类型是什么。1234567891011public static void minmaxBonus(Manager [] a, Pair&lt;? super Manager&gt; result) &#123; if (a.length == 0) return ; Manager min = a[0]; Manager max = a[0]; for (int i=1; i&lt;a.length; i++) &#123; if (min.getBonus() &gt; a[i].getBonus()) min = a[i]; if (max.getBonus() &lt; a[i].getBonus()) max = a[i]; &#125; result.setFirst(min); result.setSecond(max);&#125; 其类图如下所示： 一般来说，父类界定的通配符类型可以set对象，而子类型界定的通配符类型可以让你get对象 Comparable接口本身就是一个泛型：123public interface Comparable&lt;T&gt; &#123; public int compareTo(T other);&#125; 使用T extends Comparable方式，经过类型擦除后是：123public interface Comparable &#123; public int compareTo(Object other);&#125; 所以，对于ArrayAlg类中的min方法，我们可以将其定义为：1public static &lt;T extends Comparable&lt;T&gt;&gt; T min(T[] a) 这样比T extends Comparable更为全面，而且对于大多数类来说都能很好的工作。但是对于LocalDate对象来说，并不适用。LocalDate实现了ChronoLocalDate接口，ChronoLocalDate接口继承了Comparable&lt;ChronoLocalDate&gt;，因此LocalDate实现了Comparable&lt;ChronoLocalDate&gt;而不是Comparable&lt;LocalDate&gt;。在这种情况下，使用下面的方法更适用：1public static &lt;T extends Comparable&lt;? super T&gt;&gt; T min(T[] a) &#123;&#125; 这样经过类型擦除之后：1public int compareTo(LocalDate other); 虽然这样看起来很繁琐，但是这样声明能够消除调用方法时对参数的不必要限制。 无界限通配符无界限通配符，如Pair&lt;?&gt;。无界限通配符与原始类型Pair一样。但是，这两个类型是不同的，Pair&lt;?&gt;的方法如下：12? getFirst();void setFirst(?); getFirst方法的返回值只能是Object，而setFirst方法不能被调用，即使是Object作为参数也不行，当然null是可以的。这是Pair&lt;?&gt;与原始的Pair类型的不同。 无界限通配符一般会用来做非常简单的操作，例如，判断值是不是null:123public static boolean hasNulls(Pair&lt;?&gt; p) &#123; return p.getFirst() == null || p.getSecond() == null;&#125; 通配符捕获我们有一个交换Pair元素的方法：1public static void swap(Pair&lt;?&gt; p) 通配符不是一个类型变量，我们不能用?作为一个类型，也就是下面的代码是不合法的：123? t = p.getFirst(); // Errorp.setFirst(p.getSecond());p.setSecond(t); 我们在交换元素时，必须要将其中一个元素保存成临时变量。为了解决这个问题，我们可以编写一个辅助方法swapHelper:12345public static &lt;T&gt; void swapHelper (Pair&lt;T&gt; p) &#123; T t = p.getFirst(); p.setFirst(p.getSecond()); p.setSecond(t);&#125; swapHelper是一个泛型方法，而swap不是，现在我们可以在swap中调用swapHelper:1public static void swap(Pair&lt;?&gt; p) &#123; swapHelper(p);&#125; 在上述方法中，swapHelper中的T捕获了swap中的通配符类型。编译器不知道通配符是什么类型，但它是一种确定的类型，当T表示该类型时， swapHelper的定义是完美的。当然，在这个例子中，我们没有必要使用Pair&lt;?&gt;，可以直接定义&lt;T&gt; void swapHelper。但是，如果某个方法中像如下定义：123public static void maxmin(Manager[] a, Pair&lt;? super Manager&gt; result) &#123; PairAlg.swap(result); // swapHepler 捕获了通配符类型&#125; 下边的例子给了前边所描述的内容：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class GenericMethod &#123; public static void main(String[] args) &#123; Manager ceo = new Manager(\"Gus Greedy\", 800000, 2003, 12, 15); Manager cfo = new Manager(\"Sid Sneaky\", 600000, 2003, 12, 15); Pair&lt;Manager&gt; buddies = new Pair&lt;&gt;(ceo, cfo); printBuddies(buddies); ceo.setBonus(1000000); cfo.setBonus(500000); Manager[] managers = &#123;ceo, cfo&#125;; Pair&lt;Employee&gt; result = new Pair&lt;&gt;(); minmaxBonus(managers, result); System.out.println(\"first: \" + result.getFirst().getName() + \", second: \" + result.getSecond().getName()); maxminBonus(managers, result); System.out.println(\"first: \" + result.getFirst().getName() + \", second: \" + result.getSecond().getName()); &#125; public static void printBuddies(Pair&lt;? extends Employee&gt; p) &#123; Employee first = p.getFirst(); Employee second = p.getSecond(); System.out.println(first.getName() + \" and \" + second.getName() + \" are buddies.\"); &#125; public static void minmaxBonus(Manager[] a, Pair&lt;? super Manager&gt; result) &#123; if (a.length == 0) return; Manager min = a[0]; Manager max = a[0]; (Continues) .8 Wildcard Types 449 Listing 8.3 (Continued) for (int i = 1; i &lt; a.length; i++) &#123; if (min.getBonus() &gt; a[i].getBonus()) min = a[i]; if (max.getBonus() &lt; a[i].getBonus()) max = a[i]; &#125; result.setFirst(min); result.setSecond(max); &#125; public static void maxminBonus(Manager[] a, Pair&lt;? super Manager&gt; result) &#123; minmaxBonus(a, result); PairAlg.swapHelper(result); // OK--swapHelper captures wildcard type &#125;&#125;class PairAlg &#123; public static boolean hasNulls(Pair&lt;?&gt; p) &#123; return p.getFirst() == null || p.getSecond() == null; &#125; public static void swap(Pair&lt;?&gt; p) &#123; swapHelper(p); &#125; public static &lt;T&gt; void swapHelper(Pair&lt;T&gt; p) &#123; T t = p.getFirst(); p.setFirst(p.getSecond()); p.setSecond(t); &#125;&#125;","categories":[{"name":"java","slug":"java","permalink":"http://wzhongke.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://wzhongke.github.io/tags/java/"}]},{"title":"找出字符串最大回文","slug":"algorithms/找出字符串最大回文","date":"2017-09-17T14:20:00.000Z","updated":"2017-09-18T06:10:05.698Z","comments":true,"path":"2017/09/17/algorithms/找出字符串最大回文/","link":"","permalink":"http://wzhongke.github.io/2017/09/17/algorithms/找出字符串最大回文/","excerpt":"","text":"题目给定一个字符串 s，找到s中最长的回文字符串。可以假设s的最长长度是1000。Example1 : Input: “babad” Output: “bab” Note: “aba” 也是可以的答案Example2 : Input: “cbbd” Output: “bb” 解法假设前i个字符最大的回文串长度是currLength，那么i+1个字符最大的回文长度计算方法是： 计算i+1-curLength-1到i+1是否为回文 计算i+1-curLength-2到i+1是否为回文 如果前两步中为是，那么将curLength赋值为其中的最大值 原理对于 “xxxbcbxxxxa” (x 是随机的字符) 来说，我们现在处理最后一个字符 a。目前最长回文是bcb，长度是 3 如果 xxxxa 是回文，那么我们可以计算得到一个新的最大回文长度 5 如果 xxxa 是回文，那么我们可以计算得到一个新的最大回文长度 4 无需计算更短的字符串，因为其回文的最大长度不会大于现在回文长度 不用计算 xxxxxa，因为如果它是回文，那么去掉头和尾，xxxx仍然是回文，其长度是4，与假设矛盾。 代码12345678910111213141516171819202122232425private byte[] sByte;public String alongestPalindrome(String s) &#123; int currLength = 0, start = 0, end = 0; sByte = s.getBytes(); for(int i=0;i&lt;s.length();i++)&#123; if(isPalindrome(i-currLength-1,i))&#123; start = i-currLength-1; currLength = currLength+2; &#125; else if(isPalindrome(i-currLength,i))&#123; start = i-currLength; end = i+1; currLength = currLength+1; &#125; &#125; return s.substring(start, end);&#125;public boolean isPalindrome( int begin, int end)&#123; if(begin&lt;0) return false; while(begin&lt;end)&#123; if(sByte[begin++]!=sByte[end--]) return false; &#125; return true;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"http://wzhongke.github.io/categories/算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://wzhongke.github.io/tags/算法/"}]},{"title":"webpackage","slug":"webpackage","date":"2017-09-14T02:02:15.898Z","updated":"2017-09-14T02:02:15.898Z","comments":true,"path":"2017/09/14/webpackage/","link":"","permalink":"http://wzhongke.github.io/2017/09/14/webpackage/","excerpt":"","text":"文件中的缩进是2，修改idea的配置之后不生效，需要修改文件 .editorconfig 创建webpack12345vue init webpack # 或者vue init gurghet/webpacknpm install # 安装依赖 如果有 less 文件，需要安装1npm install --save-dev less-loader less 指定webpack入口文件：123456module.exports = &#123; entry: &#123; main: &apos;./src/main.js&apos;, a: &apos;./src/a.js&apos; &#125;&#125; 指定输出路径123456module.exports = &#123; output: &#123; path: &apos;./dist&apos;, filename: &apos;js/[name]-[chunkhash].js&apos; &#125;&#125; 安装htmlWebpackPlugin插件：12345678910111213141516module.exports = &#123; // 环境的上下文 context: ./ plugins: &#123; new htmlWebpackPlugin(&#123; // 指定html模板 template: index.html, // 指定生成文件名 filename: 'index-[hash].html', // 指定script标签位置 inject: 'head', // 设定参数 title: 'webpack is awesome!' &#125;) &#125;&#125; 在html中使用htmlWebpackPlugin的参数1&lt;title&gt;&lt;%= htmlWebpackPlugin.options.title %&gt;&lt;/title&gt;","categories":[],"tags":[]},{"title":"vuex","slug":"front/vuex","date":"2017-08-30T19:42:25.000Z","updated":"2017-09-01T04:53:01.955Z","comments":true,"path":"2017/08/31/front/vuex/","link":"","permalink":"http://wzhongke.github.io/2017/08/31/front/vuex/","excerpt":"","text":"Vuex 能做什么Vuex将多个组件共享的状态从组件中抽离出来，，以一个全局单例的模式进行统一管理。解决问题 多层嵌套组件间传参繁琐，且兄弟组件间的状态传递无能为力。 父子组件直接引用或者通过事件来变更和同步状态的多份拷贝，这种方式非常脆弱，代码不易维护 核心概念单一状态树 – state单一状态树是全局唯一的变量，唯一的数据源，每个应用仅包含一个store实例在 Vue 组件中获得 Vuex 状态Vuex 通过调用 Vue.use(Vuex) 将store注入到子组件中，子组件可以通过this.$store访问到store中的内容：12345678910111213141516171819const Counter = &#123; template: `&lt;div&gt; &#123;&#123;count&#125;&#125;&lt;/div&gt;`, computed: &#123; count() &#123; return this.$store.state.count &#125; &#125;&#125;const app = new Vue(&#123; el: '#app', // 把 store 对象提供给 “store” 选项，这可以把 store 的实例注入所有的子组件 store, components: &#123; Counter &#125;, template: ` &lt;div class=\"app\"&gt; &lt;counter&gt;&lt;/counter&gt; &lt;/div&gt; `&#125;) getter当我们需要从store中提取出一些状态，可以在computed中进行过滤计算。但是如果多个组件要使用该属性，那么就会导致代码冗余。可以在store中敌营getter来解决该问题。而且getter会将计算的值缓存起来，当其依赖的值发生改变才会被重新计算。12345678910111213141516171819const store = new Vuex.Store(&#123; state: &#123; todos: [ &#123; id: 1, text: '...', done: true &#125;, &#123; id: 2, text: '...', done: false &#125; ] &#125;, getters: &#123; doneTodosCount: (state, getters) =&gt; &#123; return getters.doneTodos.length &#125; &#125;&#125;)// 在组件中使用computed: &#123; doneTodoCount() &#123; return this.$store.getters.doneTodosCount &#125;&#125; 更改store变量的值 – 同步方式mutation更改 Vuex 的 store 中的状态的唯一方法是提交mutation：每个mutation都有一个字符串的事件类型和回调函数，该函数接受一个state作为第一个参数123456789101112const store = new Vuex.Store(&#123; state: &#123; count: 1 &#125;, mutations: &#123; increment (state) &#123; state.count++ // 变更状态 &#125; &#125;&#125;)// 在组件中需要用如下方式调用：store.commit(\"increment\") 如果提交的内容含有参数：123456789101112131415161718mutations: &#123; increment (state, n) &#123; state.count += n &#125;&#125;this.$store.commit(\"increment\", 1)// 对象方式提交mutations: &#123; increment (state, payload) &#123; state.count += payload.amount &#125;&#125;this.$store.commit(\"increment\" &#123;amount: 10&#125;)this.$store.commit(&#123; type: 'increment', amount: 10&#125;) mutations 遵循vue响应规则 最好提前在你的 store 中初始化好所有所需属性。 当需要在对象上添加新属性时，你应该 使用 Vue.set(obj, &#39;newProp&#39;, 123) 以新对象替换老对象 state.obj = { ...state.obj, newProp: 123 }更改store变量的值 – 异步方式actionsaction可以包含任意异步操作。定义action：1234567891011121314151617181920const store = new Vuex.Store(&#123; state: &#123; count: 0 &#125;, mutations: &#123; increment (state) &#123; state.count++ &#125; &#125;, actions: &#123; increment (context) &#123; context.commit('increment') &#125;, incrementAsync (&#123; commit &#125;) &#123; setTimeout(() =&gt; &#123; commit('increment') &#125;, 1000) &#125; &#125;&#125;) 调用actions1234567891011store.dispatch('increment')// 以载荷形式分发store.dispatch('incrementAsync', &#123; amount: 10&#125;)// 以对象形式分发store.dispatch(&#123; type: 'incrementAsync', amount: 10&#125;) 在组件中使用action，可以用this.$store.dispatch(&#39;xxx&#39;) 分发 action，或者使用 mapActions 辅助函数将组件的 methods 映射为 store.dispatch 调用:123456789101112import &#123; mapActions &#125; from 'vuex'export default &#123; methods: &#123; ...mapActions([ 'increment' // 映射 this.increment() 为 this.$store.dispatch('increment') ]), ...mapActions(&#123; add: 'increment' // 映射 this.add() 为 this.$store.dispatch('increment') &#125;) &#125;&#125;","categories":[{"name":"javascript","slug":"javascript","permalink":"http://wzhongke.github.io/categories/javascript/"},{"name":"vue","slug":"javascript/vue","permalink":"http://wzhongke.github.io/categories/javascript/vue/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://wzhongke.github.io/tags/javascript/"},{"name":"vue","slug":"vue","permalink":"http://wzhongke.github.io/tags/vue/"}]},{"title":"git 版本管理工具","slug":"git","date":"2017-08-24T07:45:48.647Z","updated":"2017-08-24T07:45:48.651Z","comments":true,"path":"2017/08/24/git/","link":"","permalink":"http://wzhongke.github.io/2017/08/24/git/","excerpt":"","text":"git是比较常用的版本控制工具。 git的基本使用 git init : 创建新的git仓库 git clone path : 从远端服务器或本地检出仓库 git add filename 或者 git add * : 添加改动到缓存区 git commit -m &#39;代码提交信息&#39; : 实际提交改动，将改动提交到本地仓库的HEAD中 git remote add origin &lt;server&gt; : 添加远程仓库 git push origin master : 将改动提交道远端仓库 git branch -a : 查看远程分支 git branch : 查看本地分支 git branch –d xxxx : 删除本地分支 git branch –r –d origin/xxxx : 删除远程分支 git 分支分支是用来将特性开发绝缘开来的。在创建仓库的时候，master是默认的。 git checkout –b feature : 创建一个叫做 “feature”的分支，并切换到该分支 git checkout master : 切换回主分支 git branch –d feature :删除feature 分支 git push origin &lt;branch&gt; : 将分支推送到远端仓库 git更新与合并 git pull : 将更新本地仓库至最新改动 git merge &lt;branch&gt; : 在当前工作目录中获取并合并远端的改动；要合并其他分支到当前分支 git add &lt;filename&gt; : 解决冲突之后，执行该命令表示合并成功 git diff &lt;source_branch&gt; &lt;target_branch&gt;: 在合并改动之前，使用该命令查看 git替换本地改动 git checkout -- &lt;filename&gt; : 使用HEAD中的最新内容替换掉工作目录中的文件，已添加到缓存区的改动，以及新文件不受影响。 git fetch origin git reset –hard origin/master丢弃所有的本地改动与提交，可以到服务器上获取最新的版本并将你本地主分支指向它:","categories":[{"name":"工具","slug":"工具","permalink":"http://wzhongke.github.io/categories/工具/"}],"tags":[{"name":"工具","slug":"工具","permalink":"http://wzhongke.github.io/tags/工具/"}]},{"title":"碰到过的问题","slug":"碰到过的问题","date":"2017-08-22T02:18:53.994Z","updated":"2017-10-23T08:50:57.257Z","comments":true,"path":"2017/08/22/碰到过的问题/","link":"","permalink":"http://wzhongke.github.io/2017/08/22/碰到过的问题/","excerpt":"Java 在java中，对于读取文件乱码，可以通过以下方式来指定文件的编码new InputStreamReader(new FileInputStream(file), &quot;GBK&quot;) 或者 Files.newBufferedReader(path, StandardCharsets.UTF_8) Cookie rejected [...] 对于 Cookie rejected ，可能是机器配置了域名，但是没有使用域名访问机器。 使用Java转换xslt时，可以通过 TransformerFactory.newInstance(&quot;com.self.SelfConfig&quot;,com.self.SelfConfig.class.getClassLoader())，其中 com.self.SelfConfig 是继承自 TransformerFactoryImpl，覆盖了其 newTemplatesHandlers() 方法的类。 在maven中使用java编译时，出现 Compilation failed:internal java compiler error，信息中有Information:java:javacTask:源发行版1.8需要目标发行版1.8。这是因为maven默认的编译版本不是1.8，修改pom.xml: 123456789101112&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 引入 slf4j jar 包时，出现： java.lang.IllegalAccessError: tried to access field org.slf4j.impl.StaticLoggerBinder.SINGLETON from class org.slf4j.LoggerFactory。可能的原因是其他jar包中包含的 slf4j-api.jar 的版本比较低，解决方案是查找引入的jar包文件，哪一个包使用的 slf4j-api 版本比较低，如果是 maven，可以使用如下方式去掉低版本的jar： 123456 &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;/exclusion&gt;&lt;/exclusions&gt; eclipse 不能正确引用jar文件。 在jar文件上右键 -&gt; Build Path -&gt; add to path JavaScript 在ipad上通过jquery绑定的click事件不生效，解决方法： 1$(document).bind(\"click touchstart\", function()&#123;&#125;) 使用java拼接json字符串时，不能用\\n， 否则JavaScript不会识别。","text":"Java 在java中，对于读取文件乱码，可以通过以下方式来指定文件的编码new InputStreamReader(new FileInputStream(file), &quot;GBK&quot;) 或者 Files.newBufferedReader(path, StandardCharsets.UTF_8) Cookie rejected [...] 对于 Cookie rejected ，可能是机器配置了域名，但是没有使用域名访问机器。 使用Java转换xslt时，可以通过 TransformerFactory.newInstance(&quot;com.self.SelfConfig&quot;,com.self.SelfConfig.class.getClassLoader())，其中 com.self.SelfConfig 是继承自 TransformerFactoryImpl，覆盖了其 newTemplatesHandlers() 方法的类。 在maven中使用java编译时，出现 Compilation failed:internal java compiler error，信息中有Information:java:javacTask:源发行版1.8需要目标发行版1.8。这是因为maven默认的编译版本不是1.8，修改pom.xml: 123456789101112&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 引入 slf4j jar 包时，出现： java.lang.IllegalAccessError: tried to access field org.slf4j.impl.StaticLoggerBinder.SINGLETON from class org.slf4j.LoggerFactory。可能的原因是其他jar包中包含的 slf4j-api.jar 的版本比较低，解决方案是查找引入的jar包文件，哪一个包使用的 slf4j-api 版本比较低，如果是 maven，可以使用如下方式去掉低版本的jar： 123456 &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;/exclusion&gt;&lt;/exclusions&gt; eclipse 不能正确引用jar文件。 在jar文件上右键 -&gt; Build Path -&gt; add to path JavaScript 在ipad上通过jquery绑定的click事件不生效，解决方法： 1$(document).bind(\"click touchstart\", function()&#123;&#125;) 使用java拼接json字符串时，不能用\\n， 否则JavaScript不会识别。 CSS1.含有画布内容隐藏时，获取画布可能会出现错误。隐藏方式修改为： 12position: relative; left: 1000px; 通过定位的方式可能会导致页面可以左右滑动或者下方有大片空白。 后来采用的方式是先展示元素，通过js脚本控制元素最后隐藏。 因为js脚本执行可能会有延时或者顺序不可保证，因此使用先展示后隐藏会有问题，因此可以使用设置通过如下方式控制 12height:0;overflow: hidden; linux /var 目录使用率为100% 使用 du -h --max-depth=1 /var命令查看var下的文件，发现没有占用空间特别大的文件，总量也不够磁盘的100% 使用lsof -n | grep delete 命令查看哪些进程使用了已经删除的文件，这些文件虽然已经删除，但是没有释放空间，解决方法是kill掉进程或者reboot 可能是inode的总量达到磁盘上限，使用df -i查看inode使用情况。如果达到100%，可能是小文件过多，需要找到并清理这些文件 linux 的 shell 脚本。如果是手动使用sh shell.sh执行没有问题，但是使用 crontab 或者 java 等程序调用时，执行错误或者与sh shell.sh 执行不一致。那么可能是环境变量不同所导致的，比如 PATH， 可以通过export PATH=$PATH:... 来解决。但是碰到过一次比较奇怪的问题，使用 sh shell.sh 执行数据查询没问题，但是使用 crontab 执行却总是没有结果。经过一段时间的调试，找问题，终于定位到是编码的问题。在sh shell.sh执行时，$LANG=zh_CN.UTF-8，但是在 crontab 执行时却是 $LANG=en_US，导致查询失败。在代码开头加入 export LANG=zh_CN.UTF-8 解决。 nginx resin 在nginx+resin的配置中，nginx总是报错：upstream timed out (110: Connection timed out) while reading response header from upstream。一般情况下是因为resin处理时间过长，没有返回结果。通过配置 nginx的 location 的超时时间来解决 12345location / &#123; hmux_read_timeout 180; # 若为proxy，则改为 proxy_read_timeout 180; hmux_pass hmux://resin_add;&#125; nginx 不能连接上resin，说resin拒绝连接，浏览器访问出现502错误 解决方案：查看resin配置文件resin.xml或resin.conf，看配置的host是否与nginx配置的相同，端口号是否一致 123&lt;cluster&gt; &lt;srun server-id=\"\" host=\"localhost\" port=\"8080\"/&gt;&lt;/cluster&gt; resin启动失败，查看日志，有java.net.UnknownHostException，编辑/etc/hosts文件，配置相应的host即可 PHP php脚本中不能将 “+” 通过urldecode($str)正确解析，需要通过rawurldecode($str)解析 PHP中双引号中的变量会被解析 SQL 在MySQL插入操作时，抛出java.sql.SQLException: Incorrect string value: &#39;\\xE4\\xB8\\xAD\\xE5\\x9B\\xBD...&#39; for column &#39;request&#39;异常该异常是因为数据库表或者字段使用的字符集不支持这种编码，将数据库表或者字段采用的编码集设置成utf8 Other 换个角度思考问题，往往能更好地解决问题。 resin 出现validating indexes due to unclean shutdown.错误时，可以将resin安装目录下的 resin-data 文件夹整体删除。JSP JSP执行莫名失败，不报错。可能是变量名称定义重复。可以通过在外层加一个大括号，将变量的定义分离开来 在使用JSP的out.write()返回内容时，需要用out.flush()将缓存中的内容刷新到返回体中","categories":[{"name":"other","slug":"other","permalink":"http://wzhongke.github.io/categories/other/"}],"tags":[{"name":"other","slug":"other","permalink":"http://wzhongke.github.io/tags/other/"}]},{"title":"linux 网络常用命令","slug":"linux/linux server","date":"2017-08-22T02:18:53.985Z","updated":"2017-10-18T03:21:00.922Z","comments":true,"path":"2017/08/22/linux/linux server/","link":"","permalink":"http://wzhongke.github.io/2017/08/22/linux/linux server/","excerpt":"","text":"linux 常用网络命令ifconfig, ifup, ifdown这三个指令都是用来启动网络接口的。 ifconfigifconfig主要是可以手动启动、观察与修改网络接口的相关参数。语法如下: 123456789ifconfig [interface] &#123;up/down&#125; ## 观察与启动接口ifconfig interface &#123;options&#125; ## 设定与修改接口# 参数说明- interface: 网卡接口代号，如: eth0, th1, ppp0等- options: 可以使用的参数: - up/down: 启动/关闭该网络接口 - mtu : 设定不同的MTU数值（不建议修改） - netmask: 设置自屏蔽网络 - broadcast: 广播地址 在linux机器上执行ifconfig，会返回如下结果1234567eth0 Link encap: Ethernet HWaddr AA: AA: AA: 31: 79: 95 inet addr: 10.143.59.167 Bcast: 10.143.63.255 Mask: 255.255.248.0 UP BROADCAST RUNNING MULTICAST MTU: 1500 Metric: 1 RX packets: 69269420 errors: 0 dropped: 0 overruns: 0 frame: 0 TX packets: 43411105 errors: 0 dropped: 0 overruns: 0 carrier: 0 collisions: 0 txqueuelen: 1000 RX bytes: 159293308457 (148.3 GiB) TX bytes: 106356430482 (99.0 GiB) eth0: 网卡代号 HWaddr: 网卡硬件地址 RX: 网络由启动到目前为止的封包接收情况，packets代表封包数、errors代表封包发生错误的数量、dropped代表封包由于有问题而遭到丢弃的数量 TX: 与RX相反，为网络由启动到目前为止的传送情况 collisions: 代表封包碰撞情况 RX bytes, TX bytes: 总接收、发送字节总量修改网络接口12ifconfig eth0 10.134.96.237 # 系统会依照IP所在的class范围，自动计算netmask、broadcast等IP参数ifconfig eth0 10.134.96.237 netmask 255.255.255.128 mtu 8000 # 修改其他数值 如果手动设置错误或者有问题，我们可以通过/etc/init.d/network restart 来重启整个网络接口 ifup, ifdown还可以用配置文件来修改网络参数，执行这两个命令会执行/etc/sysconfig/network-scripts中相应的脚本 routeroute可以查看机器使用的路由信息123456789101112route [-nee]route add [-net/host] [网域或主机] netmask [mask] [gw/dev]route del [-net/host] [网域或主机] netmask [mask] [gw/dev]## 参数说明-n: 直接展示通讯协议或主机名，直接用IP或port number-ee: 使用更详细的信息显示## 增加与删除路由-nest: 后边接的是路由为一个域名-host: 后面接的为连接到单部主机的路由netmask: 与域名有关，可以设定netmask决定域名的大小gw: gateway的简写，后接的是IPdev: 如果指定哪一块网卡联机出去，设定该值 使用route指令字段的含义如下: Destination, Genmask: 分别是network和netmask Gateway: 表明该机器是通过哪个gateway连接出去的，如果是 0.0.0.0 表示该路由直接是本机传送 Iface: 表明是从哪个网卡出去的12345# 路由的增加与删除# 删除192.168.0.0/16网段，需要将路由表上的信息都写入才能删除route del -net 192.168.0.0 netmask 255.255.0.0 dev eth0# 增加预设路由，只有一个就够了route add default gw 192.168.1.250 当出现Network is unreachable时，可能是gw后边的IP直接连接。 pingping通过ICMP封包来进行网络状态报告。其使用方式如下:12345678910111213141516ping [选项与参数] IP -c 数值: 后接ping的次数 -n: 输出数据时不进行IP与主机的反查，直接用IP输出，速度较快 -s 数值: 发送出去的ICMP封包大小，预设为56bytes，可以调大 -t 数值: TTL的数值，预设是255，每经过一个节点就会减1 -W 数值: 等待响应时间# 例子ping -c 3 192.168.22.10PING 192.168.22.10 (192.168.22.10) 56(84) bytes of data.64 bytes from 192.168.22.10: icmp_seq=1 ttl=59 time=4.40 ms64 bytes from 192.168.22.10: icmp_seq=2 ttl=59 time=1.40 ms64 bytes from 192.168.22.10: icmp_seq=3 ttl=59 time=1.12 ms--- 192.168.22.10 ping statistics ---3 packets transmitted, 3 received, 0% packet loss, time 2004msrtt min/avg/max/mdev = 1.121/2.309/4.405/1.486 ms 上例中响应消息中，几个重要的项目是： 64bytes: 表示传送的ICMP封包大小为64bytes，在某些特殊场合中，可以用-s 2000来取代 imcp_seq=1: ICMP所侦测进行的次数，第一次编号为1 ttl=59 traceroute 两主机间各节点分析traceroute用来追踪两部主机之间通过的各个节点通讯状况的好坏。其使用方式如下:12345678910111213141516traceroute [选项与参数] IP -n: 必进行主机的名称解析，单纯用IP，速度较快 -U: 使用UDP的port 33433 来进行侦测 -I: 会用 ICMP 的方式 进行侦测 -w: 若对方主机在几秒钟没有回声，就放弃 -T: 使用TCP来侦测，因为UDP/ICMP的攻击层出不穷，因此很多路由器可能取消两个封包的响应功能。## 例子traceroute -n -w1 10.152.105.195traceroute to 10.152.105.195 (10.152.105.195), 30 hops max, 60 byte packets 1 10.144.103.252 0.662 ms 0.646 ms 0.741 ms 2 * * * 3 * * * 4 * * * 5 * * * 6 10.152.105.195 1.344 ms 1.172 ms 1.042 ms 其中 * * * 是因为该节点可能有某些防护措施，让我们发送的封包信息被丢弃 netstat 查看本机的网络联机与后门netstat可以查看网络接口监听情况 12345678910111213141516171819202122232425262728293031# 与路由有关的参数netstat -[rn]# 与网络接口有关的参数netstat -[antulpc]与路由有关的参数：-r : 列出路由表(route table)，功能如同 route 这个指令；-n : 不使用主机名与服务名称，使用 IP 与 port number ，如同 route -n与网络接口有关的参数: -a : 列出所有的联机状态，包括 tcp/udp/unix socket 等；-t : 仅列出 TCP 封包的联机；-u : 仅列出 UDP 封包的联机；-l : 仅列出有在 Listen (监听) 的服务之网络状态；-p : 列出 PID 与 Program-c : 可以设定几秒钟后自动更新一次，例如 -c 5 每五秒更新一次网络状态的显示# 例子netstat -anActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:9090 0.0.0.0:* LISTEN tcp 0 0 127.0.0.1:6600 0.0.0.0:* LISTEN tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN # 显示目前已经启动的网络服务netstat -tulnpActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:9090 0.0.0.0:* LISTEN 18251/java tcp 0 0 127.0.0.1:6600 0.0.0.0:* LISTEN 18201/java tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 26249/nginx tcp 0 0 0.0.0.0:8080 0.0.0.0:* LISTEN 18251/java # 观察本机上头所有的网络联机状态netstat -atunp netstat的输出主要分为两大部分：TPC/IP的网络接口；传统的Unix socket。输出参数的含义如下： Proto: 联机封包协议，TCP/UDP等 Recv-Q: 非由用户程序连接所复制而来的总bytes数， Send-Q: 由远程主机所传送而来，但不具有ACK标志的总bytes数，意指主动联机SYNdrome或其他标志的封包所占的bytes数 Local Address: 本地端的地址和端口号 Foreign Address: 远程主机IP与端口 stat: 连接状态 host 侦测主机名12345host [-a] hostname [server]-a: 列出该主机详细的各项主机名设定数据[server]: 可以使用非为 /etc/resolv.con 的DNS服务IP来查询# 例子host www.baidu.com","categories":[{"name":"other","slug":"other","permalink":"http://wzhongke.github.io/categories/other/"}],"tags":[{"name":"other","slug":"other","permalink":"http://wzhongke.github.io/tags/other/"}]},{"title":"sublime 配置","slug":"sublime","date":"2017-08-19T09:52:00.000Z","updated":"2017-09-04T11:30:31.355Z","comments":true,"path":"2017/08/19/sublime/","link":"","permalink":"http://wzhongke.github.io/2017/08/19/sublime/","excerpt":"","text":"配置markdown 安装package controll: 快捷键`ctrl+``打开Sublime控制台，输入下面代码： sublime 3 1import urllib.request,os,hashlib; h = 'df21e130d211cfc94d9b0905775a7c0f' + '1e3d39e33b79698005270310898eea76'; pf = 'Package Control.sublime-package'; ipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); by = urllib.request.urlopen( 'http://packagecontrol.io/' + pf.replace(' ', '%20')).read(); dh = hashlib.sha256(by).hexdigest(); print('Error validating download (got %s instead of %s), please try manual install' % (dh, h)) if dh != h else open(os.path.join( ipp, pf), 'wb' ).write(by) sublime 2 1import urllib2,os,hashlib; h = &apos;df21e130d211cfc94d9b0905775a7c0f&apos; + &apos;1e3d39e33b79698005270310898eea76&apos;; pf = &apos;Package Control.sublime-package&apos;; ipp = sublime.installed_packages_path(); os.makedirs( ipp ) if not os.path.exists(ipp) else None; urllib2.install_opener( urllib2.build_opener( urllib2.ProxyHandler()) ); by = urllib2.urlopen( &apos;http://packagecontrol.io/&apos; + pf.replace(&apos; &apos;, &apos;%20&apos;)).read(); dh = hashlib.sha256(by).hexdigest(); open( os.path.join( ipp, pf), &apos;wb&apos; ).write(by) if dh == h else None; print(&apos;Error validating download (got %s instead of %s), please try manual install&apos; % (dh, h) if dh != h else &apos;Please restart Sublime Text to finish installation&apos;) 安装markdownediting: ctrl+shift+p 进入sublime命令面板，打开install package，输入markdownediting，安装后重启 sublime 安装OmniMarkupPreviewer，同方法2 配置markdownediting: 1234567&#123; \"color_scheme\": \"Packages/MarkdownEditing/MarkdownEditor-ArcDark.tmTheme\", \"draw_centered\": false, \"word_wrap\": true, \"wrap_width\": \"auto\", \"line_numbers\": true&#125; 安装格式化插件 安装 JSFormat: ctrl+shift+p 进入sublime 命令面板，打开install package，输入jsformat，安装完成后重启sublime 选中代码，使用快捷键ctrl+alt+f即可快速格式化代码 删除插件 ctrl+shift+p，打开命令面板，搜索remove package 选中要删除的插件，确认即可 配置1234567891011&#123; \"font_face\": \"Monaco\", \"font_size\": 10, \"ignored_packages\":[], \"line_padding_top\": 3, // Additional spacing at the bottom of each line, in pixels \"line_padding_bottom\": 3, // translate tabs to four spaces \"translate_tabs_to_spaces\": false&#125; 仿照eclipse快捷键配置12345678910111213141516171819202122232425262728[ &#123; \"keys\": [\"f12\"], \"command\": \"htmlprettify\"&#125;, &#123; \"keys\": [\"f1\"], \"command\": \"fold\" &#125;, &#123; \"keys\": [\"f2\"], \"command\": \"unfold\" &#125;, &#123; \"keys\": [\"ctrl+l\"], \"command\": \"show_overlay\", \"args\": &#123;\"overlay\": \"goto\", \"text\": \"@\"&#125; &#125;, &#123; \"keys\": [\"ctrl+space\"], \"command\": \"auto_complete\" &#125;, &#123; \"keys\": [\"ctrl+space\"], \"command\": \"replace_completion_with_auto_complete\", \"context\": [ &#123; \"key\": \"last_command\", \"operator\": \"equal\", \"operand\": \"insert_best_completion\" &#125;, &#123; \"key\": \"auto_complete_visible\", \"operator\": \"equal\", \"operand\": false &#125;, &#123; \"key\": \"setting.tab_completion\", \"operator\": \"equal\", \"operand\": true &#125; ] &#125;, &#123; \"keys\": [\"ctrl+d\"], \"command\": \"run_macro_file\", \"args\": &#123;\"file\": \"Packages/Default/Delete Line.sublime-macro\"&#125; &#125;, &#123; \"keys\": [\"ctrl+shift+c\"], \"command\": \"toggle_comment\", \"args\": &#123; \"block\": false &#125; &#125;, &#123; \"keys\": [\"ctrl+shift+c\"], \"command\": \"toggle_comment\", \"args\": &#123; \"block\": true &#125; &#125;, &#123; \"keys\": [\"ctrl+shift+f\"], \"command\": \"reindent\" , \"args\": &#123;\"single_line\": false&#125;&#125;, &#123; \"keys\": [\"alt+up\"], \"command\": \"swap_line_up\" &#125;, &#123; \"keys\": [\"alt+down\"], \"command\": \"swap_line_down\" &#125;, &#123; \"keys\": [\"ctrl+alt+down\"], \"command\": \"duplicate_line\" &#125;, &#123; \"keys\": [\"shift+ctrl+r\"], \"command\": \"show_overlay\", \"args\": &#123;\"overlay\": \"goto\", \"show_files\": true&#125; &#125;, &#123; \"keys\": [\"ctrl+shift+s\"], \"command\": \"save_all\" &#125;, &#123; \"keys\": [\"ctrl+l\"], \"command\": \"show_overlay\", \"args\": &#123;\"overlay\": \"goto\", \"text\": \":\"&#125; &#125;, &#123; \"keys\": [\"shift+ctrl+f4\"], \"command\": \"close_all\" &#125;, &#123; \"keys\": [\"shift+ctrl+y\"], \"command\": \"lower_case\" &#125;, &#123; \"keys\": [\"shift+ctrl+x\"], \"command\": \"upper_case\" &#125;]","categories":[{"name":"工具","slug":"工具","permalink":"http://wzhongke.github.io/categories/工具/"}],"tags":[{"name":"工具","slug":"工具","permalink":"http://wzhongke.github.io/tags/工具/"}]},{"title":"shell 编程","slug":"linux/shell","date":"2017-08-19T09:52:00.000Z","updated":"2017-09-22T06:23:09.101Z","comments":true,"path":"2017/08/19/linux/shell/","link":"","permalink":"http://wzhongke.github.io/2017/08/19/linux/shell/","excerpt":"shell script虽然是程序，但是它处理数据的速度是不够的。因为shell用的是外部的命令bash shell的一些默认工具，所以它经常会调用外部的函数库。shell 经常被用来管理系统，而不是处理数据。","text":"shell script虽然是程序，但是它处理数据的速度是不够的。因为shell用的是外部的命令bash shell的一些默认工具，所以它经常会调用外部的函数库。shell 经常被用来管理系统，而不是处理数据。 shell程序执行有两种方式可以执行shell脚本： 直接命令执行：这种方式要求文件有rx权限 绝对路径 /home/user/shell.sh 相对路径 ./shell.sh 放到PATH路径下，直接执行 shell.sh 通过bash shell.sh或者 sh shell.sh来执行shell基本说明12345#!/bin/bash# Program: shell脚本用途说明# 修改时间，作者相关信息read -p \"name: \" nameecho -e \"\\nname is $name\" shell 脚本通常以#!/bin/bash 开头，来声明这个文件使用bash语法。在文件执行时，能够加载bash的相关环境配置文件 test测试命令test命令经常用来检测文件或者是其相关属性 检测文件类型 test -e filename 测试标志 代表含义 -e 该文件名是否存在 -f 该文件名是否存在且为文件 -d 该文件名是否存在且为目录 -L 该文件名是否存在且为一个连接文件 检测文件权限 test -r filename 测试标志 代表含义 -r 检测文件名是否存在且具有可读权限 -w 检测文件名是否存在且具有可写权限 -x 检测文件名是否存在且具有可执行权限 -u 检测文件名是否存在且具有SUID属性 -s 检测文件名是否存在且为 非空白文件 两个文件间比较 test file1 -nt file2 测试标志 代表含义 -nt (newer than) 判断file1是否比file2新 -ot (older than) 判断file1是否比file2旧 -ef 判断file1与file2是否为同一个文件，可用在hard link的判断上 整数之间的判断 test n1 -eq n2 测试标志 代表含义 -eq 两数值相等 -ne 两数值不相等 -gt n1 大于 n2 -lt n1 小于 n2 -ge n1 大于等于 n2 -le n1 小于等于 n2 判定字符串的数据 测试标志 代表含义 test -z string 判定字符串是否为0，若string为字符串，则为true test -n string 判定字符串是否为0，若string为字符串，则为false, -n可以省略 test st1 = str2 判断str1是否等于str2，若相等，则为true test st1 != str2 判断str1是否等于str2，若相等，则为false 多条件判定 test -r filename -a -x filename 测试标志 代表含义 -a 两个条件同时成立 -o 任何一个条件成立 ! 反向状态，not 使用判断符号 []可以使用[]来代替test进行判断1[ -z \"$HOME\" ] 使用[]必须要特别注意，在bash语法中使用时，必须要注意中括号内的每个组件都需要有空格键来分隔，中括号中的变量最好都以双引号括起来 shell脚本的默认变量向shell脚本中传递参数和获取参数的方法如下：12scriptname opt1 opt2 opt3 ...$0 $1 $2 $3 其他的一些参数： $# : 后接参数个数 $@ : 所有的参数shiftshift会移动变量，后面可以跟数字，表示一次移除多少变量 条件判断if ... then...if ... then... 是最常见的条件判断式。当只有一个判断要进行时，可以使用如下方式：123if [ 条件测试语句 ]; then 条件成立fi 可以通过&amp;&amp;或者||来分隔两个条件判断式，如：123if [ \"$yn\" == \"Y\" || \"$yn\" == \"y\"]; then \"do something\"fi 对于多重、复杂条件判断，可以用如下方式：1234567if [ 条件判断式一 ]; then \"do something\"elif [ 条件判断式二 ]; then \"do something\"else \"do something\"fi 使用 case...esac判断这种判断经常用来做固定字符串来执行某些操作的需求case 语法如下：12345678case $变量 in \"第一个变量内容\" ) \"do something\" ;; #需要用两个分号结尾 * ) 其他条件执行内容 ;;esac functionshell中函数的语法如下：123function fname () &#123; 'do some thing'&#125; 因为shell脚本的执行方式是由下而上的，由左而右的，因此，function的设置一定要在程序的最前面，这样才能在执行时被找到可用的程序段。function中也有内置变量，函数名为$0, 而后续连接的变量也是以$1, $2… 来代替的。1234567891011121314151617#!/bin/bashfunction print () &#123; echo \"Choice is $1\" &#125;echo \"This program will print your choice: \"case $1 in \"one\" ) print 1 ;; \"two\" ) print 2 ;; * ) echo \"Usage $0 (one|two)\" ;;esac 循环不定循环：while do done, util do done两种方式的循环如下：1234567891011# 当满足条件condition时，执行循环体while [ condition ]do 'do something'done# 当不满足条件时执行循环体until [condition]do 'do something'done 自加运算如下：1234567s=0i=0while [ \"$i\" != \"100\" ]do i=$(($i+1)) s=$(($s+$i))done for...do...done语法如下：123456789for var in con1 con2 con3 ...do 'do something'done# 第二种方式for ( ( 初始值; 限制数; 执行步长 ))do 'do something'done 可以对其他输出内容进行遍历123456789101112131415161718192021222324users=$( cut -d ':' -f1 /etc/passwd )for username in $usersdo id $username finger $usernamedone# 扫描网络network=\"192.168.1\"for sitenu in $(seq 1 100)do ping -c 1 -w 1 $&#123;network&#125;.$&#123;sitenu&#125; &amp;&gt; /dev/null &amp;&amp; result=0 || result=1 if [ \"$result\" == 0 ]; then echo \"Server $&#123;network&#125;.$&#123;sitenu&#125; is up\" fidone# 数值处理s=0nu=100for ( ( i=1; i&lt;=$nu; i=i+1))do s=$( ($s+$i))done shell脚本调试可以利用shell脚本参数来检查shell的正确性1234sh [-nvx] script.sh-n: 不执行script，只检查语法-v: 执行script前，将script内容输出到屏幕上-x: 将使用到的script内容显示到屏幕上 环境变量可以用 export 来将自定义变量转换成环境变量","categories":[{"name":"linux 编程","slug":"linux-编程","permalink":"http://wzhongke.github.io/categories/linux-编程/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://wzhongke.github.io/tags/linux/"}]},{"title":"vim 使用快捷键","slug":"linux/vim使用快捷键","date":"2017-08-14T18:51:00.000Z","updated":"2017-09-04T07:25:22.863Z","comments":true,"path":"2017/08/15/linux/vim使用快捷键/","link":"","permalink":"http://wzhongke.github.io/2017/08/15/linux/vim使用快捷键/","excerpt":"","text":"在我看来，vim是linux上内置的强大的文本编辑器。 基本操作vim有三种模式：一般模式、编辑模式和命令行模式。使用’i, I, o, O, a, A, r, R’按键可以从一般模式进入到编辑模式。使用’:, /, ?’按键可以从一般模式进入到命令行模式。通过[ESC]按键可以从其他模式进入到一般模式。 一般模式可用快捷键下面表格中的 n 都表示数字 光标移动 按键 说明 h或向左箭头(←) 光标向左移动一个字符 j或向下箭头(↓) 光标向下移动一个字符 k或向上箭头(↑) 光标向上移动一个字符 l或向下箭头(→) 光标向右移动一个字符 [ctrl + f] 屏幕向下移动一页，同[page down] [ctrl + b] 屏幕向上移动一页，同[page up] [ctrl + d] 屏幕向下移动半页 [ctrl + u] 屏幕向上移动半页 + 光标移动到非空格符的下一行 - 光标移动到非空格符的上一行 n [space] n 为数字，按下数字后，再按下空格，光标会向右移动这一行的n个字符 0 或 [Home] 光标移动到这行最前面字符处 $ 或 [End] 光标移动到这行最后面字符处 H 光标移动到这个屏幕的最上方那行的第一个字符处 M 光标移动到这个屏幕的中央的那行的第一个字符处 L 光标移动到这个屏幕的最下方的那行的第一个字符处 G 光标移动到这个文件的最后一行 nG 光标移动到这个文件的第n行 gg 光标移动到文件的第一行 N [enter] 光标向下移动n行 查找 按键 说明 :n1,n2s/word1/word2/g n1, n2为数字，在第n1与n2行之间查找word1，并将该字符串替换为word2 :1,$s/word1/word2/g 全文查找word1，并将该字符串替换为word2 :1,$s/word1/word2/gc 全文查找word1，并将该字符串替换为word2，需要用户确认 删除、复制、粘贴 按键 说明 x, X x为向后删除一个字符，X为向前删除一个字符 nx 连续向后删除n个字符 dd 删除光标所在行 ndd 删除光标所在的向下n行 d1G 删除光标所在到第一行的所有数据 dG 删除从光标所在到最后一行的所有数据 d$ 删除光标所在处到该行的最后一个字符 d0 删除光标所在处到该行最前面的一个字符 yy 复制光标所在的那一行 nyy 复制光标所在的向下n行 y1G 复制光标所在行到第一行的所有数据 yG 复制光标所在行到最后一行的所有数据 y0 复制光标所在的字符到该行行首的所有数据 y$ 复制光标所在的那个字符到该行行尾的所有数据 p, P p为将已复制的数据在光标下一行粘贴，P为粘贴在光标的上一行 J 将光标所在行与下一行的数据结合成同一行 c 重复删除多个数据，例如向下删除10行 [10cj] u 复原前一个操作 [ctrl + r] 重复上一个操作 . 重复前一个操作 命令行模式命令 按键 说明 :w 将编辑的数据写入硬盘文件中 :w! 强制写入，不一定成功 :q 离开文件 :q! 强制离开而不保存文件 :wq 或 :x 保存后离开 ZZ 若文件没有改动，则不保存离开，若文件已经被改动，则保存后离开 :w[filename] 将编辑的数据保存成另一个文件 :r[filename] 在编辑的数据中，读入另一个文件，并将数据加到光标所在行后面 :n1,n2 w[filename] 将n1到n2的内容保存成名为filename的文件 多窗口功能 使用大写的O参数来垂直分屏 1vim -O file1 file2 2.使用小写的o参数来水平分屏 1vim -o file1 file2 关闭当前窗口，不能关闭最后一个窗口 1ctrl+w c 关闭当前窗口，如果只剩下最后一个了，则退出vim 1ctrl+w q 上下分割当前打开的文件 1ctrl+w s 上下分割，并打开一个新的文件 1:sp filename 左右分割当前打开的文件 1Ctrl+w v 左右分割，并打开一个新的文件 1:vsp filename 9 把光标移到右边的屏 1Ctrl+w l 把光标移到左边的屏中 1Ctrl+w h 把光标移到上边的屏中 1Ctrl+w k 把光标移到下边的屏中 1Ctrl+w j 把光标移到下一个的屏中 1Ctrl+w w 向右移动屏幕 1Ctrl+W L 向左移动屏幕 1Ctrl+w H 向上移动屏幕 1Ctrl+w K 向下移动屏幕 1Ctrl+W J vim的一些设置vim设置内容往往通过修改~/.vimrc来进行一些默认的设置(其注释是 “)可以参考像 IDE 一样使用 vim12345678910111213141516171819202122232425262728293031323334353637383940414243&quot; 开启实时搜索功能set incsearch&quot; 搜索时大小写不敏感set ignorecase&quot; 关闭兼容模式set nocompatible&quot; vim 自身命令行模式智能补全set wildmenu&quot; 打开语法高亮syntax on&quot; &quot; 自适应不同语言的智能缩进filetype indent on&quot; 将制表符扩展为空格set expandtab&quot; 设置编辑时制表符占用空格数set tabstop=4&quot; 设置格式化时制表符占用空格数set shiftwidth=4&quot; 让 vim 把连续数量的空格视为一个制表符set softtabstop=4 set cindent&quot; 总是显示状态栏set laststatus=2&quot; 显示光标当前位置set ruler&quot; 开启行号显示set number&quot; 高亮显示当前行/列set cursorlineset cursorcolumn&quot; 高亮显示搜索结果set hlsearchset fenc=utf-8set fencs=utf-8,usc-bom,euc-jp,gb18030,gbk,gb2312,cp936set showmatch&quot; 禁止折行set nowrap&quot; 设置状态栏主题风格let g:Powerline_colorscheme=&apos;solarized256&apos;","categories":[{"name":"linux","slug":"linux","permalink":"http://wzhongke.github.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://wzhongke.github.io/tags/linux/"}]},{"title":"单例实现方式","slug":"java/单例实现方式","date":"2017-07-30T11:41:43.000Z","updated":"2017-09-30T07:35:37.506Z","comments":true,"path":"2017/07/30/java/单例实现方式/","link":"","permalink":"http://wzhongke.github.io/2017/07/30/java/单例实现方式/","excerpt":"有时候需要采用延迟初始化来降低初始化类和创建对象的开销。双重检查锁定是常见的延时初始化技术。 基于volatile的单例，双锁检测该方式中，必须使用volatile关键字来声明instance变量。因为对象的初始化代码可能会被重排序，也就是说instance在未初始化完成前，可能已经被其他线程访问。volatile标识符可以禁止这种重排序。","text":"有时候需要采用延迟初始化来降低初始化类和创建对象的开销。双重检查锁定是常见的延时初始化技术。 基于volatile的单例，双锁检测该方式中，必须使用volatile关键字来声明instance变量。因为对象的初始化代码可能会被重排序，也就是说instance在未初始化完成前，可能已经被其他线程访问。volatile标识符可以禁止这种重排序。12345678910111213public class Singleton &#123; private volatile static Singleton instance; public static Singleton getInstance() &#123; if (instance == null) &#123; synchronized (Singleton.class) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 基于类的单例在初次调用Instance.getInstance()时初始化Instance变量，利用语言的线程安全保证静态初始化，不需要额外的同步。123456789public class Instance &#123; private static class InstanceHolder &#123; public static Instance instance = new Instance(); &#125; public static Instance getInstance() &#123; return InstanceHolder.instance; &#125;&#125; 基于枚举类型的懒加载单例枚举类型使用私有的构造器，能够提供适当的序列化机制。他们也能以线程安全的方式懒初始化。JVM保证了枚举值不会被多次实例化，这使得单例模式有非常大的防御反射的攻击。这种方式是实现单例模式的推荐模式。12345678910111213public enum EnumSingleton&#123; INSTANCE; private EnumSingleton singleton; //JVM会保证此方法绝对只调用一次 Singleton()&#123; singleton = new EnumSingleton(); System.out.println(122); &#125; public EnumSingleton getInstance()&#123; return singleton; &#125;&#125;","categories":[{"name":"java","slug":"java","permalink":"http://wzhongke.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://wzhongke.github.io/tags/java/"}]},{"title":"青海湖四日游","slug":"青海四日游","date":"2017-07-22T19:42:25.000Z","updated":"2017-08-04T05:51:58.095Z","comments":true,"path":"2017/07/23/青海四日游/","link":"","permalink":"http://wzhongke.github.io/2017/07/23/青海四日游/","excerpt":"最近趁着女朋友暑假，去青海湖周边自驾旅游一次。不过开车经常会迎着或者侧对着太阳，必须做好防晒的准备 都说去青海，来回必须有一次交通方式是火车。因此，我们9号下午坐火车从北京出发，历经24小时到达西宁市。从天水站开始，沿途风景开始秀丽起来，可以通过欣赏景色来缓解旅途的无趣和疲惫。","text":"最近趁着女朋友暑假，去青海湖周边自驾旅游一次。不过开车经常会迎着或者侧对着太阳，必须做好防晒的准备 都说去青海，来回必须有一次交通方式是火车。因此，我们9号下午坐火车从北京出发，历经24小时到达西宁市。从天水站开始，沿途风景开始秀丽起来，可以通过欣赏景色来缓解旅途的无趣和疲惫。 西宁市 – 7.11从火车站下车后，我们直奔具有美食街之称的莫家街。很多网友都推荐了马忠食府，像一个食堂，充值拿卡，刷卡取餐，退卡返还余额。吃了大名鼎鼎的酿皮和酸奶，说实话感觉一般，没有传说中的那么好吃。随后在屈臣氏买了些面膜和洗面奶，西宁那边真的很晒，预先做好防护措施吧。回来之后，同事都说怎么没有晒黑。我们是在神州租车上预定的别克昂科拉。在附近随便找了家酒店–西宁元树花园酒店，是在小区里边的一个住宿地。可能是一层的缘故，被褥比较潮湿，环境也一般。安排好住宿的地后，我在周围找了下神州租车的具体位置，先踩好点，明天好提车。 日月山 – 7.12早上七点起来，收拾好东西，去神州租车顺利提车。这是我第一次开车上路，难免有些紧张。开始都不敢转弯，不敢停车，因此也没在西宁吃早饭。直接开车出了西宁，上了绕城高速。一直开车到湟源县城，顺便补了下早饭。如果不吃饭，店家还不让上他们的厕所。后来开车直接上了日月山，开阔的视野，美丽的风景，都让人煞是陶醉。因为昨天晚上被抢了被子，没有睡好，感觉头疼（后来才知道是高原反应），所以在日月山的停车场小歇，睡了会儿觉~ 青海湖 – 7.12日月山小歇后，驱车去青海湖。开车两个小时左右后（速度比较慢），终于看到了传说中的青海湖。在视野的尽头，碧水和青天连成一色，中间点缀着些许白色。我和湖之间是黄绿交织的。黄色的是盛开的油菜花，绿色的这边的主食青稞。路上时不时超过骑行的坚毅骑者。开车绕青海湖将近一半的路程，有不少上下坡的路段，有些还略陡，对绕湖骑行的人，愈发佩服。公路与油菜花之间是用简陋的铁丝网成片围起来的，找了家看着还不错的，在黄色的海洋中竖着一个牌子，写着“爱你一万年”。游览完油菜花，照完相片，驱车向里，走到了湖边。透过清澈的湖水，可以看到很多被一波波湖水磨掉棱角的不规则石头。顺着波纹，看到远处倒影的白云，在这里，可以分清湖与天之间的界限。天空碧澈如洗，完全远离了城市的喧嚣和雾霾。比较不爽的就是收费50，厕所也是收费的。 想体验一下游牧部落的蒙古包，预定了青海湖游牧部落酒店。百度地图导航到“青海湖游牧部落酒店”，开车到环湖西路十三公里左右的地方，本以为到了。因为高原反应，头已经比较疼了，也不想再继续开车，没想到导航地址应该是“青海湖黑马游牧部落酒店”，在环湖西路七十公里的地方。而且这时候亲爱的老婆，也有些高原反应，有些晕车，竟然吐了，我头更疼了。不过停车的地方，是碧水连着蓝天，中间没有一丝杂质，最适合看日出了。 可惜已经预定了酒店，舍不得那两百多块钱，而且这附近没有住宿的地，只能开车继续走。非常担心老婆的身体，只想着尽量开快些，这样让老婆少遭些罪。不觉间已经把速度提到将近100，也许是化担忧为力量，也许是挥发出自己未知的潜力，头不是那么疼了。否极泰来，半途中，老婆身体好转，开始能跟我闲聊了。到酒店已经将近晚上8点了，可是太阳还是高高在上，散发着热量。安排好住宿，吃完了烤羊肉，太阳开始慢慢落山了，真的是落山。日落把天空都染红了，整个草原都镀上了一层红色。随着太阳逐渐消散，黑暗慢慢蚕食光亮，气温也翻跟头地往下降，看着别人穿上厚厚的暖和的衣服，我和老婆只能缩到被窝里，积攒明天看日出的热量。还好热心的老板给我们准备了电热毯，否则，晚上真不知道怎么熬过去了。 没有搜日出时间，和老婆，早上5点就开车到了湖边，在车上开着暖风等了将近一个小时，还被一个老藏民用藏语啰里啰嗦地收了15块钱。不过为了看日出，这些都值了。看着太阳一点点挣脱束缚，跳出来，果真如老舍文章上写的那样，不同的是远处是慢慢的，由黑转亮的青山。没办法，找的看日出的位置不尽人意。 卡茶盐湖 – 7.13从青海湖游牧部落酒店出来，驾车一百五十多公里就到了号称“天空之境”的卡茶盐湖。湖名，估计是盛产盐而得来，所谓“茶卡”是藏语的“盐池”。开车近乎绕卡茶盐湖一圈才到了入口处。途中，可以看到和白云鬼混在一起的白色的卡茶盐湖。与青海湖的清亮透彻，小家碧玉不同，卡茶盐湖是洁白如雪，端庄肃穆，似乎诉说这它在古丝绸之路的辉煌。从远处可以清晰地看到山、云、人的倒影，大胆阐释了对称美。偶尔一阵波纹荡漾开来，倒影也开始娇羞起来，变得若隐若现。为了防止我们这些凡夫俗子玷污盐湖的圣洁，在可以下去的地方，是需要穿上鞋套的。来盐湖的路上，有当地人，顶着烈日，叫卖着鞋套。可惜当时不知道鞋套是何用处，遂没有管它。景区里边，鞋套却是需要15一双，贵了许多。为了近距离接触这座“天空之境”，忍痛买了两双。不过鞋套是防不住调皮的湖水的，在深些的地方，湖水还是跑进了鞋中。于是，将鞋袜脱下，扔在一旁，赤脚穿上鞋套。慢慢地踏进湖里，顿时感觉仿佛踩在了满是石子的不平整路上。从边缘处，躲避着黑色塌陷的无底洞，小心翼翼地向湖中心走去。云在水中的倒影，跟你玩起了你追我赶的游戏，总是不能把他们踩在脚下。老婆看着别人拍的彩色倒影的照片，很是羡慕，却是抓耳挠腮，不得其解。后来拉开了距离，才晓得高中学习的知识已经遗忘了，水的倒影和太阳产生的影子傻傻地分不清楚。 我们游玩的时间是下午2点到5点。太阳毫不留情地把热量挥洒到大地上，遮阳伞仿佛也受不了这种热情，只有盐湖在那静静地享受着。烤熟的大地，驱赶着几乎快要中暑的我们，只得匆匆告别了秀丽的卡茶盐湖。车子里已经被蒸的热气腾腾，赶紧打开车窗，把冷风调到最低，我们在车外贪婪地享受着片刻的清凉。 祁连山草原 – 7.144天的行程很紧，时间催促着我们赶往下一个景点–祁连山草原。从炽烈的阳光下，开车到伸手不见五指的黑夜，终于在晚上十点的时候，在青海湖旁的泉吉乡圣洁宾馆投宿。晚餐是在天峻县的兄弟茶餐厅，条件和饭菜都不错，能在县城碰上一个有品位的餐馆，也是有些惊喜的。在路程上来说应该先去卡茶盐湖的，只是提前预定了酒店的缘故，多跑了两百多公里。早上起来在一家南方人开的小店里边解决了早餐。跟老板聊了几句，才知道幸好是在老婆暑假的时候来旅游的。青海湖到了十月份左右，赶上冷空气从这边过，那时候整天北风呼啸，也开始缺起氧来，是待不下去的。大部分人会在那时候去其他地方过冬，很多热闹的营业商店，都会关掉，外来人是适应不了高原上的秋冬的，后来晚上住宿的老板也如是说。（回到北京，听同事说，十一的时候，也有好多人去青海湖，不过那时候需要把能穿的都穿上。因为那边山路比较多，估计自驾就很有挑战性了）吃完早饭，太阳就开始暴晒，不给人留一点清凉。顶着烈日行车，沿西莎线二十多公里处，有一片油菜花海。可以放心的停车，照相留念，没有人看管，也就无从收费。青海湖的油菜花却是也比不上这的，有一个小亭子，用木头搭建的，却是不遮光的。在此，可以俯瞰整个花海，在风中摇曳，一望无际。 继续行车，从一个特别小而难走的路，下了西莎线，进入了哈热段。与路途中的标语形成鲜明对比的，是凹凸不平，如羊肠小道的公路，时不时地还会有大坑给你惊喜。后来才知道，这样的路已经算是不错了。从哈热段上了省道204，到了盘大公路，才知道什么是山路，什么是山路十八弯，水路九连环。有很长一段公路是石子铺成的，更有甚者，就是比较宽敞的土路。慢速摇摇晃晃地通过，尤其是一段上山和下山的路，很多死弯。对于新手的我来说，都已经快绝望了，但也咬牙开出来了，给自己赞一个。 在途中会遇到挡路的绵羊，如果是正对着它们还好，如果要是从后面超车，那是要难死了，鸣笛是不管用的，只能耐心等它们的主人驱赶或者它们从公路上转移了。 从盘大公路转到西张线的时候，有一片空地可以休息。在这可以清楚地看到远处悠悠白云下白蒙蒙的雪山。由于严重低估了开车经过山路的时间，到达百度地图导航的祁连山草原，已经是下午4点多了。也许是前几天没有休息好，也许是有些高原反应，开车却是不行了。只得到峨堡镇的牧家住宿住下，随后在附近转悠下来。晚上终于是尝了手抓羊肉，或许是我舌头没那么敏感，对吃食兴趣不大，却是感觉味道一般。在旅店老板的推荐下，去了藏民家参观。路途上还有藏民收拾好的牦牛粪便，估计是用来烧的。他们住宿的地方很奇特，是自己搭建的帐篷，外边放着太阳能电池板。在门口周围是两堆东西，估计是晚上用来当门用的。帐篷的中间一个长条形的炉子，添加燃料的在一边，烧火的在另一边。他们是用羊粪当燃料的，炉子上边放着一大一小两个壶，是用来煮奶茶的。帐篷的顶部是留出长条形的一块。即可以看到蔚然的天空，也让炉子冒出的烟能顺利跑出去。牧民也比较健谈，聊了些风土人情，还给了我们些虫草（我们是后来才知道这个是冬虫夏草的），说是可以减轻高原反应。因为牧民忙着去收牦牛，所以没有能够穿上藏袍。他们用牦牛颈上的绳套绑到下面固定好的绳子上，防止晚上牦牛乱跑。 第二天，早上起来，老婆就兴冲冲的拉着我，要去穿藏袍。我们到的时候，藏民正忙着用一人环抱的大铁盆熬煮酸奶，看到旁边已经熬好了一盆了。不知道他们是要卖出去，还是怎么。藏民帮老婆打理好藏袍，戴上帽子和挂饰。迎着朝阳，挥动着裙子，煞是好看。 不过我们却是对所谓的祁连山草原失望起来，虽然周围都是草，但真没啥美景。后来才知道，这只是去张掖，七彩丹霞的必经之路，却算不上是美丽的草原。 卓尔山 –7.14从峨堡镇出发已经快十点了，主要是走的省道302，比昨天的路好走了许多。临近卓尔山的时候，就已经有零零星星的景点了。我们只在“林海听涛”的地方稍作停留，林是有的，不过涛却是悄悄溜走。在这可以清晰地看到远处的丹霞地貌，红绿相间，远处的雪山也若隐若现。 中午的时候，赶到了卓尔山，车不能直接开上去，只能放到免费的停车场。门票加往返车费总共八十，摆渡车B线是上山的，A线是下山的。稍等片刻，就坐车上山了。路途也有许多美景，近处的黄色的油菜花，绿色的青稞点缀其间，接着就是红褐色的健壮岩石，远处的雪山，像是蒙着白色丝巾的朦胧大姑娘。上山的路是由木头堆砌而成，虽然不陡峭，但是也可以看出当时花费了巨大的人力物力。 因为是顶着烈日爬山，高原上的紫外线也很强烈，秀色可餐的风景才能带来一丝慰藉。顺着木头铺成的路，一步步走到山顶，丝丝凉风拂面，带走了焦躁和困倦。山顶的起伏不大，可以绕山顶一圈，处处都是风景。从山顶上，可以俯视整个祁连县城，干净整洁，建筑与自然环境之间相辅相成，毫无违和感。建筑成功融入到自然景色之中，又成为其点睛之笔。这是座美丽的城市，是大自然的宠儿，在群山环抱中，八宝河静静流淌，让人有在此定居，从此不问世事，陶醉于美景的冲动。 从山顶的另一面，能够望到远处为皑皑白雪所覆盖的牛心山。因为还要回程，只能与卓尔山依依惜别。 无论如何都要从省道204走一遭，才能说去祁连山草原旅游过。从祁连县出城不远，就可以听到“林海听涛”的涛了。林间清澈见底的小溪水从石间欢快流过，吸引着过路的游客。捧一把溪水，调皮地从指缝间滑落，凉飕飕的。继续走，就到了海拔4120的大冬树山垭口。终于可以体会“会当凌绝顶，一览众山小”。凛冽的风从山顶吹过，吹走了仅留下的热量，远处黑乎乎的云压了过来，不敢久留，急匆匆踩上油门，跑了。 开车到吉龙沟附近，突然走进一副山水画里。画里面可以看到远处乌云下的青翠山脉，羊啊牛啊围着雪白的帐篷在欢乐地玩耍。一条小河从脚下静淌淌流过。我们像是那只掰棒子的熊，每一个可以泊车的地，都迫不及待地停车。期待前方有更美，更让人陶醉的景色，可又怕这是最后一处美景。走走停停，时间流逝太快，为了赶上投宿的地，只能一步三回头地慢慢开车走了。阳光从乌云缝隙里悄悄洒落，终是没有挣脱束缚，瓢盆大雨乍然惊现。大雨过后，彩虹偷偷在如洗的碧空中出现，沧桑劲壮的公路，构成一幅美丽画卷。就像卓尔山上的阿姨所说：如果我是一个画家，我就把眼前的景色画进画里；如果我是一个诗人，我就用最美丽的诗句，歌颂眼前的美景…。碧澈的天空，让人忍不住，仰天长啸。 旅行的时间总是过的那么快，转眼间，就到了离别的时候了。从八一路客运站坐大巴到曹家堡机场，还好飞机没有取消。看着西宁市慢慢变小，依依不舍。","categories":[{"name":"旅行","slug":"旅行","permalink":"http://wzhongke.github.io/categories/旅行/"}],"tags":[{"name":"旅行","slug":"旅行","permalink":"http://wzhongke.github.io/tags/旅行/"}]},{"title":"java中没有见过的用法","slug":"java/java中没有见过的用法","date":"2017-07-20T17:16:32.000Z","updated":"2017-08-22T02:33:54.796Z","comments":true,"path":"2017/07/21/java/java中没有见过的用法/","link":"","permalink":"http://wzhongke.github.io/2017/07/21/java/java中没有见过的用法/","excerpt":"interface &amp; interface在阅读Comparator源码时，无意间发现了如下这种用法：123456public static &lt;T, U extends Comparable&lt;? super U&gt;&gt; Comparator&lt;T&gt; comparing( Function&lt;? super T, ? extends U&gt; keyExtractor) &#123; Objects.requireNonNull(keyExtractor); return (Comparator&lt;T&gt; &amp; Serializable) (c1, c2) -&gt; keyExtractor.apply(c1).compareTo(keyExtractor.apply(c2));&#125;","text":"interface &amp; interface在阅读Comparator源码时，无意间发现了如下这种用法：123456public static &lt;T, U extends Comparable&lt;? super U&gt;&gt; Comparator&lt;T&gt; comparing( Function&lt;? super T, ? extends U&gt; keyExtractor) &#123; Objects.requireNonNull(keyExtractor); return (Comparator&lt;T&gt; &amp; Serializable) (c1, c2) -&gt; keyExtractor.apply(c1).compareTo(keyExtractor.apply(c2));&#125; 在这个方法中有 (Comparator&lt;T&gt; &amp; Serializable) 这样的用法。经过调研，发现是类型转换的意思，返回的结果被转换成实现Comparator和Serializable两个接口的实例。java中做强制转换时，对于类，只能指定一个；对于接口，能够指定无数个。","categories":[{"name":"java","slug":"java","permalink":"http://wzhongke.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://wzhongke.github.io/tags/java/"}]},{"title":"mybatis","slug":"java/mybatis","date":"2017-07-20T16:05:42.000Z","updated":"2017-09-14T02:07:07.852Z","comments":true,"path":"2017/07/21/java/mybatis/","link":"","permalink":"http://wzhongke.github.io/2017/07/21/java/mybatis/","excerpt":"MyBatis是什么MyBatis是定制化SQL、存储过程以及高级映射的持久层框架。MyBatis 可以对配置和原生Map使用简单的 XML 或注解，将接口和 Java 的 POJOs(Plain Old Java Objects,普通的 Java对象)映射成数据库中的记录。","text":"MyBatis是什么MyBatis是定制化SQL、存储过程以及高级映射的持久层框架。MyBatis 可以对配置和原生Map使用简单的 XML 或注解，将接口和 Java 的 POJOs(Plain Old Java Objects,普通的 Java对象)映射成数据库中的记录。 开始入门maven导入MyBatis包在pom.xml的dependencies下添加如下依赖：123456&lt;!-- https://mvnrepository.com/artifact/org.mybatis/mybatis --&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.4&lt;/version&gt;&lt;/dependency&gt; MyBatis是中心是SqlSessionFactory实例，该实例通过SqlSessionFactoryBuilder获得。SqlSessionFactoryBuilder可以通过XML配置或使用Configuration构建。 使用XML构建SqlSessionFactoryXML配置文件包含了MyBatis系统的核心配置，包含数据库连接实例的数据源和决定事务作用域和控制方式的事务管理器。下面是配置中比较关键的部分：1234567891011121314151617181920&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt; &lt;environments default=&quot;development&quot;&gt; &lt;environment id=&quot;development&quot;&gt; &lt;transactionManager type=&quot;JDBC&quot;/&gt; &lt;dataSource type=&quot;POOLED&quot;&gt; &lt;property name=&quot;driver&quot; value=&quot;$&#123;driver&#125;&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;$&#123;url&#125;&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;$&#123;username&#125;&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;$&#123;password&#125;&quot;/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;mappers&gt; &lt;mapper resource=&quot;mybatis/mapper/PersonMapper.xml&quot;/&gt; &lt;/mappers&gt;&lt;/configuration&gt; 要注意XML头部的声明，该声明用来验证XML文档正确性。environment元素中包含了事务管理和连接池的配置。mappers元素包含一组mapper映射器。我们可以通过Mybatis的一个Resources工具类从classpath或其他位置加载配置文件。123String resource = &quot;mybatis.xml&quot;;InputStream confStream = Resources.getResourceAsStream(resource);SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(confStream); 不使用XML构建SqlSessionFactory如果不想依赖配置构建程序，那么可以使用Java程序构建configuration，MyBatis提供了完全不用XML配置的类：123456DataSource dataSource = BlogDataSourceFactory.getBlogDataSource();TransactionFactory transactionFactory = new JdbcTransactionFactory();Environment environment = new Environment(&quot;development&quot;, transactionFactory, dataSource);Configuration configuration = new Configuration(environment);configuration.addMapper(BlogMapper.class);SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(configuration); 从SqlSessionFactory中获取SqlSessionSqlSession中包含了面向数据库执行SQL命令所有的方法，可以通过SqlSession实例来直接执行已经映射的SQL语句：123try (SqlSession session = sqlSessionFactory.openSession()) &#123; Person person = session.selectOne(&quot;mybatis.mapper.PersonMapper.selectPerson&quot;, 101);&#125; 上例中需要PersonMapper.xml配置项：12345&lt;mapper namespace=&quot;mybatis.mapper.PersonMapper&quot;&gt; &lt;select id=&quot;selectPerson&quot; resultType=&quot;mybatis.dao.Person&quot; parameterType=&quot;int&quot;&gt; SELECT * FROM Person WHERE id = #&#123;id&#125; &lt;/select&gt;&lt;/mapper&gt; 在一个XML映射文件中，可以定义任意多个映射语句，而且具有很好的自解释性。在命名空间mybatis.mapper.PersonMapper中定义了一个名为selectBlog的映射语句，这样就可以像上例中那样调用查询语句。我们还可以不使用XML配置，使用注解来实现同样的功能1234public interface PersonMapper &#123; @Select(&quot;SELECT * FROM blog WHERE id = #&#123;id&#125;&quot;) Person selectPerson(int id);&#125; 对于简单的语句，用Java注解简洁清晰；但是对于复杂的语句，就显得有些混乱，那么可以使用XML映射语句。这两种方式可以自由移植和切换。 作用域和生命周期 如果使用依赖注入的框架，如spring，则可以直接忽略他们的生命周期。因为这些框架可以创建线程安全的、基于事务的SqlSession和映射器，并将他们注入到bean中。 SqlSessionFactoryBuilder该类可以被实例化、使用和丢弃，一旦创建了SqlSessionFactory，就可以不再用它了。因此SqlSessionFactoryBuilder实例最佳作用域是局部变量。可以重用SqlSessionFactoryBuilder来创建多个SqlSessionFactory实例。但是不要让其一直存在，避免一直占有资源。 SqlSessionFactorySqlSessionFactory实例一旦创建，就应该在运行期间一直存在，对其清除和重建是浪费资源的。因此SqlSessionFactory的最佳作用域是应用级的，可以用单例模式或者静态单例模式创建 SqlSession每个线程都应该有它自己的 SqlSession 实例。SqlSession 的实例不是线程安全的，因此是不能被共享的，所以它的最佳的作用域是请求或方法作用域。绝对不能将 SqlSession 实例的引用放在一个类的静态域，甚至一个类的实例变量也不行。也绝不能将SqlSession实例的引用放在任何类型的管理作用域中。简单概括来说，就是使用之前，创建；使用完之后，马上关闭。SqlSession实现了Closeable，因此可以使用自动关闭的特性：123try (SqlSession session = sqlSessionFactory.openSession()) &#123; Person person = session.selectOne(&quot;mybatis.mapper.PersonMapper.selectPerson&quot;, 101);&#125; 映射器实例映射器是用来绑定映射语句的接口，该实例是从SqlSession中获取的，所以映射器的作用域同SqlSession相同，其最佳作用域是方法作用域。 XML映射配置文件MyBatis配置文件的层次结构如下12345678910111213-- configuration -- properties -- settings -- typeAliases -- typeHandlers -- objectFactory -- plugins -- environments -- environment -- transactionManager -- dataSource -- databaseIdProvider -- mappers properties这些属性相当于定义的变量，可以在Java属性文件中配置，也可以通过properties元素子元素传递：1234&lt;properties resource=&quot;jdbc.properties&quot;&gt; &lt;property name=&quot;username&quot; value=&quot;dev_user&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;F2Fa3!33TYyg&quot;/&gt;&lt;/properties&gt; 中期的属性可以在这个配置文件中使用：123456&lt;dataSource type=&quot;POOLED&quot;&gt; &lt;property name=&quot;driver&quot; value=&quot;$&#123;driver&#125;&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;$&#123;url&#125;&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;$&#123;username&#125;&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;$&#123;password&#125;&quot;/&gt;&lt;/dataSource&gt; 上例中username和password会由properties元素中相应的值来替换，driver和url属性取自jdbc.properties。如果在多个地方配置了属性，那么会按照下面对顺序来加载： 首先读取properties元素体内指定的属性 然后根据properties中的resource属性读取类路径下属性文件或根据url属性指定读取属性文件，并覆盖已读取的同名属性。 最后读取作为方法参数传递的属性，并覆盖已读取的同名属性。从MyBatis3.4.2开始，可以用占位符指定一个默认值。：123&lt;dataSource type=&quot;POOLED&quot;&gt; &lt;property name=&quot;username&quot; value=&quot;$&#123;username:ut_user&#125;&quot;/&gt; &lt;!-- 如果&apos;username&apos;不存在, username 取值为&apos;ut_user&apos; --&gt;&lt;/dataSource&gt; 这个特性默认是关闭的，需要在properties下，用指定的属性来开启此特性123&lt;properties&gt;&lt;property name=&quot;org.apache.ibatis.parsing.PropertyParser.enable-default-value&quot; value=&quot;true&quot;/&gt;&lt;/properties&gt; settings这是MyBatis中极为重要的调整设置，他们会改变MyBatis的运行时行为： 设置参数 描述 取值 默认值 cacheEnabled 该配置影响所有映射器中配置的缓存的全局开关 true/false true lazyLoadingEnabled 延迟加载的全局开关。当开启时，所有关联对象都会延迟加载。 特定关联关系中可通过设置fetchType属性来覆盖该项的开关状态. true/false false aggressiveLazyLoading 当开启时，任何方法的调用都会加载该对象的所有属性。否则，每个属性会按需加载（参考lazyLoadTriggerMethods). true\\false false (true in ≤3.4.1) multipleResultSetsEnabled 是否允许单一语句返回多结果集（需要兼容驱动） true\\false true useColumnLabel 使用列标签代替列名。不同的驱动在这方面会有不同的表现， 具体可参考相关驱动文档或通过测试这两种不同的模式来观察所用驱动的结果 true\\false true useGeneratedKeys 允许 JDBC 支持自动生成主键，需要驱动兼容。 如果设置为 true 则这个设置强制使用自动生成主键，尽管一些驱动不能兼容但仍可正常工作 true/false false autoMappingBehavior 指定 MyBatis 应如何自动映射列到字段或属性。 NONE 表示取消自动映射；PARTIAL 只会自动映射没有定义嵌套结果集映射的结果集。 FULL 会自动映射任意复杂的结果集（无论是否嵌套） NONE,PARTIAL,FULL PARTIAL autoMappingUnknownColumnBehavior 指定发现自动映射目标未知列（或者未知属性类型）的行为 NONE, WARNING, FAILING NONE defaultExecutorType 配置默认的执行器。SIMPLE 就是普通的执行器；REUSE 执行器会重用预处理语句（prepared statements）； BATCH 执行器将重用语句并执行批量更新 SIMPLE REUSE BATCH SIMPLE 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;settings&gt; &lt;!-- 该配置影响的所有映射器中配置的缓存的全局开关。 --&gt; &lt;setting name=\"cacheEnabled\" value=\"true\"/&gt; &lt;!-- 延迟加载的全局开关。当开启时，所有关联对象都会延迟加载。 特定关联关系中可通过设置fetchType属性来覆盖该项的开关状态。--&gt; &lt;setting name=\"lazyLoadingEnabled\" value=\"false\"/&gt; &lt;!-- 是否允许单一语句返回多结果集（需要兼容驱动）。 --&gt; &lt;setting name=\"multipleResultSetsEnabled\" value=\"true\"/&gt; &lt;!-- 使用列标签代替列名。不同的驱动在这方面会有不同的表现， 具体可参考相关驱动文档或通过测试这两种不同的模式来观察所用驱动的结果。 --&gt; &lt;setting name=\"useColumnLabel\" value=\"true\"/&gt; &lt;!-- 允许 JDBC 支持自动生成主键，需要驱动兼容。 如果设置为 true 则这个设置强制使用自动生成主键，尽管一些驱动不能兼容但仍可正常工作（比如 Derby）。 --&gt; &lt;setting name=\"useGeneratedKeys\" value=\"false\"/&gt; &lt;!-- 指定 MyBatis 应如何自动映射列到字段或属性。 NONE 表示取消自动映射； PARTIAL 只会自动映射没有定义嵌套结果集映射的结果集。 FULL 会自动映射任意复杂的结果集（无论是否嵌套）。--&gt; &lt;setting name=\"autoMappingBehavior\" value=\"PARTIAL\"/&gt; &lt;!-- 指定发现自动映射目标未知列（或者未知属性类型）的行为。 NONE: 不做任何反应 WARNING: 输出提醒日志 ('org.apache.ibatis.session.AutoMappingUnknownColumnBehavior' 的日志等级必须设置为 WARN) FAILING: 映射失败 (抛出 SqlSessionException) --&gt; &lt;setting name=\"autoMappingUnknownColumnBehavior\" value=\"WARNING\"/&gt; &lt;!-- 配置默认的执行器。 SIMPLE 就是普通的执行器； REUSE 执行器会重用预处理语句（prepared statements）； BATCH 执行器将重用语句并执行批量更新。 --&gt; &lt;setting name=\"defaultExecutorType\" value=\"SIMPLE\"/&gt; &lt;!-- 设置超时时间，它决定驱动等待数据库响应的秒数。(任意正整数) --&gt; &lt;setting name=\"defaultStatementTimeout\" value=\"25\"/&gt; &lt;!-- 为驱动的结果集获取数量（fetchSize）设置一个提示值。此参数只可以在查询设置中被覆盖。 --&gt; &lt;setting name=\"defaultFetchSize\" value=\"100\"/&gt; &lt;!-- 允许在嵌套语句中使用分页（RowBounds）。 If allow, set the false. --&gt; &lt;setting name=\"safeRowBoundsEnabled\" value=\"false\"/&gt; &lt;!-- 是否开启自动驼峰命名规则（camel case）映射，即从经典数据库列名 A_COLUMN 到经典 Java 属性名 aColumn 的类似映射。 --&gt; &lt;setting name=\"mapUnderscoreToCamelCase\" value=\"false\"/&gt; &lt;!-- MyBatis 利用本地缓存机制（Local Cache）防止循环引用（circular references）和加速重复嵌套查询。 默认值为 SESSION，这种情况下会缓存一个会话中执行的所有查询。 若设置值为 STATEMENT，本地会话仅用在语句执行上， 对相同 SqlSession 的不同调用将不会共享数据。 --&gt; &lt;setting name=\"localCacheScope\" value=\"SESSION\"/&gt; &lt;!-- 当没有为参数提供特定的 JDBC 类型时，为空值指定 JDBC 类型。 某些驱动需要指定列的 JDBC 类型， 多数情况直接用一般类型即可，比如 NULL、VARCHAR 或 OTHER。--&gt; &lt;setting name=\"jdbcTypeForNull\" value=\"OTHER\"/&gt; &lt;!-- 指定哪个对象的方法触发一次延迟加载。 --&gt; &lt;setting name=\"lazyLoadTriggerMethods\" value=\"equals,clone,hashCode,toString\"/&gt; &lt;!-- 指定 MyBatis 增加到日志名称的前缀。 --&gt; &lt;setting name=\"logPrefix\" value=\"mybatis\" /&gt;&lt;/settings&gt; typeAliases类型名是为Java类型设置一个短名字，只和XML配置有关，仅用来减少类完全限定名的冗余。比如：12345678&lt;typeAliases&gt; &lt;typeAlias alias=\"Author\" type=\"domain.blog.Author\"/&gt; &lt;typeAlias alias=\"Blog\" type=\"domain.blog.Blog\"/&gt; &lt;typeAlias alias=\"Comment\" type=\"domain.blog.Comment\"/&gt; &lt;typeAlias alias=\"Post\" type=\"domain.blog.Post\"/&gt; &lt;typeAlias alias=\"Section\" type=\"domain.blog.Section\"/&gt; &lt;typeAlias alias=\"Tag\" type=\"domain.blog.Tag\"/&gt;&lt;/typeAliases&gt; 这样，就可以在使用domain.blog.Blog的地方用Blog替换。还可以通过指定包名，来批量指定别名：123&lt;typeAliases&gt; &lt;package name=&quot;domain.blog&quot;/&gt;&lt;/typeAliases&gt; 这样每个在包domain.blog中的Java对象，在没有注解的情况下，会使用该对象的首字母小写的类名来作为它的别名。如domain.blog.Author的别名为author；如果有注解，那么以注解值为准。1234@Alias(\"author\")public class Author &#123; ...&#125; typeHandlers无论在处理预处理语句中设置一个参数时，还是从结果集中取出一个值时，都会用到类型处理器将获取的值以合适的方式转换成Java类型。这就是类型处理器。我们可以重写类型处理器或创建自己的类型处理器来处理不支持的或非标准的类型。具体做法：实现org.apache.ibatis.type.TypeHandler接口，或者继承类org.apache.ibatis.type.BaseTypeHandler，然后可以选择性地将它映射到一个JDBC类型：12345678910111213141516171819202122@MappedJdbcTypes(JdbcType.VARCHAR)public class ExampleTypeHandler extends BaseTypeHandler&lt;String&gt; &#123; @Override public void setNonNullParameter(PreparedStatement preparedStatement, int i, String s, JdbcType jdbcType) throws SQLException &#123; preparedStatement.setString(i, s); &#125; @Override public String getNullableResult(ResultSet resultSet, String columnName) throws SQLException &#123; return resultSet.getString(columnName); &#125; @Override public String getNullableResult(ResultSet resultSet, int columnIndex) throws SQLException &#123; return resultSet.getString(columnIndex); &#125; @Override public String getNullableResult(CallableStatement callableStatement, int columnIndex) throws SQLException &#123; return callableStatement.getString(columnIndex); &#125;&#125; 这个类需要在MyBatis的配置文件中配置：123&lt;typeHandlers&gt; &lt;typeHandler handler=\"org.mybatis.example.ExampleTypeHandler\"/&gt;&lt;/typeHandlers&gt; 使用这个的类型处理器将会覆盖已经存在的处理Java的String类型属性和VARCHAR参数及结果的类型处理器。 MyBatis不会探测数据库元信息来决定使用哪种数据类型，所以必须在参数和结果映射中指明那个是VARCHAR类型的字段，以便能够绑定到正确的类型处理器上。 通过类型处理器的泛型，MyBatis 可以得知该类型处理器处理的 Java 类型，不过这种行为可以通过两种方法改变： 在类型处理器的配置元素（typeHandler element）上增加一个 javaType 属性（比如：javaType=”String”）； 在类型处理器的类上（TypeHandler class）增加一个 @MappedTypes 注解来指定与其关联的 Java 类型列表。 如果在 javaType 属性中也同时指定，则注解方式将被忽略。 可以通过两种方式来指定被关联的 JDBC 类型： 在类型处理器的配置元素上增加一个 jdbcType 属性（比如：jdbcType=”VARCHAR”）； 在类型处理器的类上（TypeHandler class）增加一个 @MappedJdbcTypes 注解来指定与其关联的 JDBC 类型列表。 如果在 jdbcType 属性中也同时指定，则注解方式将被忽略。 我们还可以让MyBatis自动查找类型处理器，该方式只能通过注解方式来指定JDBC类型：1234&lt;!-- mybatis-config.xml --&gt;&lt;typeHandlers&gt; &lt;package name=\"org.mybatis.example\"/&gt;&lt;/typeHandlers&gt; 处理枚举类若想映射枚举类型Enum，则需要从EnumTypeHandler或者EnumOrdinalTypeHandler中选一个来使用。 对象工厂MyBatis 每次创建结果对象的新实例时，它都会使用一个对象工厂（ObjectFactory）实例来完成。 默认的对象工厂需要做的仅仅是实例化目标类，要么通过默认构造方法，要么在参数映射存在的时候通过参数构造方法来实例化。 如果想覆盖对象工厂的默认行为，则可以通过创建自己的对象工厂来实现。比如：1234567891011121314public class ExampleObjectFactory extends DefaultObjectFactory &#123; public Object create(Class type) &#123; return super.create(type); &#125; public Object create(Class type, List&lt;Class&gt; constructorArgTypes, List&lt;Object&gt; constructorArgs) &#123; return super.create(type, constructorArgTypes, constructorArgs); &#125; public void setProperties(Properties properties) &#123; super.setProperties(properties); &#125; public &lt;T&gt; boolean isCollection(Class&lt;T&gt; type) &#123; return Collection.class.isAssignableFrom(type); &#125;&#125; 1234&lt;!-- mybatis-config.xml --&gt;&lt;objectFactory type=\"org.mybatis.example.ExampleObjectFactory\"&gt; &lt;property name=\"someProperty\" value=\"100\"/&gt;&lt;/objectFactory&gt; 插件MyBatis允许你在已映射语句执行过程中的某一个点进行拦截调用。MyBatis允许使用插件拦截的调用有： Executor (update, query, flushStatements, commit, rollback, getTransaction, close, isClosed) ParameterHandler (getParameterObject, setParameters) ResultSetHandler (handleResultSets, handleOutputParameters) StatementHandler (prepare, parameterize, batch, update, query) 假设你想做的不仅仅是监控方法的调用，那么你应该很好的了解正在重写的方法的行为。 因为如果试图修改或重写已有方法，你很可能在破坏 MyBatis的核心模块。 这些都是更低层的类和方法，所以使用插件的时候要特别当心。使用插件，只需要实现Interceptor接口，并指定想要拦截的方法签名即可。1234567891011121314151617181920212223@Intercepts(&#123; @Signature( type = Executor.class, method = \"update\", args = &#123;MappedStatement.class, Object.class&#125; )&#125;)public class ExamplePlugin implements Interceptor &#123; @Override public Object intercept(Invocation invocation) throws Throwable &#123; return invocation.proceed(); &#125; @Override public Object plugin(Object o) &#123; return Plugin.wrap(o, this); &#125; @Override public void setProperties(Properties properties) &#123; &#125;&#125; 配置文件中需要增加：12345&lt;plugins&gt; &lt;plugin interceptor=\"org.mybatis.example.ExamplePlugin\"&gt; &lt;property name=\"someProperty\" value=\"100\"/&gt; &lt;/plugin&gt;&lt;/plugins&gt; 上面的插件将会拦截在Executor实例中所有的 “update” 方法调用，这里的Executor是负责执行低层映射语句的内部对象。 配置环境每个数据库应该对应至少一个SqlSessionFactory实例。MyBatis中有两种类型的事务管理器（type=&quot;[JDBC|MANAGED]&quot;) JDBC: 这个配置就是直接使用了JDBC的提交和回滚设置，它依赖于从数据源得到的连接来管理事物作用域 MANAGED：这个配置将管理事务的整个生命周期的任务交给了容器。默认情况下它会关闭连接，然而一些容器并不希望这样，因此需要将 closeConnection 属性设置为 false 来阻止它默认的关闭行为。例如:123&lt;transactionManager type=\"MANAGED\"&gt; &lt;property name=\"closeConnection\" value=\"false\"/&gt;&lt;/transactionManager&gt; 如果使用 Spring + MyBatis，则没有必要配置事务管理器， 因为 Spring 模块会使用自带的管理器来覆盖前面的配置。 dataSource 数据源有三种内建的数据源类型 (type=&quot;[UNPOLLED|POOLED|JNDI]&quot;) UNPOOLED：每次被请求时打开和关闭连接 POOLED: 利用数据库连接池，避免了创建新的连接实例时所需要的初始化和认证时间，有比较多的属性可以配置： poolMaximumActiveConnections: 最大连接数量 poolMaximumIdleConnections: 最大空闲连接数 poolMaximumCheckoutTime: 连接池中的连接被检出时间 poolTimeToWait: 这是一个底层设置，如果获取连接花费的相当长的时间，它会给连接池打印状态日志并重新尝试获取一个连接 poolPingQuery: 发送到数据库的侦测查询，用来检验连接是否处在正常工作秩序中并准备接受请求 poolPingEnabled: 是否启用侦测查询。默认值false，启用是必须设置一个可执行的SQL语句作为poolPingQuery的值 poolPingConnectionsNotUsedFor: 配置 poolPingQuery 的使用频度。 JNDI: 在EJB或应用服务器类容器中使用 Mapper XML映射文件XML SQL映射文件中有一下几个顶级元素： cache: 给定命名空间的缓存配置 cache-ref: 其他命名空间缓存配置的引用。 resultMap: 是最复杂也是最强大的元素，用来描述如何从数据库结果集中来加载对象。 sql: 可以被其他语句引用的重用块 insert: 插入语句 update: 更新语句 delete: 删除语句 select: 查询语句select查询是数据库操作中应用最频繁的语句。MyBatis简单的select非常简单：12","categories":[{"name":"sql","slug":"sql","permalink":"http://wzhongke.github.io/categories/sql/"}],"tags":[{"name":"sql","slug":"sql","permalink":"http://wzhongke.github.io/tags/sql/"}]},{"title":"Lambda表达式和Stream","slug":"java/Lambda表达式和Stream","date":"2017-07-20T12:14:12.000Z","updated":"2017-08-21T11:32:12.791Z","comments":true,"path":"2017/07/20/java/Lambda表达式和Stream/","link":"","permalink":"http://wzhongke.github.io/2017/07/20/java/Lambda表达式和Stream/","excerpt":"流被设计为与lambda表达式一起使用，这使得日常编程更容易。 Lambda 表达式匿名类的一个非常明显的问题是，如果匿名类的实现非常简单，例如只包含一个方法的接口，那么匿名类的语法可能看起来很笨重而且也不清晰。在这些情况下，可以将功能作为参数传递给另一种方法。Lambda表达式就是为此而生，它能够将功能视为方法参数或将代码作为数据。对于单一方法的实例，相对于匿名类，lambda表达式可以更紧凑地表示。","text":"流被设计为与lambda表达式一起使用，这使得日常编程更容易。 Lambda 表达式匿名类的一个非常明显的问题是，如果匿名类的实现非常简单，例如只包含一个方法的接口，那么匿名类的语法可能看起来很笨重而且也不清晰。在这些情况下，可以将功能作为参数传递给另一种方法。Lambda表达式就是为此而生，它能够将功能视为方法参数或将代码作为数据。对于单一方法的实例，相对于匿名类，lambda表达式可以更紧凑地表示。 使用Lambda表达式的理想情况假设要创建一个社交网络应用程序，想要创建一个功能，使管理员可以在符合特定条件的社交网络应用程序的成员上执行任何类型的操作（例如发送消息）。1234567891011public class Person &#123; public enum Sex &#123; MALE, FEMALE &#125; int age; String name; LocalDate birthday; Sex gender; String emailAddress; // getter和setter方法&#125; 1. 创建搜索符合某个特征成员的方法最简单的方式是创建几个方法，每个方法都负责搜索出满足某个特性的成员，比如性别或者年龄。123456public static void printPersonOlderThan(List&lt;Person&gt; roster, int age) &#123; for (Person p: roster) &#123; if (p.getAge() &gt;= age) p.printPerson(); &#125;&#125; 上面的方法可能使得应用程序变得脆弱，因为修改Person类，比如修改数据类型，就会导致程序无法正常工作。假设要升级程序，需要改变Person类的结构，增加了新的属性，也许还会改变衡量ages的数据类型或者算法。就需要根据这些修改重写API。 2. 创建一个更通用的搜索方法下面的方法更为通用，它打印了指定年龄段的成员12345678public static void printPersonsWithinAgeRange( List&lt;Person&gt; roster, int low, int high) &#123; for (Person p : roster) &#123; if (low &lt;= p.getAge() &amp;&amp; p.getAge() &lt; high) &#123; p.printPerson(); &#125; &#125;&#125; 如果想要打印指定性别的成员或者指定性别和特定年龄段的成员该怎么办？如果要改变Person类，比如添加一些关系状态或者地理位置的属性，要怎么修改？虽然这个方法比printPersonOlderThan更为通用，但是为不同可能的搜索请求，创建不同的方法，依然会使得代码脆弱。可以将指定要在其他类中搜索的条件的代码分开。 3. 在Local Class中指定搜索情况的代码下面的方法可以允许你指定搜索环境。12345678public static void printPersons( List&lt;Person&gt; roster, CheckPerson tester) &#123; for (Person p : roster) &#123; if (tester.test(p)) &#123; p.printPerson(); &#125; &#125;&#125; 上面的方法使用了CheckPerson的方法test检测了roster中每个Person实例，如果方法返回true，那么printPerson会被调用。可以通过实现CheckPerson接口来指定搜索条件123interface CheckPerson &#123; boolean test(Person p);&#125; 下面的类实现了CheckPerson接口，它的test方法过滤了年龄在18到25之间的男性1234567class CheckPersonEligible implements CheckPerson &#123; public boolean test(Person p) &#123; return p.gender == Person.Sex.MALE &amp;&amp; p.getAge() &gt;= 18 &amp;&amp; p.getAge() &lt;= 25; &#125;&#125; 可以通过新建一个该类的实例，传递给printPersons方法：1printPersons(roster, new CheckPersonEligible()); 虽然这个方式不那么脆弱，如果改变了Person的结构，就不必重新方法了，但是还是要有额外的代码：一个新的接口和新的搜索结果的类。因为CheckPersonEligible实现了接口，可以用一个匿名类代替这个类，这样可以不用为每次搜索都声明一个新类。 4. 使用匿名类12345678910printPersons( roster, new CheckPerson() &#123; public boolean test(Person p) &#123; return p.getGender() == Person.Sex.MALE &amp;&amp; p.getAge() &gt;= 18 &amp;&amp; p.getAge() &lt;= 25; &#125; &#125;); 这种方法减少了所需的代码量，不用每次执行时都创建一个新类。然而，匿名类的语法庞大。因为CheckPerson接口只包含一种方法。在这种情况下，可以使用lambda表达式而不是匿名类。 5. 使用Lambda表达式CheckPerson接口是一个函数式接口（functional interface)。函数式接口只包含一个抽象方法。函数式接口可以包含多个default methods和static methods。因为函数式接口只包含一个抽象方法，可以在实现该方法时省略该方法的名称。123456printPersons( roster, (Person p) -&gt; p.getGender() == Person.Sex.MALE &amp;&amp; p.getAge() &gt;= 18 &amp;&amp; p.getAge() &lt;= 25); 6. 使用标准的函数式接口CheckPerson是一个简单的函数式接口。该方法如此简单，没有必要在程序声明一次。因此，JDK中定义了几个标准的功能接口，可以在java.util.function包中找到它们。可以使用Predicate&lt;T&gt;接口替换CheckPerson，这个接口有一个方法boolean test(T t)123interface Predicate&lt;T&gt; &#123; boolean test(T t);&#125; 使用Predicate&lt;T&gt;接口替换CheckPerson，如下：123456printPersonsWithPredicate( roster, p -&gt; p.getGender() == Person.Sex.MALE &amp;&amp; p.getAge() &gt;= 18 &amp;&amp; p.getAge() &lt;= 25); 不止有这一种方式使用lambda表达式，下面的方式是推荐的方式 7. 在应用中使用Lambda表达式只有实现一个函数式接口，才能使用lambda表达式。如果想要使用另一个lambda表达式，该表达式接收一个参数，并且返回void，可以使用Consumer&lt;T&gt;接口，该接口有一个抽象方法void accept(T t).我们可以如下定义Person的方法：1234567public static void processPersons(List&lt;Person&gt; roster, Predicate&lt;Person&gt; tester, Consumer&lt;Person&gt; block) &#123; for (Person p: roster) &#123; if (tester.test(p)) &#123; block.accept(p ); &#125; &#125;&#125; 该方法可以用如下方式调用：1processPersons(roster, p -&gt; p.getAge() &gt;= 18, p -&gt; p.printPerson()); 如果你不止打印符合条件的信息，比如想要验证成员的信息或者获取他们的联系方式。需要一个有返回值的抽象方法的函数式接口。Function&lt;T,R&gt;包含一个方法R apply(T t)，下面的例子展示了通过mapper获取数据，并使用block处理数据的代码1234567891011public static void processPersonsWithFunction(List&lt;Person&gt; roster, Predicate&lt;Person&gt; tester, Function&lt;Person, String&gt; mapper, Consumer&lt;String&gt; block) &#123; for (Person p: roster) &#123; if (tester.test(p)) &#123; String data = mapper.apply(p); block.accept(data); &#125; &#125;&#125; 该方法可以用如下方式调用：12345678processPersonsWithFunction( roster, p -&gt; p.getGender() == Person.Sex.MALE &amp;&amp; p.getAge() &gt;= 18 &amp;&amp; p.getAge() &lt;= 25, p -&gt; p.getEmailAddress(), email -&gt; System.out.println(email)); 8. 使用泛型下面使用泛型的方法，可以接收任意数据类型的集合123456789101112public static &lt;X, Y&gt; void processElements ( Iterable&lt;X&gt; source, Predicate&lt;X&gt; tester, Function&lt;X, Y&gt; mapper, Consumer&lt;Y&gt; block ) &#123; for (X p: source) &#123; if (tester.test(p)) &#123; Y data = mapper.apply(p); block.accept(data); &#125; &#125;&#125; 上面的方法可以使用如下方式调用1234567processElements( roster, p -&gt; p.getAge() &gt;= 18 &amp;&amp; p.getAge() &lt;= 25, p -&gt; p.getEmailAddress(), email -&gt; System.out.println(email) ); 9. 使用接受Lambda表达式作为参数的聚合操作下面的例子使用聚合操作来打印email12345roster.stream(). filter( p -&gt; p.getAge() &gt;= 18 &amp;&amp; p.getAge() &lt;= 25) .map(p -&gt; p.getEmailAddress()) .forEach( email -&gt; System.out.println(email)); 接口 – 默认方法java8中在接口中可以定义默认方法，默认方法同抽象类中的非抽象方法类似，子类可以选择是否覆盖。这样就可以在接口中添加新的方法，而不用修改原有实现该接口的类。12345public interface DefaultInterface &#123; default String defaultMethod() &#123; return &quot;Default method&quot;; &#125;&#125; 接口的默认方法可以不用加public前缀，因为接口中的方法都是public的。还可以定义静态的方法，和类中的静态方法相同，都是与类相关联的，而不是它的实例。12345public interface DefaultInterface &#123; static String defaultMethod() &#123; return &quot;Static method&quot;; &#125;&#125; 默认方法可以向现有接口中添加支持lambda表达式作为参数的方法。 函数式接口@FunctionalInterface注解的接口是函数式接口。使用此种接口作为函数参数的方法，传递参数时，可以使用lambda表达式作为参数。12345public void sort(Comparator&lt;Card&gt; c) &#123; Collections.sort(entireDeck, c);&#125;// 可以这样调用deck.sort((firstCart, secondCard) -&gt; firstCart.getRank().value() - secondCard.getRank().value()); 如果只是创建一个Comparator实例来比较可以从诸如getValue或hashCode之类的方法返回数值的任何对象，我们可以使用Comparator接口提供的静态方法comparing123deck.sort(Comparator.comparing((card) -&gt; card.getRank())); // 还可以写成方法引用deck.sort(Comparator.comparing(Card::getRank)); Comparator还提供了comparingDouble、thenComparing等一系列方法来创建Comparator实例。如果要创建一个可以将对象的多个属性进行比较的Comparator实例，如下例：12345678910deck.sort( (firstCard, secondCard) -&gt; &#123; int compare = firstCard.getRank().value() - secondCard.getRank().value(); if (compare != 0) return compare; else return firstCard.getSuit().value() - secondCard.getSuit().value(); &#125; ); 我们可以使用Comparator接口提供的静态方法来创建实例1234deck.sort( Comparator .comparing(Card::getRank) .thenComparing(Comparator.comparing(Card::getSuit))); 方法引用我们使用lambda表达式来创建匿名方法。但是，有时候使用lambda表达式只是调用了一个方法。这种情况下，通过方法引用现有方法往往更加清晰。使用方法引用，可以使代码更紧凑，更易于阅读。如果对Person的数组根据age属性进行排序。或许可以使用下面的代码1234567class PersonAgeComparator implements Comparator&lt;Person&gt; &#123; public int compare(Person a, Person b) &#123; return a.getBirthday().compareTo(b.getBirthday()); &#125;&#125;Person[] rosterAsArray = roster.toArray(new Person[roster.size()]);Arrays.sort(rosterAsArray, new PersonAgeComparator()); sort方法的签名是static &lt;T&gt; void sort(T[] a, Comparator&lt;? super T&gt; c)。Comparator接口是函数式接口，所以我们可以使用lambda表达式代替PersonAgeComparator类：123Arrays.sort(rosterAsArray, (Person a, Person b) -&gt; a.getBirthday().compareTo(b.getBirthday())); 我们还可以定义Person的静态方法compareByAge:123public static int compareByAge(Person a, Person b) &#123; return a.birthday.compareTo(b.birthday);&#125; 那么上边的方法可以写成：123Arrays.sort(rosterAsArray, (a, b) -&gt; Person.compareByAge(a, b)); 因为lambda表达式调用了一个已经存在的方法，我们可以用方法引用：1Arrays.sort(rosterAsArray, Person::compareByAge); 使用方法引用由两个条件： 其形式参数列表从Comparator &lt;Person&gt; .compare复制，是(Person，Person)。也就是说方法引用的方法的参数类型需要同所需要的参数类型是一致的。 它的调用时Person.compareByAge方法应用的类型| 类型 | 示例:——–|:———–|应用静态方法| ContainingClass::staticMethodName|某个对象的方法| containingObject::instanceMethodName|引用特定类型的任意对象的实例方法|ContainingType::methodName|构造器方法|ClassName::new主要介绍下构造器方法：同静态方法引用类似，我们可以用new来使用构造器引用。以下方法将元素从一个集合复制到另一个集合：1234567891011public static &lt;T, SOURCE extends Collection&lt;T&gt;, DEST extends Collection&lt;T&gt;&gt; DEST transferElements( SOURCE sourceCollection, Supplier&lt;DEST&gt; collectionFactory) &#123; DEST result = collectionFactory.get(); for (T t : sourceCollection) &#123; result.add(t); &#125; return result;&#125; 函数式接口Supplier包含一个方法，其签名为T get()。可以通过如下方式调用该方法：123Set&lt;Person&gt; rosterSetLambda = transferElements(roster, () -&gt; &#123; return new HashSet&lt;&gt;(); &#125;);Set&lt;Person&gt; rosterSet = transferElements(roster, HashSet::new); 聚合操作聚合操作描述了以下管道的操作，它计算了集合roster中所有男性的平均年龄：123456double average = roster .stream() .filter(p -&gt; p.getGender() == Person.Sex.MALE) .mapToInt(Person::getAge) .average() .getAsDouble(); JDK中包含许多终止操作（如：average, sum, min, max 和 count），终止操作返回一个对流中数据计算的值。这些操作被称为归纳操作，也有些归纳操作返回一个集合。许多归纳操作执行像计算平局值或者将元素分类的操作。主要有两个方法： Stream.reduce类方法；Stream.collect类方法 Stream.reduce 方法Stream.reduce方法是通用的简化操作，比如下例中的Stream.sum归纳操作：1234Integer totlaAge = roster .stream() .mapToInt(Person::getAge) .sum(); 使用Stream.reduce操作也能实现上述操作：123456Integer totalAgeReduce = roster .stream() .map(Person::getAge) .reduce( 0, (a, b) -&gt; a + b); reduce操作需要两个参数： identity: 该参数是归纳操作的初始值，如果集合中没有元素，也是默认的返回值。 accumulator: 累加器函数需要两个参数：归纳的一部分结果和流的下一个元素。它返回一个新的部分结果。Stream.collect 方法collect方法会改变现有值。如果要计算一个stream中的平均值，需要两段数据：stream中的元素的总数和元素的和。与reduce类似，collect方法也只返回一个值。可以创建一个新的数据类型，跟踪元素的总数和这些元素的和：123456789101112131415class Averager implements IntConsumer&#123; private int total = 0; private int count = 0; public double average() &#123; return count &gt; 0 ? ((double) total)/count : 0; &#125; public void accept(int i) &#123; total += i; count++; &#125; public void combine(Averager other) &#123; total += other.total; count += other.count; &#125;&#125; 下面的管道使用了Average类和collect方法来计算男性成员的平均年龄：12345Averager averageCollect = roster.stream() .filter(p -&gt; p.getGender() == Person.Sex.MALE) .map(Person::getAge) .collect(Averager::new, Averager::accept, Averager::combine);System.out.println(&quot;Average age of male members: &quot; + averageCollect.average()); collect方法需要三个参数： supplier: 该参数需要一个工厂方法，它创建了新的实例。对于collect操作来说，它创建了放置结果的容器，就如Averager accumulator: 累加器功能将流元素结合到结果容器。在此示例中，它通过将count变量增加1来修改Averager结果容器，并将总成员变量添加到流元素的值，该元素是表示男性成员年龄的总和。 combiner: 组合器功能需要两个结果容器并合并其内容。虽然JDK为您提供了平均运算以计算流中元素的平均值，但如果需要从流的元素中计算多个值，则可以使用collect操作和自定义类。collect操作非常适合于集合。以下示例将男性成员的名字提取出来：12345List&lt;String&gt; namesOfMaleMembersCollect = roster .stream() .filter(p -&gt; p.getGender() == Person.Sex.MALE) .map(Person::getName) .collect(Collectors.toList()); 上述例子中，collect操作需要一个Collector类型的参数。该类中封装了collect所需要的三个参数。Collectors类中包含了许多有用的归纳操作，例如将元素累积到集合中并根据各种标准汇总元素。这些归纳操作返回Collector的实例，可以用他们作为collect操作的参数。上例中的Collectors.toList将流元素累加到List的新实例中。toList操作返回了一个Collector实例，而不是一个集合。下例中将roster集合元素根据性别归类：12Map&lt;Person.Sex, List&lt;Person&gt;&gt; byGender = roster.stream() .collect(Collectors.groupingBy(Person::getGender)); 下例中根据性别将集合中元素的名字归类：12345678Map&lt;Person.Sex, List&lt;String&gt;&gt; namesByGender = roster.stream() .collect( Collectors.groupingBy( Person::getGender, Collectors.mapping( Person::getName, Collectors.toList()))); 以下示例检索每个性别成员的总年龄：123456789Map&lt;Person.Sex, Integer&gt; totalAgeByGender = roster.stream() .collect( Collectors.groupingBy( Person::getGender, Collectors.reducing( 0, Person::getAge, Integer::sum))); 以下示例检索每个性别成员的平均年龄：123456Map&lt;Person.Sex, Double&gt; averageAgeByGender = roster .stream() .collect( Collectors.groupingBy( Person::getGender, Collectors.averagingInt(Person::getAge))); 并行处理流并行计算包括将问题分解为子问题，同时解决这些问题（并行地，每个子问题在单独的线程中运行），然后将解决方案的结果组合。Java中有fork/join框架可以轻松地在应用程序中实现并行计算，不过需要问题是怎么分解成子问题的。在聚合操作中，Java运行时会自动处理分解和组合问题。在应用程序中实现并行计算的一个主要难点是使用的集合不是线程安全的，这意味着多线程会导致线程之间的干扰或者内存一致性错误。集合框架提供了同步包装方法，可以通过包装任意集合，让他们成为线程安全的。但是，这会引入线程竞争，使得线程不能并行计算。聚合操作和并行处理流可以并行处理线程不安全的集合，而不用我们做修改。 并行性并不会自动快于连续执行操作，即使有足够的数据和处理器内核，并行性也不会快。 虽然集合操作能够更轻松地实现并行性，但我们仍要确定应用程序是否适合并行性。我们可以自己选择串行或者并行执行流。如果需要并行执行流，那么需要使用指定的方法：Collection.parallelStream.123456double average = roster .parallelStream() .filter(p -&gt; p.getGender() == Person.Sex.MALE) .mapToInt(Person::getAge) .average() .getAsDouble(); 并行归纳下例是我们串行处理流12345Map&lt;Person.Sex, List&lt;Person&gt;&gt; byGender = roster .stream() .collect( Collectors.groupingBy(Person::getGender)); 其并行处理如下例：12345ConcurrentMap&lt;Person.Sex, List&lt;Person&gt;&gt; byGender = roster .parallelStream() .collect( Collectors.groupingByConcurrent(Person::getGender)); 用groupingByConcurrent代替了groupingBy，返回结果也有Map变为ConcurrentMap.","categories":[{"name":"java","slug":"java","permalink":"http://wzhongke.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://wzhongke.github.io/tags/java/"}]},{"title":"java线程池技术","slug":"java/Java线程池技术","date":"2017-07-03T19:01:11.000Z","updated":"2017-08-04T05:51:58.064Z","comments":true,"path":"2017/07/04/java/Java线程池技术/","link":"","permalink":"http://wzhongke.github.io/2017/07/04/java/Java线程池技术/","excerpt":"服务器在处理客户端请求时，经常面对的是客户端的任务简单，单一。如果针对每个任务，都创建一个线程执行，那么对于成千上万的客户端任务，服务器会创建数以万计的线程。这会使得操作系统频繁地进行线程的上下文切换，增加系统负载，浪费系统资源。线程池技术很好地解决了这个问题，它预先创建了若干个线程。用这些线程处理客户端提交的任务，避免了频繁的线程创建和销毁的系统开销。 下面是一个简单的线程池接口定义12345678public interface ThreadPool&lt;Job extends Runnable&gt; &#123; // 执行一个Job，这个Job需要实现Runnable void execute(Job job); void shutdown(); void addWorkers(int num); void removeWorkers(int num); int getJobSize();&#125;","text":"服务器在处理客户端请求时，经常面对的是客户端的任务简单，单一。如果针对每个任务，都创建一个线程执行，那么对于成千上万的客户端任务，服务器会创建数以万计的线程。这会使得操作系统频繁地进行线程的上下文切换，增加系统负载，浪费系统资源。线程池技术很好地解决了这个问题，它预先创建了若干个线程。用这些线程处理客户端提交的任务，避免了频繁的线程创建和销毁的系统开销。 下面是一个简单的线程池接口定义12345678public interface ThreadPool&lt;Job extends Runnable&gt; &#123; // 执行一个Job，这个Job需要实现Runnable void execute(Job job); void shutdown(); void addWorkers(int num); void removeWorkers(int num); int getJobSize();&#125; 客户端可以通过execute来将任务提交到线程池。线程池提供了减少/增大工作线程以及关闭线程的方法。这里工作线程代表着一个重复执行Job的线程，每个有客户端提交的Job都将进入到一个工作队列中，等待工作线程处理。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135package com.wang.chapter4.threadpool;import java.util.*;import java.util.concurrent.atomic.AtomicLong;/** * Created by 王忠珂 on 2016/11/23. */public class DefaultThreadPool&lt;Job extends Runnable&gt; implements ThreadPool&lt;Job&gt; &#123; // 线程最大限制数 private static int maxWorkerNumber = 10; // 线程池默认的数量 private static int defaultWorkerNumbers = 5; // 线程池最小数量 private static int minWorkerNumbers = 1; // 工作列表 private final LinkedList&lt;Job&gt; jobs = new LinkedList&lt;Job&gt;(); // 工作者列表 private final List&lt;Worker&gt; workers = Collections.synchronizedList(new ArrayList&lt;Worker&gt;()); // 工作者线程的数量 private int workerNum = defaultWorkerNumbers; // 线程编号 private AtomicLong threadNum = new AtomicLong(); public DefaultThreadPool() &#123; initializeWorkers(defaultWorkerNumbers); &#125; public DefaultThreadPool(int num) &#123; workerNum = num &gt; maxWorkerNumber ? maxWorkerNumber : num &lt; minWorkerNumbers ? minWorkerNumbers : num; initializeWorkers(workerNum); &#125; public DefaultThreadPool(int defaultWorkerNumber, int maxWorkerNumber, int minWorkerNumber) &#123; this.maxWorkerNumber = maxWorkerNumber; this.minWorkerNumbers = minWorkerNumber; workerNum = defaultWorkerNumber &gt; maxWorkerNumber ? maxWorkerNumber : defaultWorkerNumber &lt; minWorkerNumbers ? minWorkerNumbers : defaultWorkerNumber; initializeWorkers(workerNum); &#125; @Override public void execute(Job job) &#123; if (job != null) &#123; synchronized (jobs) &#123; jobs.addLast(job); jobs.notify(); &#125; &#125; &#125; @Override public void shutdown() &#123; for (Worker worker: workers) &#123; worker.shutdown(); &#125; &#125; @Override public void addWorkers(int num) &#123; synchronized (jobs) &#123; if (num + this.workerNum &gt; maxWorkerNumber) &#123; num = maxWorkerNumber - this.workerNum; &#125; initializeWorkers(num); this.workerNum += num; &#125; &#125; @Override public void removeWorkers(int num) &#123; synchronized (jobs) &#123; if (num &gt;= this.workerNum) &#123; throw new IllegalArgumentException(\"beyond workNum\"); &#125; int count = 0; while (count &lt; num) &#123; Worker worker = workers.get(count); if (workers.remove(worker)) &#123; worker.shutdown(); count ++; &#125; &#125; this.workerNum -= count; &#125; &#125; @Override public int getJobSize() &#123; return jobs.size(); &#125; private void initializeWorkers (int num) &#123; for (int i=0; i&lt;num; i++) &#123; Worker worker = new Worker(); workers.add(worker); Thread thread = new Thread(worker, \"ThreadPool-Worker-\" + threadNum.incrementAndGet()); thread.start(); &#125; &#125; class Worker implements Runnable &#123; // 是否工作 private volatile boolean running = true; public void run() &#123; while (running)&#123; Job job = null; synchronized (jobs) &#123; while (jobs.isEmpty()) &#123; try &#123; jobs.wait(); &#125; catch (InterruptedException e) &#123; Thread.currentThread().interrupt(); return; &#125; &#125; // 取出一个Job job = jobs.removeFirst(); &#125; if (job != null) &#123; try &#123; job.run(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; public void shutdown() &#123; running = false; &#125; &#125;&#125;","categories":[{"name":"java","slug":"java","permalink":"http://wzhongke.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://wzhongke.github.io/tags/java/"}]},{"title":"svg动画","slug":"svg动画","date":"2017-07-02T19:42:25.000Z","updated":"2017-09-02T05:10:15.604Z","comments":true,"path":"2017/07/03/svg动画/","link":"","permalink":"http://wzhongke.github.io/2017/07/03/svg动画/","excerpt":"svg 字体动画","text":"svg 字体动画 .center-btn-wrapper { width: 100%; top: 50%; text-align: center; font-size: 24px; } .center-btn-wrapper a { color: white; text-decoration: none; text-shadow: 1px 1px 1px rgba(0, 0, 0, 0.42); background-color: #D87B00; padding: 12px 30px; border-radius: 5px; } .center-btn-wrapper a:hover { background-color: #14516F; } /* 手机适配 */ @media screen and (max-width: 768px) { .center-btn-wrapper { font-size: 18px; } } /* 暂时隐藏CNZZ统计按钮 */ span.cnzz-wrapper { display: none; } #svg { display: block; margin: 0 auto; } #svg path { /*虚线长度足够长，至少要大于整个path的长度*/ stroke-dasharray: 3498; -webkit-animation: dash 15s linear infinite alternate; animation: dash 15s linear infinite alternate; } @-webkit-keyframes dash { 0%{stroke-dashoffset: 3498;stroke-dasharray: 3498;stroke:red;} 50%{stroke-dashoffset: 0;stroke-dasharray: 20;stroke:#D302D6;} 100%{stroke-dashoffset: 1000;stroke-dasharray: 20;stroke:green;} } @keyframes dash { 0%{stroke-dashoffset: 3498;stroke-dasharray: 3498;stroke:red;} 50%{stroke-dashoffset: 0;stroke-dasharray: 20;stroke:#D302D6;} 100%{stroke-dashoffset: 1000;stroke-dasharray: 20;stroke:green;} } Layer 1 css源代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647.center-btn-wrapper &#123; width: 100%; top: 50%; text-align: center; font-size: 24px;&#125;.center-btn-wrapper a &#123; color: white; text-decoration: none; text-shadow: 1px 1px 1px rgba(0, 0, 0, 0.42); background-color: #D87B00; padding: 12px 30px; border-radius: 5px;&#125;.center-btn-wrapper a:hover &#123; background-color: #14516F;&#125;/* 手机适配 */@media screen and (max-width: 768px) &#123; .center-btn-wrapper &#123; font-size: 18px; &#125;&#125;/* 暂时隐藏CNZZ统计按钮 */span.cnzz-wrapper &#123; display: none;&#125;#svg &#123; display: block; margin: 0 auto;&#125;#svg path &#123; /*虚线长度足够长，至少要大于整个path的长度*/ stroke-dasharray: 3498; -webkit-animation: dash 15s linear infinite alternate; animation: dash 15s linear infinite alternate;&#125;@-webkit-keyframes dash &#123; 0%&#123;stroke-dashoffset: 3498;stroke-dasharray: 3498;stroke:red;&#125; 50%&#123;stroke-dashoffset: 0;stroke-dasharray: 20;stroke:#D302D6;&#125; 100%&#123;stroke-dashoffset: 1000;stroke-dasharray: 20;stroke:green;&#125;&#125;@keyframes dash &#123; 0%&#123;stroke-dashoffset: 3498;stroke-dasharray: 3498;stroke:red;&#125; 50%&#123;stroke-dashoffset: 0;stroke-dasharray: 20;stroke:#D302D6;&#125; 100%&#123;stroke-dashoffset: 1000;stroke-dasharray: 20;stroke:green;&#125;&#125; html源码123456789&lt;div class=\"center-btn-wrapper\"&gt; &lt;svg id=\"svg\" xmlns=\"http://www.w3.org/2000/svg\" height=\"404\" width=\"452\"&gt; &lt;g&gt; &lt;title&gt;Layer 1&lt;/title&gt; &lt;!-- path 是用svg工具生成的 --&gt; &lt;path fill-opacity=\"null\" stroke-opacity=\"null\" stroke-width=\"3\" stroke=\"#41ABF7\" fill=\"none\" d=\"m31.919427,29.815911c0,0 323.1068,0.991126 323.1068,0.991126c0,0 31.716006,-27.751503 31.716006,-27.751503c0,0 43.609516,49.556251 43.609516,49.556251c0,0 -185.34041,0 -185.34041,0c0,0 0,141.730913 0,141.730913c0,0 96.139145,0 95.643186,-0.00002c0.495959,0.00002 25.274085,-24.778126 25.274085,-24.778126c0,0 39.645013,46.582894 39.645013,46.582894c0,0 -160.562284,0.991126 -160.562284,0.991126c0,0 0,154.615509 0,154.615509c0,0 139.748642,0 139.748642,0c0,0 26.760377,-26.760377 26.760377,-26.760377c0,0 42.618391,48.565145 42.618391,48.565145c0,0 -401.405681,-1.982252 -401.405681,-1.982252c0,0 -14.866887,2.973377 -14.866887,2.973377c0,0 -14.866868,2.973377 -14.866868,2.973377c0,0 -21.804748,-25.769271 -21.804748,-25.769271c0,0 204.171761,-0.991126 204.171761,-0.991126c0,0 0,-154.615509 0,-154.615509c0,0 -84.245635,-0.991126 -84.245635,-0.991126c0,0 -15.857993,0 -15.857993,0c0,0 -11.89351,1.982252 -11.89351,1.982252c0,0 -13.875742,1.982252 -13.875742,1.982252c0,0 -21.804748,-22.795894 -21.804748,-22.795894c0,0 147.677629,-0.991106 147.677629,-0.991106c0,0 0,-143.713145 0,-143.713145c0,0 -118.935,-0.991126 -118.935,-0.991126c0,0 -29.733755,3.964483 -29.733755,3.964483c0,0 -6.937881,2.973377 -6.937881,2.973377c0,0 -17.840265,-27.751503 -17.840265,-27.751503z\" id=\"svg_8\"/&gt; &lt;/g&gt; &lt;/svg&gt;&lt;/div&gt;","categories":[{"name":"svg","slug":"svg","permalink":"http://wzhongke.github.io/categories/svg/"}],"tags":[{"name":"svg","slug":"svg","permalink":"http://wzhongke.github.io/tags/svg/"}]},{"title":"缓存算法","slug":"algorithms/缓存算法","date":"2017-06-30T11:41:43.000Z","updated":"2017-08-04T05:51:58.095Z","comments":true,"path":"2017/06/30/algorithms/缓存算法/","link":"","permalink":"http://wzhongke.github.io/2017/06/30/algorithms/缓存算法/","excerpt":"众所周知，内存的读取速度比硬盘类存储设备快的多。为了降低硬件设备的负载，提高响应速度，增加吞吐率，我们可以将最近使用过，并且将来还要使用的数据缓存到内存中。因为内存的容量是有限的，所以根据怎么选择将来还要使用的数据，产生了各种缓存算法。 一些术语 命中：当客户发起一个请求，如果在缓存中，就成为缓存命中 Cache Miss：如果还有缓存空间，没有命中的就会被存储到缓存中；如果缓存满了，而又没命中缓存，那么久会按照缓存算法，用新对象替换旧对象。 存储成本：将数据放到缓存所需要的时间和空间 失效：当存在缓存中的数据需要更新时，缓存中的这个数据就失效了 Least Frequently Used (LFU):LFU算法认为：如果一个数据在最近一段时间内使用次数很少，那么在将来一段时间内被使用的可能性也很小。 命中率LFU的命中率还要看数据的访问顺序。一旦访问内容发生较大的变化，LFU需要更长的时间来适应。因为他是根据频率来淘汰数据的，新的数据访问频率低，很容易被淘汰掉。这样会导致之前经常而现在不被访问的数据，一直赖在缓存中。所以，一般相比LFU，会采用LRU算法","text":"众所周知，内存的读取速度比硬盘类存储设备快的多。为了降低硬件设备的负载，提高响应速度，增加吞吐率，我们可以将最近使用过，并且将来还要使用的数据缓存到内存中。因为内存的容量是有限的，所以根据怎么选择将来还要使用的数据，产生了各种缓存算法。 一些术语 命中：当客户发起一个请求，如果在缓存中，就成为缓存命中 Cache Miss：如果还有缓存空间，没有命中的就会被存储到缓存中；如果缓存满了，而又没命中缓存，那么久会按照缓存算法，用新对象替换旧对象。 存储成本：将数据放到缓存所需要的时间和空间 失效：当存在缓存中的数据需要更新时，缓存中的这个数据就失效了 Least Frequently Used (LFU):LFU算法认为：如果一个数据在最近一段时间内使用次数很少，那么在将来一段时间内被使用的可能性也很小。 命中率LFU的命中率还要看数据的访问顺序。一旦访问内容发生较大的变化，LFU需要更长的时间来适应。因为他是根据频率来淘汰数据的，新的数据访问频率低，很容易被淘汰掉。这样会导致之前经常而现在不被访问的数据，一直赖在缓存中。所以，一般相比LFU，会采用LRU算法 Least Recently Used (LRU):LRU算法认为：如果数据最近被访问过，那么将来被访问的几率也更高。 LRU算法将最近最少使用的数据淘汰。最近使用的数据会被放到缓存的顶部，当缓存达到容量上限时，将底部的数据移除。 命中率如果存在热点数据，LRU的命中率比较高。但是针对偶然性、周期性或者随机性的批量操作会导致LRU的命中率急剧下降，缓存污染情况也比较严重。 复杂度实现简单，java中可以通过扩展LinkedHashMap来实现。1234567891011121314151617181920import java.util.LinkedHashMap;import java.util.Map;//扩展LinkedHashMap，实现LRUpublic class LRUCache&lt;K,V&gt; extends LinkedHashMap&lt;K,V&gt;&#123; //定义缓存的容量 private int capacity; private static final long serialVersionUID = 1L; //带参数的构造器 public LRUCache(int capacity)&#123; //调用LinkedHashMap的构造器，传入以下参数 super(capacity); this.capacity=capacity; &#125; //实现LRU的关键方法，如果map里面的元素个数大于了缓存最大容量，则删除链表的顶端元素 @Override public boolean removeEldestEntry(Map.Entry&lt;K, V&gt; eldest)&#123; System.out.println(eldest.getKey() + &quot;=&quot; + eldest.getValue()); return size() &gt; capacity; &#125;&#125; Least Recently Used 2 (LRU2)：LRU2算法认为：将被两次访问过的对象放入缓存池，当缓存池满了，会移除两次最少使用的缓存对象。因为要跟踪对象两次，访问负载就会随着缓存池的增加而增加，所以不能用于大容量的缓存池。 Two Queues (2Q)：将被访问的数据放到LRU的缓存中，如果这个对象再一次被访问，就将它转移到更大的LRU缓存中。移除对象是为了保持第一个缓存池是第二个缓存池的1/3，当缓存访问负载是固定的时候，把LRU换成LRU2，比增加缓存容量更好，是adoptive to access模式 Adaptive Replacement Cache (ARC):介于LRU和LFU之间。由两个LRU组成，第一个L1，包含的条目是最近值被使用过一次的，而L2，包含的是最近被使用过两次的数据。L1放的是新对象，L2放的是常用对象。 Most Recently Used (MRU):移除最近最多被使用的对象。每当一次缓存记录的使用，就会被放到栈顶，当栈满了，将栈顶的对象移除。 First In First Out (FIFO):先进先出，低负载的算法，通过队列跟踪所有的缓存对象，最近最常用的对象放在后边，当缓存容量满的时，会移除前边缓存的更早的对象。很快，但是不适用","categories":[{"name":"算法","slug":"算法","permalink":"http://wzhongke.github.io/categories/算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://wzhongke.github.io/tags/算法/"}]},{"title":"一些有价值的参考网站","slug":"有价值的参考网站","date":"2017-06-30T11:41:43.000Z","updated":"2017-10-20T07:48:05.938Z","comments":true,"path":"2017/06/30/有价值的参考网站/","link":"","permalink":"http://wzhongke.github.io/2017/06/30/有价值的参考网站/","excerpt":"","text":"nginx配置之location及rewrite阿里巴巴java开发规约-IDEA插件","categories":[{"name":"other","slug":"other","permalink":"http://wzhongke.github.io/categories/other/"}],"tags":[{"name":"other","slug":"other","permalink":"http://wzhongke.github.io/tags/other/"}]},{"title":"java 文件处理","slug":"java/java 文件处理","date":"2017-06-30T11:41:43.000Z","updated":"2017-09-18T10:21:48.092Z","comments":true,"path":"2017/06/30/java/java 文件处理/","link":"","permalink":"http://wzhongke.github.io/2017/06/30/java/java 文件处理/","excerpt":"","text":"PathPath 是java7中java.nio.file包中的类，它是一个抽象构造。创建和处理Path不会马上绑定到对应的物理位置，如果试图读取一个未创建的文件会抛出IOException. 使用 Paths.get(String filePath, String more ... ) 来创建一个 Path。 可以通过resolve方法来合并两个Path:12// 最终是文件是 /usr/local/xml.conf Paths.get(\"/usr\").resolve(\"local/xml.conf\") 还可以通过startsWith(Path prefix), equals(Path path) 和 endsWith(Path suffix) 来比较路径 还可以在Path和File之间进行转换: file.toPath(), path.toFile() 遍历目录可以通过Files.walkFileTree(Path start, FileVisitor&lt;? super Path&gt; visitor) 来遍历目录树，其中实现FileVisitor接口，需要实现如下几个方法：12345678// 在进入一个目录之前被调用FileVisitResult preVisitDirectory(T dir, BasicFileAttributes attrs)// 处理当前文件FileVisitResult visitFile(T file, BasicFileAttributes attrs) throws IOException// 访问文件失败时被调动，文件属性不能读取、目录不能被打开等等FileVisitResult visitFileFailed(T file, IOException exc) throws IOException// 访问完目录时被调用FileVisitResult postVisitDirectory(T dir, IOException exc) 可以如下使用12345678910111213141516171819202122232425262728293031public static class HandleFile implements FileVisitor&lt;Path&gt; &#123; @Override public FileVisitResult preVisitDirectory(Path dir, BasicFileAttributes attrs) throws IOException &#123; System.out.println(\"preVisitDirectory: \" + dir.toString()); return FileVisitResult.CONTINUE; &#125; @Override public FileVisitResult visitFile(Path path, BasicFileAttributes attrs) throws IOException &#123; System.out.println(\"visitFile: \" +path.getFileName()); return FileVisitResult.CONTINUE; &#125; @Override public FileVisitResult visitFileFailed(Path file, IOException exc) throws IOException &#123; System.out.println(\"visitFile: \" + file.getFileName()); return FileVisitResult.CONTINUE; &#125; @Override public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException &#123; System.out.println(\"postVisitDirectory: \" + dir.getFileName()); return FileVisitResult.CONTINUE; &#125; public static void main(String[] args) throws IOException &#123; Path startingDir = Paths.get(\"E:\\\\golang\"); Files.walkFileTree(startingDir, new HandleFile()); &#125;&#125; 执行上述程序产生结果为：1234567preVisitDirectory: E:\\golangpreVisitDirectory: E:\\golang\\pkgpostVisitDirectory: pkgpreVisitDirectory: E:\\golang\\srcvisitFile: test.gopostVisitDirectory: srcpostVisitDirectory: golang 注意： 路径中如果有中文，可能会有问题 java中提供了实现FileVisitor的接口的类SimpleFileVisitor，可以按需覆盖默认方法，简化编写代码。 文件的创建和删除可以调用Files工具类的createFile(Path path, FileAttribute&lt;?&gt;... attrs)方法来创建文件，还可以通过FileAttribute来指定文件属性。1234Path path = Paths.get(\"D://test.txt\");Set&lt;PosixFilePermission&gt; perms = PosixFilePermissions.fromString(\"rwxrw-r--\");FileAttribute&lt;Set&lt;PosixFilePermission&gt;&gt; attrs = PosixFilePermissions.asFileAttribute(perms);Files.createFile(path, attrs); 文件的删除就比较简单了：12Path path = Paths.get(\"D://test.txt\");Files.delete(path); 文件的复制和移动借助Files工具类可以很简单地完成文件的复制和移动12345678910111213// 将一个流拷贝到文件中Files.copy(InputStream in, Path target, CopyOption... options) throws IOException// 例子URI u = URI.create(\"http://java.sun.com/\");try (InputStream in = u.toURL().openStream()) &#123; Files.copy(in, Paths.get(\"D:/test\"), StandardCopyOption.REPLACE_EXISTING);&#125;// 将一个输入流拷贝到输出流中Files.copy(InputStream source, OutputStream sink) throws IOException// 将文件拷贝到输出流中Files.copy(Path source, OutputStream out) throws IOException// 将文件从一个路径拷贝到另一个路径Files.copy(Path source, Path target, CopyOption... options) throws IOException 可以通过Files.move(Path source, Path taget, CopyOption... options) 来移动文件：1Files.move(Path.get(\"source\"), Path.get(\"target\"), StandardCopyOption.REPLACE_EXISTING, StandardCopyOption.COPY_ATTRIBUTES); 快速读写数据可以通过Files工具类中的newBufferedReader(Path path, Charset cs) throws IOException 将一个文件快速读入到BufferedReader实例中:1234567Path path = Paths.get(\"D://test.txt\");try (BufferedReader reader = Files.newBufferedReader(path, StandardCharsets.UTF_8)) &#123; String line; while ((line = reader.readLine()) != null) &#123; System.out.println(line); &#125;&#125; Files工具类中的BufferedWriter newBufferedWriter(Path path, Charset cs, OpenOption... options) 来快速获取BufferedWriter. 还有一些简化的读取和写入，不过对于大文件的处理并不适用：12List&lt;String&gt; lines = Files.readAllLines(path, StandardCharsets.UTF_8);byte[] bytes = Files.readAllBytes(path); 监控文件变化java7中可以用java.nio.file.WatchService类检测文件或者目录的变化，并在文件发生变化时触发相应的方法12345678910111213try &#123; WatchService watcher = FileSystems.getDefault().newWatchService(); Path path = Paths.get(\"D:/test\"); WatchKey key = path.register(watcher, StandardWatchEventKinds.ENTRY_MODIFY); while (!isShutdown) &#123; key = watcher.take(); key.pollEvents().stream() .filter(event -&gt; event.kind() == StandardWatchEventKinds.ENTRY_MODIFY) .forEach(event -&gt; System.out.println(path.toAbsolutePath().toString() + \" has been modified\")); &#125;&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125;","categories":[{"name":"java","slug":"java","permalink":"http://wzhongke.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://wzhongke.github.io/tags/java/"}]},{"title":"nginx配置双向认证 并通过java访问","slug":"nginx配置双向认证 并通过java访问","date":"2017-06-18T19:42:25.000Z","updated":"2017-08-04T05:51:58.080Z","comments":true,"path":"2017/06/19/nginx配置双向认证 并通过java访问/","link":"","permalink":"http://wzhongke.github.io/2017/06/19/nginx配置双向认证 并通过java访问/","excerpt":"最近项目开发中的接口要使用双向认证，因为搭建服务器的方式是nginx+resin，而java的keytool配置nginx的双向认证时，并不好用。所以使用了openssl来生成证书。 安装openssl部分linux系统上已经默认安装了openssl，可以使用openssl version来查看机器上是否安装了openssl。如果没有安装，可以执行 yum install nginx openssl -y 安装 使用脚本生成证书每次使用命令行安装都是一个巨大的考验，尤其是在输入各种信息的时候。输入错误就要Crtl+c重新来过。因此，将安装过程写成一个脚本，方便安装。","text":"最近项目开发中的接口要使用双向认证，因为搭建服务器的方式是nginx+resin，而java的keytool配置nginx的双向认证时，并不好用。所以使用了openssl来生成证书。 安装openssl部分linux系统上已经默认安装了openssl，可以使用openssl version来查看机器上是否安装了openssl。如果没有安装，可以执行 yum install nginx openssl -y 安装 使用脚本生成证书每次使用命令行安装都是一个巨大的考验，尤其是在输入各种信息的时候。输入错误就要Crtl+c重新来过。因此，将安装过程写成一个脚本，方便安装。 在nginx的conf目录下新建一个文件夹：mkdir openssl &amp;&amp; cd openssl 将shell脚本和下面的配置文件拷贝到openssl目录下，可以根据自己修改sheel脚本中的SUBJECT和CA；脚本执行过程中需要输入证书的域名，如果机器没有域名，那么输入ip。如果证书的ip或者域名与输入的内容不一致，是用java访问时，会报错javax.net.ssl.SSLPeerUnverifiedException: Certificate for &lt;*.*.*.*&gt; doesn&#39;t match any of the subject alternative names: []；需要输入两种密码，第一种是server.key的密码，第二种是client.key的密码，改密码要在是用证书时用到，需要记住。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#!/bin/sh# create self-signed server certificate:read -p \"请输入证书的域 例如[www.example.com or 192.168.1.52]: \" DOMAINmkdir newcerts private conf server# 根据自己的需求，来更改这些内容SUBJECT=\"/C=CN/ST=BJ/L=BJ/O=company/OU=company/CN=$DOMAIN\"CA=\"/C=CN/ST=BJ/L=BJ/O=company/OU=company/CN=$DOMAIN\"echo \"创建 CA 根证书...\"echo \"生成私钥 key 文件...\"openssl genrsa -out private/ca.key 2048 echo \"生成证书请求 csr 文件...\"openssl req -new -subj $CA -key private/ca.key -out private/ca.csr echo \"生成凭证 crt 文件...\"openssl x509 -req -days 365 -in private/ca.csr -signkey private/ca.key -out private/ca.crt echo \"为我们的 key 设置起始序列号和创建 CA 键库...\"rm -rf serial index.txtecho FACE &gt; serialtouch index.txtecho \"服务器证书的生成...\"openssl genrsa -out server/server.key 2048 openssl req -new -subj $SUBJECT -key server/server.key -out server/server.csr echo \"使用我们私有的 CA key 为刚才的 key 签名...\"openssl ca -in server/server.csr -cert private/ca.crt -keyfile private/ca.key -out server/server.crt -config \"./openssl.conf\" echo \"客户端证书的生成 * 创建存放 key 的目录 users...\"mkdir users echo \" 为用户创建一个 key...\"openssl genrsa -des3 -out ./users/client.key 2048 echo \"为 key 创建一个证书签名请求 csr 文件...\"openssl req -new -subj $SUBJECT -key ./users/client.key -out ./users/client.csr echo \"使用我们私有的 CA key 为刚才的 key 签名...\"openssl ca -in ./users/client.csr -cert ./private/ca.crt -keyfile ./private/ca.key -out ./users/client.crt -config \"./openssl.conf\" echo \"将证书转换为大多数浏览器都能识别的 PKCS12 文件...\"openssl pkcs12 -export -clcerts -in ./users/client.crt -inkey ./users/client.key -out ./users/client.p12 echo \"把以上生成的文件copy到nginx conf文件的ssl目录下面，如果ssl目录不存在请创建\"echo \"接下请配置nginx.conf操作:\"echo \" server &#123; \"echo \" ... \"echo \" ssl on; \"echo \" ssl_certificate ca/server/server.crt; \"echo \" ssl_certificate_key ca/server/server.key; \"echo \" ssl_client_certificate ca/private/ca.crt; \"echo \" ssl_verify_client on; \"echo \" ... \"echo \" &#125; \"echo \"使用如下命令重新加载nginx配置\"echo \"nginx -s reload\"echo \"客户端使用： users/client.p12 和 private/ca.crt\" 在相同的目录下放置如下配置，命名为openssl.conf：12345678910111213141516171819202122232425262728[ ca ] default_ca = foo # The default ca section [ foo ] dir = ./ # top dir database = ./index.txt # index file. new_certs_dir = ./newcerts # new certs dir certificate = ./private/ca.crt # The CA cert serial = ./serial # serial no file private_key = ./private/ca.key # CA private key RANDFILE = ./private/.rand # random number file default_days = 365 # how long to certify for default_crl_days= 30 # how long before next CRL default_md = sha1 # message digest method to use unique_subject = no # Set to &apos;no&apos; to allow creation of # several ctificates with same subject. policy = policy_any # default policy [ policy_any ] countryName = match stateOrProvinceName = match organizationName = match organizationalUnitName = match localityName = optional commonName = supplied emailAddress = optional 配置nginx修改nginx的配置文件，在server配置如下信息123456789ssl_certificate /path/to/openssl/server/server.crt;ssl_certificate_key /path/to/openssl/server/server.key;ssl_client_certificate /path/to/openssl/private/ca.crt;ssl_verify_client on; ## 开启客户端的验证ssl_protocols TLSv1 TLSv1.1 TLSv1.2; 是用chrome浏览器访问修改完成后，如果不配置证书，在浏览器中是不能访问的。报错： 400 Bad Request No required SSL certificate was sent安装两个文件： client.p12和ca.crt，之后能够正常访问 使用java完成双向认证将生成的证书： client/client.p12 和 ca/ca.crt 拷贝出来。用java做双向认证时，会使用到这两个文件。java 双向认证的代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950private final static String P12_PATH = \"client.p12\"; //客户端证书路径private final static String P12_PWD = \"12345678\"; //客户端证书密码private final static String CA_PATH = \"ca.crt\"; // 根证书路径public static String sslRequestGet(String url) throws Exception &#123; SSLContext ctx = getSSLContext(P12_PATH, CA_PATH); LayeredConnectionSocketFactory sslSocketFactory = new SSLConnectionSocketFactory(ctx); HttpGet httpget = new HttpGet(url); try (CloseableHttpClient httpClient = HttpClients.custom() .setSSLSocketFactory(sslSocketFactory) .build();CloseableHttpResponse response = httpClient.execute(httpget) ) &#123; HttpEntity entity = response.getEntity(); String jsonStr = EntityUtils.toString(response.getEntity(), \"UTF-8\");//返回结果 EntityUtils.consume(entity); return jsonStr; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return \"\";&#125;/** 加载客户端验证证书 **/private static SSLContext getSSLContext(String keyStorePath, String trustStorePath) throws NoSuchAlgorithmException, KeyStoreException, UnrecoverableKeyException, IOException, CertificateException, KeyManagementException &#123; KeyManagerFactory keyManagerFactory = KeyManagerFactory.getInstance(KeyManagerFactory.getDefaultAlgorithm()); KeyStore keyStore = KeyStore.getInstance(KeyStore.getDefaultType()); InputStream is = new FileInputStream(keyStorePath); keyStore.load(is, P12_PWD.toCharArray()); is.close(); keyManagerFactory.init(keyStore, P12_PWD.toCharArray()); SSLContext ctx = SSLContext.getInstance(\"TLS\"); ctx.init(keyManagerFactory.getKeyManagers(), getTrustManagers(trustStorePath) , null); return ctx;&#125;/** 加载信任证书 **/private static TrustManager [] getTrustManagers (String ... crtPath) throws IOException, CertificateException, KeyStoreException, NoSuchAlgorithmException &#123; if (crtPath == null || crtPath.length &lt; 1) &#123; return null; &#125; CertificateFactory certificateFactory = CertificateFactory.getInstance(\"X.509\"); KeyStore keyStore = KeyStore.getInstance(KeyStore.getDefaultType()); keyStore.load(null); for (int i=0, j=crtPath.length; i&lt;j; i++) &#123; String path = crtPath[i]; InputStream is = new FileInputStream(path); keyStore.setCertificateEntry(Integer.toString(i), certificateFactory.generateCertificate(is)); is.close(); &#125; TrustManagerFactory trustManagerFactory =TrustManagerFactory.getInstance(TrustManagerFactory.getDefaultAlgorithm()); trustManagerFactory.init(keyStore); return trustManagerFactory.getTrustManagers();&#125; 在VM options中添加执行参数： -Djavax.net.debug=all -Djavax.net.ssl.trustStore=trustStore 可以将双向认证的过程，在debug信息中打印出来 参考网站Nginx SSL 双向认证，key 生成和配置","categories":[{"name":"linux","slug":"linux","permalink":"http://wzhongke.github.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://wzhongke.github.io/tags/linux/"}]},{"title":"java修改字符串编码","slug":"java/java修改字符串编码","date":"2017-06-18T19:01:11.000Z","updated":"2017-08-04T05:51:58.080Z","comments":true,"path":"2017/06/19/java/java修改字符串编码/","link":"","permalink":"http://wzhongke.github.io/2017/06/19/java/java修改字符串编码/","excerpt":"使用java处理接口返回数据时，经常会有编码转换的问题。一开始以为如果将gbk编码的数据转换为utf8的数据，那么应该使用gbk编码获取数据，再将数据进行utf8编码。1new String(\"中国\".getBytes(\"gbk\"), \"utf8\") 这样得出来的数据总是乱码。查看String的getBytes(String charsetName)源码","text":"使用java处理接口返回数据时，经常会有编码转换的问题。一开始以为如果将gbk编码的数据转换为utf8的数据，那么应该使用gbk编码获取数据，再将数据进行utf8编码。1new String(\"中国\".getBytes(\"gbk\"), \"utf8\") 这样得出来的数据总是乱码。查看String的getBytes(String charsetName)源码12345public byte[] getBytes(String charsetName) throws UnsupportedEncodingException &#123; if (charsetName == null) throw new NullPointerException(); return StringCoding.encode(charsetName, value, 0, value.length); &#125; 发现该方法是获得使用所传参数编码的byte数组。因此正确的方式应该是：1new String(\"中国\".getBytes(\"utf8\"), \"utf8\")","categories":[{"name":"java","slug":"java","permalink":"http://wzhongke.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://wzhongke.github.io/tags/java/"}]},{"title":"HashMap 和 ConcurrentHashMap","slug":"java/ConcurrentHashMap","date":"2017-06-17T19:48:32.000Z","updated":"2017-08-22T02:33:16.382Z","comments":true,"path":"2017/06/18/java/ConcurrentHashMap/","link":"","permalink":"http://wzhongke.github.io/2017/06/18/java/ConcurrentHashMap/","excerpt":"并发编程为什么使用ConcurrentHashMapHashMap并不是线程安全的，HashTable虽然是线程安全的，但是HashTable的效率非常低下。 HashMap不是线程安全的在多线程环境下，使用HashMap的put()会导致程序进入死循环，是因为多线程会导致HashMap的冲突链表形成环形数据。一旦新城环形数据结构，Node的next永远不为空，导致死循环。","text":"并发编程为什么使用ConcurrentHashMapHashMap并不是线程安全的，HashTable虽然是线程安全的，但是HashTable的效率非常低下。 HashMap不是线程安全的在多线程环境下，使用HashMap的put()会导致程序进入死循环，是因为多线程会导致HashMap的冲突链表形成环形数据。一旦新城环形数据结构，Node的next永远不为空，导致死循环。 HashTable效率低下以下是HashTable的put()和get()方法的源码。可以看到我们经常用到的put()和get()方法的同步是对象的同步。在线程竞争激烈的情况下，当一个线程访问HashTable的同步方法时，其他访问同步方法的线程只能进入阻塞或轮询状态。因此，HashTable在多线程下的效率非常低，连读写锁都没有采用。12345678910111213141516public synchronized V put(K key, V value) &#123; // Make sure the value is not null if (value == null) &#123; throw new NullPointerException(); &#125; ... addEntry(hash, key, value, index); return null;&#125;public synchronized V get(Object key) &#123; Entry&lt;?,?&gt; tab[] = table; int hash = key.hashCode(); ... return null;&#125; ConcurrentHashMap的锁分段技术锁分段技术就是容器中使用多把锁，每个锁用于容器中的部分数据。这样当多个线程并发访问不同数据段的数据时，线程就不会竞争锁，提高并发访问效率。在ConcurrentHashMap的put()方法中，对于向非空桶中加入数据时，才使用同步锁。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; if (tab == null || (n = tab.length) == 0) tab = initTable(); // 定位的桶中没有元素，不需要同步 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else &#123; V oldVal = null; synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; if (fh &gt;= 0) &#123; binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; addCount(1L, binCount); return null;&#125; 而ConcurrentHashMap的get()方法是没有锁的。这是因为get()方法中使用的共享变量都定义成volatile类型，而volatile类型的变量能够在多线程之间保持可见性，能够保证多个线程读取的时候不会读到过期的值。","categories":[{"name":"算法","slug":"算法","permalink":"http://wzhongke.github.io/categories/算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://wzhongke.github.io/tags/算法/"}]},{"title":"apply和call","slug":"front/apply和call的区别","date":"2017-06-17T19:48:32.000Z","updated":"2017-08-22T02:32:47.739Z","comments":true,"path":"2017/06/18/front/apply和call的区别/","link":"","permalink":"http://wzhongke.github.io/2017/06/18/front/apply和call的区别/","excerpt":"JavaScript中每个函数都包含两个非继承而来的方法：apply()和call().apply()方法接收两个参数：运行调用函数的作用域；参数数组或者arguments对象。call()方法同apply()不同之处在于除了第一个参数是函数运行的作用域，其余参数都是直接传递给函数的，因此使用call()方法时传递的参数必须全部列举出来。","text":"JavaScript中每个函数都包含两个非继承而来的方法：apply()和call().apply()方法接收两个参数：运行调用函数的作用域；参数数组或者arguments对象。call()方法同apply()不同之处在于除了第一个参数是函数运行的作用域，其余参数都是直接传递给函数的，因此使用call()方法时传递的参数必须全部列举出来。 12345678910111213141516function sum(num1, num2) &#123; console.log(num1 + num2);&#125;function timeoutCall(context, f) &#123; var len = arguments.length; var args = []; for (var i = 2; i &lt; len; i++) &#123; args.push(arguments[i]); &#125; return function() &#123; f.apply(context, args); &#125;&#125;timeoutCall(this, sum, 1,2); 上述方法可以用在setTimeout中，用来维持函数原有的作用域。","categories":[{"name":"javascript","slug":"javascript","permalink":"http://wzhongke.github.io/categories/javascript/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://wzhongke.github.io/tags/javascript/"}]},{"title":"hexo Hello World","slug":"hello-world","date":"2017-06-17T19:48:32.000Z","updated":"2017-08-22T04:15:27.916Z","comments":true,"path":"2017/06/18/hello-world/","link":"","permalink":"http://wzhongke.github.io/2017/06/18/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment 出现过的问题： 执行hexo d时，出现 ERROR Deployer not found: git，解决方法： 是否执行过npm install hexo-deployer-git --save 执行hexo init之后，是否切换过根目录。如果切换过，需要新建一个目录重新hexo init","categories":[{"name":"nodejs","slug":"nodejs","permalink":"http://wzhongke.github.io/categories/nodejs/"}],"tags":[{"name":"nodejs","slug":"nodejs","permalink":"http://wzhongke.github.io/tags/nodejs/"}]},{"title":"二叉树的分层遍历","slug":"二叉树的分层遍历","date":"2017-06-17T19:48:32.000Z","updated":"2017-08-21T10:47:24.683Z","comments":true,"path":"2017/06/18/二叉树的分层遍历/","link":"","permalink":"http://wzhongke.github.io/2017/06/18/二叉树的分层遍历/","excerpt":"今天去面试的时候被问到二叉树的分层遍历，因为原来写Python脚本的时候自己用队列的方法写过一次 分层遍历。结果面试官说能不能用递归的方法，不用队列实现。唔，临时想没有想起来，因此记录一下。 首先定义一个二叉树的节点：12345class TreeNode: def __init__(self,value): self.value=value self.left=None self.right=None","text":"今天去面试的时候被问到二叉树的分层遍历，因为原来写Python脚本的时候自己用队列的方法写过一次 分层遍历。结果面试官说能不能用递归的方法，不用队列实现。唔，临时想没有想起来，因此记录一下。 首先定义一个二叉树的节点：12345class TreeNode: def __init__(self,value): self.value=value self.left=None self.right=None 遍历算法为：123456789101112131415161718192021222324def traverse(node): '''''将要遍历的根节点放入队列中，并放入一个结束的标志位''' if node is None: return q=Queue.Queue() q.put(node) q.put(Sign()) traverse_re(q)def traverse_re(queue): node=queue.get() if node is None or isinstance(node, Sign): return while(not isinstance(node, Sign)): print node.value, #将左右子树放入队列中 if node.left is not None: queue.put(node.left) if node.right is not None: queue.put(node.right) node=queue.get() print '' queue.put(Sign()) traverse_re(queue) 验证方法为：12345678if __name__==\"__main__\": root=TreeNode(1) left=TreeNode(2) right=TreeNode(3) root.left,root.right=left,right left.left=TreeNode(4) right.left,right.right=TreeNode(6),TreeNode(7) traverse(root) 之后在《编程之美》上看到了不使用队列的递归遍历方法： 123456789101112131415def nodeAtLevel(node, level): if node is None or level &lt;0: return 0 if level==0: print node.value, return 1 return nodeAtLevel(node.left, level-1)+nodeAtLevel(node.right, level-1)def nodeByLevel(root): level=0 while(True): if(nodeAtLevel(root, level)==0): break level+=1 print \"\" 不过还是使用队列遍历的效率高，时间复杂度低","categories":[{"name":"算法","slug":"算法","permalink":"http://wzhongke.github.io/categories/算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://wzhongke.github.io/tags/算法/"}]},{"title":"正则表达式","slug":"正则表达式","date":"2017-06-17T19:42:25.000Z","updated":"2017-08-31T10:36:45.734Z","comments":true,"path":"2017/06/18/正则表达式/","link":"","permalink":"http://wzhongke.github.io/2017/06/18/正则表达式/","excerpt":"","text":"元字符 元字符 说明 . 匹配除换行符以外的任意字符 \\w 匹配字母或数字或下划线或汉字 \\s 匹配任意的空白字符 \\d 匹配数字 \\b 匹配单词的开始或结束 ^ 匹配字符串的开始 $ 匹配字符串的结束 限定符 限定符 说明 * 重复0次或更多次 + 重复一次或更多次 ? 重复0次或一次 {n} 重复n次 {n, } 重复n次或更多次 {n, m} 重复n到m次 指定范围使用[]来指定一个字符的范围，如[a-zABC]匹配的是a到z以及A、B、C中的任意一个字符。 分支条件使用 | 来分隔不同的条件 捕获分组使用小括号指定一个子表达式后，匹配这个子表达式的文本，每个分组会有一个组号，规则是从左向右以分组的左括号为标志，第一个出现的分组的组号是1，第二个是2… 后向引用用于重复搜索前面的某个分组匹配的文本，\\b(\\w+)\\b\\s+\\1\\b可以用来匹配重复的单词，\\1代表第一个分组匹配的文本也可以指定分组名，语法：(?&lt;Word&gt;\\w+) 或者 (?’word’\\w+)，要反向引用使用\\k&lt;Word&gt; 懒惰模式当正在表达式中包含能够接受重复的限定符时，通常是匹配尽可能多的字符，而懒惰是匹配尽量少的字符. 代码 语法 *? 重复任意次，但尽可能少重复 +? 重复1次或更多次，但尽可能少重复 ?? 重复0次或1次，但尽可能少重复 {n,m}? 重复n到m次，但尽可能少重复 {n, }? 重复n次以上，但尽可能少重复 常用分组语法捕获 代码 说明 (exp) 匹配exp，并捕获文本到自动命名的组里 (?exp) 匹配exp，并捕获文本到名称为name的组里 (?:exp) 匹配exp，不捕获文本，也不分配组号 零宽断言 代码 说明 (?=exp) 匹配exp前面的位置 (?&lt;=exp) 匹配exp后面的位置 (!exp) 匹配后面跟的不是exp的位置 (?&lt;!exp) 匹配前面不是exp的位置 注释: (?#comment) 注释 在Java中使用正则使用正则提取匹配内容1234567String ip = \"ip:127.0.0.1\";Pattern pattern = Pattern.compile(\"((?:(?:25[0-5]|2[0-4]\\\\d|((1\\\\d&#123;2&#125;)|([1-9]?\\\\d)))\\\\.)&#123;3&#125;(?:25[0-5]|2[0-4]\\\\d|((1\\\\d&#123;2&#125;)|([1-9]?\\\\d))))\");Matcher matcher = pattern.matcher(ip);if ( matcher.find() ) &#123; System.out.println(\"Found value: \" + matcher.group(0));&#125;System.out.println(matcher.replaceAll(\" I am matcher replace [$1] ha\")); 替换文本内容1234String text = \"here is [text] and a [input]\";// $1 代表正则表达式第一个捕获组括号中的内容System.out.println(text.replaceFirst(\"\\\\[(.*?)]\", \"&#123;$1&#125;\"));System.out.println(text.replaceAll(\"\\\\[(.*?)]\", \"&#123;$1&#125;\")); JavaScript中使用正则1/\\\\[(.*?)]/i.test(\"here is [text] \");","categories":[{"name":"other","slug":"other","permalink":"http://wzhongke.github.io/categories/other/"}],"tags":[{"name":"other","slug":"other","permalink":"http://wzhongke.github.io/tags/other/"}]},{"title":"markdown语法","slug":"markdown语法","date":"2017-06-17T19:42:25.000Z","updated":"2017-09-02T06:34:32.140Z","comments":true,"path":"2017/06/18/markdown语法/","link":"","permalink":"http://wzhongke.github.io/2017/06/18/markdown语法/","excerpt":"斜体12*这是斜体1*_这是斜体2_ 这是斜体1这是斜体2","text":"斜体12*这是斜体1*_这是斜体2_ 这是斜体1这是斜体2 粗体12**这是粗体**__这是粗体__ 这是粗体这是粗体 带删除线1~~删除线.~~ 删除线. 下划线12&lt;span style=&quot;text-decoration:underline&quot;&gt;我带下划线&lt;/span&gt;&lt;span style=&quot;text-decoration:overline&quot;&gt;我带上划线&lt;/span&gt; 超链接12[text](https://www.sogou.com)&lt;https://www.sogo.com&gt; texthttps://www.sogo.com 引用引用的区块也可以使用其他的Markdown语法12&gt; 这是一个引用&gt; &gt; 这是第二级引用 这是一个引用 这是第二级引用 锚点问内链接; 列表无序列表123- Red- Green- Blue Red Green Blue 有序列表1231. 12. 23. 3 1 2 3 列表嵌套123456789101112131. 列出所有元素： - 无序列表元素 A 1. 元素 A 的有序子列表 - 前面加四个空格2. 列表里的多段换行： 前面必须加四个空格， 这样换行，整体的格式不会乱3. 列表里引用： &gt; 前面空一行 &gt; 仍然需要在 &gt; 前面加四个空格4. 列表里代码段： 前面四个空格，之后按代码语法 1 或者直接空八个，引入代码块 123456789101112131. 列出所有元素： - 无序列表元素 A 1. 元素 A 的有序子列表 - 前面加四个空格2. 列表里的多段换行： 前面必须加四个空格， 这样换行，整体的格式不会乱3. 列表里引用： &gt; 前面空一行 &gt; 仍然需要在 &gt; 前面加四个空格4. 列表里代码段： 前面四个空格，之后按代码语法 1 或者直接八个空格，引入代码块 代办列表12- [ ] 不勾选- [x] 勾选 (为aiks) 不勾选 勾选 (为aiks) 代码123```javanew String();``` 1new String(); 表格1234First Header | Second Header | Third Header:----------- | :-----------: | -----------:Left | Center | RightLeft | Center | Right First Header Second Header Third Header Left Center Right Left Center Right 分割线12---*** 图片1234![Alt text][1][1]: https://www.sogou.com/index/images/logo_440x140.v.1.png &quot;搜狗搜索 optional title&quot;![Alt text](https://www.sogou.com/index/images/logo_440x140.v.1.png) Alt text 插入原生html123&#123;% raw %&#125;&lt;em&gt;your html&lt;/em&gt;&#123;% endraw %&#125; your html","categories":[{"name":"nodejs","slug":"nodejs","permalink":"http://wzhongke.github.io/categories/nodejs/"}],"tags":[{"name":"markdown","slug":"markdown","permalink":"http://wzhongke.github.io/tags/markdown/"}]},{"title":"linux 常用命令","slug":"linux/linux-常用命令","date":"2017-06-17T19:42:25.000Z","updated":"2017-10-23T08:17:01.451Z","comments":true,"path":"2017/06/18/linux/linux-常用命令/","link":"","permalink":"http://wzhongke.github.io/2017/06/18/linux/linux-常用命令/","excerpt":"使用ubuntu的时候经常会把常用的一些命令忘掉或不知道有些参数的意思，又懒得看那枯燥的文档。因此记录下来备忘。","text":"使用ubuntu的时候经常会把常用的一些命令忘掉或不知道有些参数的意思，又懒得看那枯燥的文档。因此记录下来备忘。 目录类 ls: 查看文件与目录 12345678910111213141516171819ls [-aAdfFhilnrRSt] 目录或文件ls [--color=&#123;never,auto,always&#125;] 目录或文件ls [--full-time] 目录或文件-a: 列出全部文件，包括隐藏文件-A: 列出全部文件，包括隐藏文件，但不包括 . 与 .. 两个目录-d: 仅列出目录，不列出目录内的文件-f: 直接列出结果，不进行排序 (ls默认会以文件名排序)-F: 根据文件、目录等信息给予附件数据结构 ( *:代表可执行文件，/: 代表目录，=: 代表socket文件，|: 代表FIFO文件)-h: 将文件容量以易读的方式列出-i: 列出inode号码-l: 列出文件属性权限等-n: 列出UID与GID，而非用户与用户组名-r: 将排序结果反向输出-R: 连同子目录内容一起列出来-S: 以文件容量大小排序-t: 以时间排序-color: never(不要依据文件特性给予颜色显示)，always(显示颜色)，auto(系统判定是否显示颜色)--full-time: 以完整的时间模式输出 年、月、日、时、分--time=&#123;atime, ctime&#125;: 输出访问时间或改变权限属性时间(ctime)，而非内容更改时间 cd: 切换目录 1234567cd [相对路径或者绝对路径]#回到自己的主文件夹cd [or cd ~]#回到上层目录cd ..#回到刚才的目录cd - pwd : 显示当前目录 12pwd [-P]-P:显示当前的路径，而非使用连接路径 mkdir : 新建目录 12345mkdir [-mp] 目录名称-m:配置文件夹的权限，忽略默认权限（umask)-p:递归地创建目录#新建权限为rwx--x--x的目录mkdir -m 711 dir_name 复制删除移动 复制 cp 1234567891011121314#只复制一个文件或文件夹cp [-adfilprsu] 源文件 目标文件-a: 相当于 -pdr，看后文-d：若文件为连接文件，则只复制连接文件的属性-f: 若目标文件已经存在且无法开启，则删除后再试一次-i: 若目标文件已存在，覆盖时会先询问是否覆盖-l: 创建文件的硬链接-p: 连同文件的属性一起复制，备份常用**-r: 递归复制，用于目录的复制**-s: 创建文件的软连接-u: 若目标文件比源文件旧才更新目标文件#复制多个文件到某一文件夹下$ cp [options] 源文件1 源文件2 ... 目标文件 移除文件或目录 1234rm [-fir] 文件或目录-f: 忽略不存在的文件-i: 删除前再次确认-r: 递归删除，主要用来删除目录 移动文件目录或者更名 1234mv [-fiu] 文件或目录 目标文件或目录-f: 目标文件存在时，不询问直接覆盖-i: 目标文件存在，询问是否覆盖-u: 目标文件存在，且较新时，才会更新 非纯文本 od 12345678od [-t TYPE] 文件-t: 后面可以接各种类型输出： a : 利用默认字符输出 c : 使用ASCII字符输出 d[size]: 用十进制输出数据，每个整数占用 size bytes f[siez]: 用浮点数输出数据，每个整数占用 size bytes o[size]: 用八进制来输出数据，每个整数占用 size bytes x[size]: 用十六进制来输出数据，每个整数占用 size bytes 连接文件 ln硬连接是将文件对应到同一个inode号码上的连接。硬连接不能跨文件系统，不能连接到目录。符号连接就是windows下的快捷方式。 123ln [-sf] 源文件 目标文件(符合连接文件) -s: 创建符号连接，而不是硬连接 -f: 如果目标文件存在，就将目标文件删除后再创建 命令与文件查询 which：可以查询脚本文件的位置，比如 ifconfig 命令的位置。但是不能够查询bash内置的命令，比如cd 12which [-a] command-a: 列出所有 PATH 目录中包含的命令，没有该参数，只会列出第一个 whereis： 定位命令的二进制，源文件和帮助文件 12345whereis [-bmsu] 文件或目录名-b : 只找二进制文件-m : 在menu下查找-s : 只找源文件-u : 其他文件 locate： 根据文件名搜索文件，输出所有的文件。因为是从存储文件记录的数据库文件/var/lib/mlocate中读取的，所以速度快。但是数据库文件是定时更新的，所以新增的文件查询不到。可以通过updatedb来更新文件，因为该命令是查找硬盘的，所以执行比较慢。 123locate [-ir] 文件名-i: 忽略大小写差异-r: 可以接正则表达式 find: 在目录下搜索文件，与xargs一起使用，功能强大 123456789101112131415161718find [PATH] [option] [action]# 与时间有关的参数有 -atime, -ctime, -mtime, 这三个参数使用方法类似。-mtime n: 在n天之前的 一天内 被更改过的文件-mtime +n: 在n天之前（不含n天）被更改过的文件-mtime -n: 在n天之内（含n天） 被更改过的文件-newer file: file问一个文件的路径，列出比file新的文件-newermt time: 比time更新的文件-type TYPE: 查找的文件类型，主要有： 一般文件(f), 设备文件(b,c), 目录(d), 连接文件(l), socket(s)等-perm [+/-]mode: 查找文件权限，刚好等于mode， \"-\" 表示文件权限必须包含 mode， \"+\" 表示文件权限包含任一 mode-name filename: 查找文件名为filename的文件， 使用通配符表示文件名时，需要加上 ''-size [+-]SIZE: 查找比size还要大(+)或小(-)的文件 ,可以是用K\\M\\G-exec command: command为命令，该命令可以处理查找结果，不支持别名。find / -exec ls -l &#123;&#125;\\;find命令会将所有匹配到的文件一起传递给exec执行，但有些系统对能够传递给exec的命令有长度限制，会出现溢出错误。这时候可以使用xargs。find . | xargs grep xxx: 查找当前目录下含有x的文件 更改权限权限分数为： r(read)=4, w(write)=2, x(execute)=112345chgrp [-R（递归更改)] groupname dirname/filename: 改变文件所属用户组chown [-R（递归更改)] username[:groupname] dirname/filename：改变文件所有者chmod [-R（递归更改)] [options] dirname/filename：改变文件所有者chmod 761 file: 将文件权限更改为 =rwxrw---xchmod u=rwx,g=rw,o=x file: u(user) g(group) o(others) =(设置) +(增加) -(取消) 数据流重定向 1&gt; : 以覆盖的方式将正确的数据输出到指定的文件或设备上 1&gt;&gt; : 以累加的方式将正确的数据输出到指定的文件或设备上 2&gt; : 以覆盖的方式将错误的数据输出到指定的文件或设备上 2&gt;&gt; : 以累加的方式将错误的数据输出到指定的文件或设备上 command &gt; list 2&gt;&amp;1 ： 将正确信息和错误信息都输入到list文件中 command 2&gt; /dev/null : 不保存错误信息命令执行判断依据： ; &amp;&amp; || com1;com2 不考虑命令的相关性，连续执行命令 com1&amp;&amp;com2 前一个命令执行正确($?=0)，才执行第二个命令 com1||com2 前一个命令执行不正确($?!=0)，才执行第二个命令 查看文件内容 cat 1234567cat [-AbEnTv] 文件-A: 相当于-vET 的整合，可列出一些特殊字符而不是空白-b: 列出行号，仅针对非空白行做行号显示-E: 将结尾的断行字符以 $ 显示出来-n: 打印行号，连同空白行也会有行号-T: 将[Tab]以 ^I显示出来-v: 列出一些看不出来的特殊字符 翻页查看more 1234567more 文件路径#空格键 向下翻一页#Enter 向下滚动一行#/字符串 在内容中向下查找字符串#:f 显示文件名以及目前显示的行数#q 离开more，不再显示内容#b 向回翻页，只对文件有效 翻页查看 less 123456789less 文件路径#空格键 向下翻一页#[PageDown] 向下翻一页#[PageUp] 向上翻一页#/字符串 在内容中向下查找字符串#?字符串 在内容中向上查找字符串#n 重复前一个查询#N 向上重复前一个查询#q 离开 数据选取 head 12head [-n number] 文件-n: 接数字，表示显示头几行，默认显示前10行 数据选取tail 12tail [-n number] 文件-n: 表示显示几行 另外可以修改 /etc/issue文件来改变终端的提示信息 压缩 zip 123456789101112131415161718192021222324zip [-AcdDfFghjJKlLmoqrSTuvVwXyz$] [-b &lt;工作目录&gt;] [-ll] [-n &lt;字尾字符串&gt;] [-t &lt;日期时间&gt;] [-&lt;压缩效率&gt;] [压缩文件名] [待压缩文件...] [-i &lt;范本样式&gt;] [-x &lt;范本样式&gt;]-A: 调整可执行的自动解压缩文件。-b: &lt;工作目录&gt; 指定暂时存放文件的目录。-c: 替每个被压缩的文件加上注释。**-d: 从压缩文件内删除指定的文件**-D: 压缩文件内不建立目录名称。-F: 尝试修复已损坏的压缩文件。-g: 将文件压缩后附加在既有的压缩文件之后，而非另行建立新的压缩文件.**-i &lt;范本样式&gt;: 只压缩符合条件的文件。****-x &lt;范本样式&gt;: 压缩时排除符合条件的文件。**-X: 不保存额外的文件属性。-j: 只保存文件名称及其内容，而不存放任何目录名称。-J: 删除压缩文件前面不必要的数据。-l: 压缩文件时，把LF字符置换成LF+CR字符。-ll: 压缩文件时，把LF+CR字符置换成LF字符。**-m: 将文件压缩并加入压缩文件后，删除原始文件，即把文件移到压缩文件中****-n&lt;字尾字符串&gt;: 不压缩具有特定字尾字符串的文件。**-q: 不显示指令执行过程**-r: 递归处理，将指定目录下的所有文件和子目录一并处理。**-t&lt;日期时间&gt;: 把压缩文件的日期设成指定的日期-y: 直接保存符号连接，而非该连接所指向的文件，本参数仅在UNIX之类的系统下有效。## 示例zip -r search.zip search/ ## 将search目录打包的zip文件中zip -r -x *.css search.zip search/ ## 打包search目录，单不包含css文件 使用zipsplit分割压缩的zip文件 1234zipsplit (选项) (参数)-n: 指定分割后每个zip文件的大小，是字节大小；-t: 报告将要产生的较小的zip文件的大小；-b: 指定分割后的zip文件的存放位置。 tar压缩tar参数中 -x,-c,-t不能同时出现。 1234567891011121314151617181920212223# 打包tar [-j|-z] [cv] [-f 新建的文件名] filename/dirname# 查看文件名tar [-j|-z] [tv] [-f 新建的文件名]# 解压tar [-j|-z] [xv] [-f 新建的文件名] [-C 目录]-c: 新建打包文件-t: 查看打包文件的内容有哪些文件名-x: 解压功能，可以配合 C 解压到特定目录-j: 通过bzip2来压缩/解压文件，此时文件名最好是 *.tar.bz2-z: 通过gzip来压缩/解压文件，此时文件名最好是 *.tar.gz-v: 在压缩/解压的过程中，将处理的文件名显示出来-f filename: -f后接要处理的文件名-C: 解压缩时，将文件解压到特定的目录-p: 保留备份数据的原本权限与属性，常用于备份重要的配置文件-P: 保留绝对路径--exclude=FILE: 在压缩过程中，不打包FILE## 示例tar -zcv -f filename.tar.gz 要压缩的文件或目录名 #压缩tar -zxv -f filename.tar.gz -C 欲解压的目录 # 解压tar -jcv -f system.tar.bz2 --exclude=/etc* --exclude=gz* /etc/root 访问网络内容 wget curlwget 用于从网络上下载资源，若没有指定目录，默认为当前目录12345678910111213141516171819202122232425262728293031wget [参数] [url地址] -o, –output-file=FILE: 把**记录**写到FILE文件中 -a, –append-output=FILE: 把**记录**追加到FILE文件中 -d, –debug: 打印调试输出 -q, –quiet: 安静模式(没有输出) -v, –verbose: 冗长模式(这是缺省设置) -nv, –non-verbose: 关掉冗长模式，但不是安静模式 -i, –input-file=FILE: 下载在FILE文件中出现的URLs -F, –force-html: 把输入文件当作HTML格式文件对待 -B, –base=URL: 将URL作为在-F -i参数指定的文件中出现的相对链接的前缀 –sslcertfile=FILE: 可选客户端证书 –sslcertkey=KEYFILE: 可选客户端证书的KEYFILE –egd-file=FILE: 指定EGD socket的文件名 -t, –tries=NUMBER 设定最大尝试链接次数(0 表示无限制). -O –output-document=FILE 把文档写到FILE文件中 -nc, –no-clobber 不要覆盖存在的文件或使用.#前缀 -c, –continue 接着下载没下载完的文件 –progress=TYPE 设定进程条标记 -N, –timestamping 不要重新下载文件除非比本地文件新 -S, –server-response 打印服务器的回应 –spider 不下载任何东西 -T, –timeout=SECONDS 设定响应超时的秒数 -w, –wait=SECONDS 两次尝试之间间隔SECONDS秒 –waitretry=SECONDS 在重新链接之间等待1…SECONDS秒 –random-wait 在下载之间等待0…2*WAIT秒 -Y, –proxy=on/off 打开或关闭代理 -Q, –quota=NUMBER 设置下载的容量限制 –limit-rate=RATE 限定下载输率 --post-data=\"\" : 通过post方式提交数据 管道命令 | - cut grep sort uniq每个|后面接的第一个数据必须是能够接受standard input数据的命令，而且管道命令只能处理standard output，对于error output会忽略 cut 1234cut –d '分隔符' –f fields -d : 后边接分隔符， 与-f一起使用 -f : 依据-d的分隔符将一段信息切割成为数段，有-f取出第几段的意思last | cut –d ' ' –f 1,2 grep 可用正则 1234567grep [-cinvP] [--color=auto] '查找字符串(正则)' filename -c : 计算找到字符串的次数 -i : 忽略大小写 -n : 给出行号 -v : 反向选择 -P : 用Perl正则表达式来匹配grep -–color=auto 'manpath' /etc/man.config sort 排序命令 123456789sort [-fbMnrtuk] [file or stdin] -f: 忽略大小写 -b: 忽略最前面的空格 -M: 以月份的名字排序 -n: 使用“纯数字”进行排序（默认是文字类型） -r: 反向排序 -u: 同umiq -t: 分隔符，默认是[tab]分割 -k: 以哪个区间来进行排序 uniq 计数 123uniq [-ic] -i: 忽略大小写字符的不同 -c: 进行计数 时间date命令能够通过date +Format设置输出格式12345678910111213date +Format - %Y : 年份 - %y : 年份的最后两位 - %d : 按月计的日期(例如：01) - %D : 按月计的日期；等于%m/%d/%y - %H : 小时(00-23) - %I : 小时(00-12) - %m : 月份 - %M : 分钟 - %S : 秒(00-60)date +%Y%m%d%H%M%S =&gt; 20170617194225# 输出时间 是一小时前的时间date -d'-1 hour' +%F' ' %T 通过 date -s 设置时间12date -s 06/17/2017date -s 19:42:25 磁盘与目录容量 df : 列出文件系统的整体磁盘使用量 12345df [-ahikHTm] [目录或文件名] -a : 列出所有文件系统，包括系统特有的/proc等文件系统 -h : 以人们较易阅读的GB、MB、KB等格式显示 -i : 不用硬盘容量，而以inode的数量来显示 -k/m : 以MB/KB的容量显示文件系统 du : 评估文件系统的磁盘使用量 123456du [-ahskm] 文件或目录名称 -a : 列出所有的文件与目录的容量，因为默认仅统计目录下面的文件量，不能同 s 一起使用 -h : 以较易阅读的格式显示 -s : 列出总量，不列出每个个别的目录占用量 -S : 尚不理解 -k/m : 以MB/KB的容量显示文件系统 lsof (list open files)在linux下，任何事物都以文件的形式存在，通过文件不仅可以访问常规数据，还可以访问网络连接和硬件。如TCP和UDP套接字等。系统在后台都为该应用程序分配了一个文件描述符，该文件描述符提供了大量关于这个应用程序本身的信息。12345678910111213lsof -a : 列出打开文件存在的进程 -c&lt;进程名&gt;: 列出指定进程所打开的文件 -g : 列出GID号进程详情 -d&lt;文件号&gt; : 列出占用该文件号的进程 +d&lt;目录&gt; : 列出目录下被打开的文件 +D&lt;目录&gt; : 递归列出目录下被打开的文件 -n&lt;目录&gt; : 列出使用NFS的文件 -i&lt;条件&gt; : 列出符合条件的进程。（4、6、协议、:端口、 @ip ） -p&lt;进程号&gt; : 列出指定进程号所打开的文件 -u : 列出UID号进程详情 -h : 显示帮助信息 -v : 显示版本信息 远程同步命令rsync命令rsync命令是用来远程同步数据的，可以通过LAN/WAN快速同步多台机器间的文件。rsync通过自己的算法来比较本地和远程文件的不同部分，而不是每次都整份传送，所以速度比scp快。:表明是通过远程shell连接，而:: 和 rsync:// 用于连接到rsync守护进程，它需要 src 或 dest 以模块名称开头12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576# 拷贝本地文件rsync [options] src dest# 使用一个远程shell程序将本地机器的内容拷贝到远程机器rsync [options] src [user@]host:dest# 使用一个远程shell将远程机器拷贝到本地机器rsync [options] [user@]host:src dest# 从远程rsync服务器中拷贝文件到本地机器rsync [options] [user@]host::src dest# 从本地机器拷贝文件到远程rsync服务器中rsync [options] src [user@]host::dest# 列远程机器的文件列表，类似rsync传输，不过需要在命令中省略本地机器rsync [options] rsync://[user@]host[:port]/src [dest]## 参数-v, --verbose: 详细模式输出-q, --quiet: 精简模式输出-c, --checksum: 打开校验开关-a, --archive: 归档模式，表示以递归方式传输文件，并保持所有文件属性，相当于 `-rlptgoD`-r, --recursive: 对子目录以递归模式处理-R, --relative: 使用相对路径信息-b, --backup: 创建备份 --backup-dir=DIR 将备份文件放到 DIR 中 --suffix=SUFFIX: 定义备份文件前缀-u, --update: 跳过接收机器上较新的文件-d, --dirs: 不会递归地传输目录-l, --link: 保留软连接-k, --copy-dirlinks: 将符号链接转换为指定目录-K, --keep-dirlinks: 将符号链接作为一个递归的目录-H, --hard-links: 保留硬链接-p, --perms: 保持文件权限-o, --owner: 保持文件属主信息-g, --group: 保持文件属组信息。 -D, --devices: 保持设备文件信息** -t, --times: 保持文件时间信息 **-S, --sparse: 对稀疏文件进行特殊处理以节省DST的空间-w, --whole-file: 拷贝文件，不进行增量检测 -x, --one-file-system: 不要跨越文件系统边界-B, --block-size=SIZE: 检验算法使用的块尺寸，默认是700字节-e, --rsh=command: 指定使用rsh、ssh方式进行数据同步 --rsync-path=PATH: 指定远程服务器上的rsync命令所在路径信息 --existing: 仅仅更新那些已经存在于DST的文件，而不备份那些新创建的文件 --delete: 删除那些DST中SRC没有的文件 --delete-excluded: 同样删除接收端那些被该选项指定排除的文件 --delete-after: 传输结束以后再删除 --ignore-errors: 即使出现IO错误也进行删除 --max-delete=NUM: 最多删除NUM个文件-C, --cvs-exclude: 使用和CVS一样的方法自动忽略文件，用来排除那些不希望传输的文件-P, --partial: 保留那些因故没有完全传输的文件，以是加快随后的再次传输--force: 强制删除目录，即使不为空--numeric-ids: 不将数字的用户和组id匹配为用户名和组名--timeout=time: ip超时时间，单位为秒-I, --ignore-times: 不跳过那些有同样的时间和长度的文件--size-only: 当决定是否要备份文件时，仅仅察看文件大小而不考虑文件时间--modify-window=NUM: 决定文件是否时间相同时使用的时间戳窗口，默认为0-T --temp-dir=DIR: 在DIR中创建临时文件--compare-dest=DIR: 同样比较DIR中的文件来决定是否需要备份。--progress: 显示备份过程-z, --compress: 对备份的文件在传输时进行压缩处理 --exclude=PATTERN: 指定排除不需要传输的文件模式 --include=PATTERN: 指定不排除而需要传输的文件模式 --exclude-from=FILE: 排除FILE中指定模式的文件 --include-from=FILE: 不排除FILE指定模式匹配的文件 --version: 打印版本信息 --address: 绑定到特定的地址 --config=FILE: 指定其他的配置文件，不使用默认的rsyncd.conf文件 --port=PORT: 指定其他的rsync服务端口 --blocking-io: 对远程shell使用阻塞IO -stats: 给出某些文件的传输状态 --progress: 在传输时现实传输过程 --password-file=FILE: 从FILE中得到密码-i, --itemize-changes: 输出所有更新的更改摘要 --out-format=FORMAT 使用指定的FORMAT输出 --log-file=FILE 将rsync做的操作记录到FILE中 --list-only 只列出文件，而不拷贝 --bwlimit=KBPS 限制I/O带宽，KBytes per second-h, --help: 显示帮助信息。 示例：1rsync -azi machine::user/path/dir/ /search/odin/ --exclude '*_log*' 定时任务在linux上，使用 crontab 来创建循环性工作调度。当然为了安全，可以通过/etc/cron.allow和/etc/cron.deny来限制用户使用 crontab。当用户是用crontab来新建工作调度时，该项工作就会被记录到 /var/spool/cron 中，而且是以用户的账户来作为判别的。一般来说，不建议直接编辑/var/spool/cron中的文件，因为可能会由于输入语法错误，而导致 cron 不能正确执行。1234567891011crontab [-u username] [-l|-e|-r]-u: 只有root才能使用这个参数，可以用其他用户的名义新建/删除 crontab 任务 -l: 查看 crontab 的内容-e: 编辑 crontab 的内容-r: 删除所有的 crontab 的工作内容## 示例## 使用 crontab -e 进入到任务编辑页面crontab -e 0 1 * * * shell exec.sh#分 时 日 月 周 执行内容 只要通过 :wq 或者 :x，保存退出后，任务就自动定时执行。配置时间方式如下表所示 分 时 日期 月 周 命令 0-59 0-23 1-31 1-12 0-7 command “周”的0和7都是代表星期日的意思。还有一些辅助字符，如下： 特殊字符 代表意义 * (星号) 代表任何时刻都接受，上例中，表示无论日月周是什么，知道是1点钟，就执行命令 , (逗号) 代表分隔时段的意思。如要执行任务的时间是 3:00 和 6:00, 那么配置是： 0 3,6 * * * command - (减号) 代表一段时间范围内。8点到12点的每小时的20分钟执行任务，那么配置是： 20 8-12 * * * command /n n是数字，即每隔 n 单位的时间间隔执行命令。例如每五分钟执行一次： */5 * * * * command contab -e 是针对用户的 cron 来设计的，如果是系统例行性任务，可以直接编辑 /etc/crontab 这个文件。 /etc/crontab 是一个纯文本文件，可以用root账号编辑。cron 服务最低的检测限制是“分钟”，所以cron 会每分钟去读取一次 /etc/crontab 与 /var/spool/cron 中的数据，所以，只要编辑并保存这些文件，就会生效。如果不生效，可以使用 /etc/init.d/crondrestart 来重启 cron 服务。 bash环境中的特殊符号bash环境中，有些符号是有特殊意义的： 符号 意义 # 注释符号，最常用于script中 \\ 转义符号，之后跟的特殊符号作为一般符号处理 \\ 管道，分割两个管道命令 ; 连续命令执行分隔符 ~ 用户的主文件夹 $ 使用变量前导符号 &amp; 将命令在后台运行 / 目录符号 \\ &gt;, &gt;&gt; 数据流重定向，输出导向 &lt;, &lt;&lt; 数据流重定向， 输入导向 ‘’ 单引号，不具有变量置换的功能 “” 双引号，具有变量置换的功能，其中的变量会用其值替换 `` 两个 ` 中间为可以先执行的命令，也可以使用 $() () 中间为子shell的起始与结束 { } 中间为命令块的组合 进程查看我们使用 ps top 和 pstree 来查看进程的运行情况。 ps : 将某个时间点的进程运行情况选取下来一般 ps 有两种用法： ps -l 仅查看自己的bash相关的进程； ps aux 查看所有系统运行的程序。语法如下：1234567891011121314151617ps [options] -A: 所有的进程均显示出来 -a: 与 terminal 无关的所有进程 -u: 有效用户相关的进程 x: 通常与 a 一起使用，可得到较为完整的信息 l: 较详细地将PID的信息列出 j: 工作的格式 -f: 做一个更完整的输出# 示例ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 1 0.0 0.0 10352 680 ? Ss 2015 18:00 init [3] root 2 0.0 0.0 0 0 ? S&lt; 2015 1:40 [migration/0]root 3 0.0 0.0 0 0 ? SN 2015 0:50 [ksoftirqd/0]root 4 0.0 0.0 0 0 ? S&lt; 2015 0:00 [watchdog/0] ps aux 结果中，各字段的意义为： 字段名 字段含义 USER 该进程属于哪个用户账号 PID 该进程的标志符 %CPU 该进程使用的CPU资源的百分比 %MEM 该进程所占用的物理内存百分比 VSZ 该进程使用的虚拟内存量 RSS 该进程占用的固定内容量 TTY 该进程是在哪个终端机上运行，若与终端无关则显示 ?；若为 pts/0 表示由网络连接的主机进程 STAT 该进程目前的状态。R(正在运行), S(可唤醒的睡眠状态), D(不可唤醒的睡眠状态，通常为等待I/O), T(停止状态), Z(僵尸状态，进程已经终止但无法删除) START 该进程启动的时间 TIME 该进程使用CPU运行时间 COMMAND 该进程是哪个命令产生的 top 动态查看进程的变化top 命令可以持续检测程序的运行状态，使用方式如下： 12345678910111213141516top [-d 数字] | top [-bnp]参数如下：-d: 后面可以接秒数，就是整个进程界面更新的秒数，默认是 5s-b: 以批次的方式执行top，通常会结合数据流重定向来批处理结果-n: 与 -b 搭配，表示需要进行几次 top 结果的数据-p: 指定某些PID来进行查看-H: 显示线程在top命令中，可以使用如下按键命令： ?: 显示在top当中可以输入的按键指令 P: 以 CPU 的使用资源排序显示 M: 以内存的使用资源排序显示 N: 以PID来排序 T: 该进程使用的CPU时间累积排序 k: 给予某个PID一个信号 r: 给某个PID重新定制一个nice属性 q: 离开top pstree 查看进程树123456789101112131415pstree [-A|U] [-up]参数：-A: 各进程树之间的连接-U: 各进程树之间的连接以utf8码的字符来连接-p: 列出每个进程的PID-u: 列出每个进程的账号示例：init(1)-+-agetty(2112) |-crond(2071)---crond(13076)---sh(13084)---sleep(13112) |-events/0(8) |-events/1(9) |-glusterfs(19972)-+-&#123;glusterfs&#125;(19973) | \\`-&#123;glusterfs&#125;(19982) |-httpd(1988)-+-httpd(884,apache) kill 进程管理我们可以使用 kill 或者 killall 来向进程发送信号。使用如下：123456kill -signal PIDkillall [-iIe] -signal 命令名称参数: -i: interactive ，交互式的，若需要删除，会出现提示-e: exact，表示后边接的 命令名称 要一致，但完整的命令不能超过15个字符-I: 命令名称（可能含有参数），忽略大小写 其中常用的 signal 有： 代号 名称 含义 1 SIGHUP 启动被终止的进程，可以让该PID重新读取自己的配置，类似重启 2 SIGINT 相当于使用键盘的 ctrl+c 来中断一个进程 9 SIGKILL 代表强行中断一个进程的运行，如果进程执行到一半，尚未完成的部分不会被处理 15 SIGTERM 正常结束进程的执行。后续操作完成后，才终止 17 SIGSTOP 相当于使用键盘的 ctrl+z 来暂停一个进程的执行 12345# 关闭特定的进程kill -SIGHUP $(ps aux | grep 'syslog' | grep -v 'grep' | awk '&#123;print $2&#125;')# 关闭一个命令开启的所有进程killall -i -9 bash 其他快捷方式 使用快捷键 ctrl+r 可以快速使用历史命令","categories":[{"name":"linux","slug":"linux","permalink":"http://wzhongke.github.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://wzhongke.github.io/tags/linux/"}]},{"title":"javascript 常用技巧","slug":"front/javascript 常用技巧","date":"2017-06-17T19:42:25.000Z","updated":"2017-10-25T03:18:56.130Z","comments":true,"path":"2017/06/18/front/javascript 常用技巧/","link":"","permalink":"http://wzhongke.github.io/2017/06/18/front/javascript 常用技巧/","excerpt":"javascript在使用中有各种各样的技巧：提高执行效率，降低执行频率等。 Web Storage 的使用Web Storage的目的是克服由cookie带来的一些限制，当数据需要被严格控制在客户端，无须将数据返回到服务器时。","text":"javascript在使用中有各种各样的技巧：提高执行效率，降低执行频率等。 Web Storage 的使用Web Storage的目的是克服由cookie带来的一些限制，当数据需要被严格控制在客户端，无须将数据返回到服务器时。 提供一种在cookie之外的存储会话数据的途径 提供一种存储大量可以跨会话存在的数据机制有两种storage存储对象： sessionStorage: 存储特定于某个会话的数据，数据只保持到浏览器关闭 localStorage: 页面必须来自同一个域名（子域名无效），使用同一种协议，在同一个端口上storage提供的方法有如下几种： clear(): 清除所有值 getItem(name): 根据名字获取对应的值 key(index): 获取index位置处的值 removeItem(name): 删除由name 指定的键值对 setItem(name, value): 为指定的name设置一个对应的值获取localStorage的方法：1234567891011var WebStorage = &#123; getLocalStorage: function() &#123; if (typeof localStorage === 'object') &#123; return localStorage; &#125; else if (typeof globalStorage === 'object') &#123; return globalStorage; &#125; else &#123; throw new Error(\"Local Storage not available\"); &#125; &#125;&#125; 使用外部变量时，超时调用在使用setTimeout进行超时调用时，其作用域是window，因此要注意其this的使用。12345for (var i=0; i&lt;10; i++) &#123; setTimeout( function () &#123; console.log(i); &#125;, 200);&#125; 上例中，会取i的最终值10，正确的方法如下：1234567for (var i=0; i&lt;10; i++) &#123; setTimeout(function(a) &#123; return function() &#123; console.log(a); &#125; &#125;(i), 200);&#125; 判断手机联网状态如果手机不支持如下属性，可以参考 github1234567// 是否在线navigator.onLine// 连接类型navigator.connection.type// type值可能是: unknown, ethernet, wifi, 2g, 3g, 4g, none.// 下行最大比特率 downlinkMaxnavigator.connection.downlinkMax","categories":[{"name":"javascript","slug":"javascript","permalink":"http://wzhongke.github.io/categories/javascript/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://wzhongke.github.io/tags/javascript/"}]},{"title":"resin 配置","slug":"resin 配置","date":"2017-06-17T19:42:25.000Z","updated":"2017-10-09T08:55:59.868Z","comments":true,"path":"2017/06/18/resin 配置/","link":"","permalink":"http://wzhongke.github.io/2017/06/18/resin 配置/","excerpt":"resin 配置resin 配置日志信息12345678910111213&lt;log-handler name=\"\" level=\"info\" path=\"stdout:\" timestamp=\"[%y-%m-%d %H:%M:%S.%s] &#123;%&#123;thread&#125;&#125; \"/&gt;&lt;stdout-log path-format=\"log/stdout.log.%Y%m%d\" rollover-period=\"1D\"/&gt;&lt;stderr-log path-format=\"log/stderr.log.%Y%m%d\" rollover-period=\"1D\"/&gt;&lt;!-- - level='info' for production - 'fine' or 'finer' for development and troubleshooting--&gt;&lt;logger name=\"com.caucho\" level=\"info\"/&gt;&lt;logger name=\"com.caucho.java\" level=\"config\"/&gt;&lt;logger name=\"com.caucho.loader\" level=\"config\"/&gt; stdout-log中的path-format设置了正常输出日志的路径和日志文件命名格式；rollover-period设置了日志文件生成时间间隔。 1D是一天，1H是一个小时。","text":"resin 配置resin 配置日志信息12345678910111213&lt;log-handler name=\"\" level=\"info\" path=\"stdout:\" timestamp=\"[%y-%m-%d %H:%M:%S.%s] &#123;%&#123;thread&#125;&#125; \"/&gt;&lt;stdout-log path-format=\"log/stdout.log.%Y%m%d\" rollover-period=\"1D\"/&gt;&lt;stderr-log path-format=\"log/stderr.log.%Y%m%d\" rollover-period=\"1D\"/&gt;&lt;!-- - level='info' for production - 'fine' or 'finer' for development and troubleshooting--&gt;&lt;logger name=\"com.caucho\" level=\"info\"/&gt;&lt;logger name=\"com.caucho.java\" level=\"config\"/&gt;&lt;logger name=\"com.caucho.loader\" level=\"config\"/&gt; stdout-log中的path-format设置了正常输出日志的路径和日志文件命名格式；rollover-period设置了日志文件生成时间间隔。 1D是一天，1H是一个小时。12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;cluster id=&quot;app&quot;&gt; &lt;!-- sets the content root for the cluster, relative to resin.root --&gt; &lt;root-directory&gt;.&lt;/root-directory&gt; &lt;!-- defaults for each server, i.e. JVM --&gt; &lt;server-default&gt; &lt;!-- The http port --&gt; &lt;http id=&quot;&quot; address=&quot;*&quot; port=&quot;9090&quot;/&gt; &lt;/server-default&gt; &lt;!-- define the servers in the cluster --&gt; &lt;server id=&quot;web&quot; address=&quot;127.0.0.1&quot; port=&quot;6801&quot;/&gt; &lt;!-- the default host, matching any host name --&gt; &lt;host id=&quot;&quot; root-directory=&quot;.&quot;&gt; &lt;!-- - configures an explicit root web-app matching the - webapp&apos;s ROOT --&gt; &lt;web-app id=&quot;/&quot; root-directory=&quot;/search/odin/resin/umiswxb&quot;/&gt; &lt;!-- - Administration application /resin-admin --&gt; &lt;!-- &lt;web-app id=&quot;/resin-admin&quot; root-directory=&quot;$&#123;resin.root&#125;/doc/admin&quot;&gt; &lt;prologue&gt; &lt;resin:set var=&quot;resin_admin_external&quot; value=&quot;false&quot;/&gt; &lt;resin:set var=&quot;resin_admin_insecure&quot; value=&quot;true&quot;/&gt; &lt;/prologue&gt; &lt;/web-app&gt; --&gt; &lt;!-- - Resin documentation - remove for a live site --&gt; &lt;!--&lt;web-app id=&quot;/resin-doc&quot; root-directory=&quot;$&#123;resin.root&#125;/doc/resin-doc&quot;/&gt;--&gt; &lt;!-- - &lt;resin:LoadBalance regexp=&quot;^/load&quot; cluster=&quot;backend-tier&quot;/&gt; - &lt;resin:HttpProxy regexp=&quot;^/http&quot; address=&quot;localhost:9000&quot;/&gt; - &lt;resin:FastCgiProxy regexp=&quot;^/fcgi&quot; address=&quot;localhost:9001&quot;/&gt; --&gt; &lt;/host&gt; &lt;/cluster&gt; cluster可以配置不同的服务，id属性是其服务唯一的标记server-default中的http的port配置了该服务监听的端口，web-app的id属性定义了服务的访问路径，root-directory定义了服务代码放置的位置。 配置远程调试端口在 resin3.1下的版本中，修改 bin/httpd.sh 文件中的配置1args=&quot;-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8787&quot; 在 resin3.1 以上的版本中，修改 conf/resin.properties 文件1jvm_args : -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=9090","categories":[{"name":"linux","slug":"linux","permalink":"http://wzhongke.github.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://wzhongke.github.io/tags/linux/"}]},{"title":"python3 安装protobuf模块","slug":"python/python3-安装protobuf模块","date":"2017-06-17T19:02:10.000Z","updated":"2017-08-04T05:51:58.080Z","comments":true,"path":"2017/06/18/python/python3-安装protobuf模块/","link":"","permalink":"http://wzhongke.github.io/2017/06/18/python/python3-安装protobuf模块/","excerpt":"","text":"python3 网上没有现成的protobuf模块可以直接使用，我在安装时费了一番周折，故此记录下来。 记录下自己安装python3-protobuf的过程 从 protobuf官网 下载源码 解压后打开 vsprojects/protobuf.sln (一般用visual studio打开） 右键生成，在Debug目录下找到protoc.exe （该文件是用来生成proto buffer的代码模块） 使用命令行定位到Python目录下，然后输入python setup.py install protobuf 的python模块，至此python3下的protobuf就可以使用了","categories":[{"name":"python","slug":"python","permalink":"http://wzhongke.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://wzhongke.github.io/tags/python/"},{"name":"program","slug":"program","permalink":"http://wzhongke.github.io/tags/program/"}]},{"title":"linux 忘记root密码","slug":"linux/linux-忘记root密码","date":"2015-08-03T09:19:14.000Z","updated":"2017-08-04T05:51:58.080Z","comments":true,"path":"2015/08/03/linux/linux-忘记root密码/","link":"","permalink":"http://wzhongke.github.io/2015/08/03/linux/linux-忘记root密码/","excerpt":"如果忘记了linux的root密码, 有两种比较通用的方式来修改 使用grub 重启系统 进入grub菜单： 在启动时，点击e进入详细设置；将光标移动到kernel上点击e进入编辑页面，输入如下指令，回车之后，按b就可以进入单用户维护模式 1grub edit&gt; kernel /vmlinuz-2.6.18-92.el5 ro root=LABEL=/ rhgb quiet &lt;strong&gt;single&lt;/strong&gt; 进入单用户维护模式后，系统会以root的权限直接给你一个shell，此时执行 passwd 就可以修改root密码了。","text":"如果忘记了linux的root密码, 有两种比较通用的方式来修改 使用grub 重启系统 进入grub菜单： 在启动时，点击e进入详细设置；将光标移动到kernel上点击e进入编辑页面，输入如下指令，回车之后，按b就可以进入单用户维护模式 1grub edit&gt; kernel /vmlinuz-2.6.18-92.el5 ro root=LABEL=/ rhgb quiet &lt;strong&gt;single&lt;/strong&gt; 进入单用户维护模式后，系统会以root的权限直接给你一个shell，此时执行 passwd 就可以修改root密码了。 使用具有sudo权限的用户修改root密码执行如下命令，输入用户密码后就可以修改密码了 1$sudo passwd root","categories":[{"name":"linux","slug":"linux","permalink":"http://wzhongke.github.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://wzhongke.github.io/tags/linux/"}]},{"title":"linux下执行脚本出现报：syntax error: unexpected end of file","slug":"linux/unexpected end of file","date":"2015-07-23T17:16:32.000Z","updated":"2017-08-04T05:51:58.095Z","comments":true,"path":"2015/07/24/linux/unexpected end of file/","link":"","permalink":"http://wzhongke.github.io/2015/07/24/linux/unexpected end of file/","excerpt":"","text":"这是因为从Windows上拷贝过去的文件，会由于Windows与linux的回车和换行表示方法不一致导致的，可以通过执行dos2unix shellname.sh来解决该问题 perl脚本在shell中调用时，也可能会出现这样的问题。通过dos2unix perl.pl命令可以修正","categories":[{"name":"linux","slug":"linux","permalink":"http://wzhongke.github.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://wzhongke.github.io/tags/linux/"}]},{"title":"java中override与overload的区别","slug":"java/java中override与overload的区别","date":"2015-07-23T17:16:32.000Z","updated":"2017-08-04T05:51:58.080Z","comments":true,"path":"2015/07/24/java/java中override与overload的区别/","link":"","permalink":"http://wzhongke.github.io/2015/07/24/java/java中override与overload的区别/","excerpt":"","text":"override（重写，覆盖） 方法名、参数、返回值相同。 子类方法不能缩小父类方法的访问权限。 子类方法不能抛出比父类方法更多的异常(但子类方法可以不抛出异常)。 存在于父类和子类之间。 方法被定义为final不能被重写。 overload（重载，过载） 参数类型、个数、顺序至少有一个不相同。 不能重载只有返回值不同的方法名。 存在于父类和子类、同类中。","categories":[{"name":"java","slug":"java","permalink":"http://wzhongke.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://wzhongke.github.io/tags/java/"}]},{"title":"java中的先赋值再定义","slug":"java/java中的先赋值再定义","date":"2015-04-02T11:32:36.000Z","updated":"2017-08-22T02:34:20.372Z","comments":true,"path":"2015/04/02/java/java中的先赋值再定义/","link":"","permalink":"http://wzhongke.github.io/2015/04/02/java/java中的先赋值再定义/","excerpt":"","text":"如下代码123456789101112131415public class MyTest&#123; &#123; value = 3; System.out.println(\"函数块\"); &#125; MyTest()&#123; System.out.println(\"构造函数\"); System.out.println(value); &#125; public int getValue() &#123; return value; &#125; int value = 0;&#125; 如果value定义在下边，因为函数块是在构造函数之前运行的，也就是value还没有定义，就已经赋值了。实际应用中应该尽量避免该情况出现，最好把属性定义放在函数开始的位置。","categories":[{"name":"java","slug":"java","permalink":"http://wzhongke.github.io/categories/java/"},{"name":"error","slug":"java/error","permalink":"http://wzhongke.github.io/categories/java/error/"}],"tags":[{"name":"java","slug":"java","permalink":"http://wzhongke.github.io/tags/java/"},{"name":"error","slug":"error","permalink":"http://wzhongke.github.io/tags/error/"}]},{"title":"Python 讨厌的MemoryError","slug":"python/Python-讨厌的MemoryError","date":"2015-04-01T15:41:43.000Z","updated":"2017-08-04T05:51:58.080Z","comments":true,"path":"2015/04/01/python/Python-讨厌的MemoryError/","link":"","permalink":"http://wzhongke.github.io/2015/04/01/python/Python-讨厌的MemoryError/","excerpt":"在用Python处理大数据时，本来16G的内存，内存还没使用四分之一就开始报MemoryError的错误，后来才知道32bit的Python使用内存超过2G之后，就报这个错误，还没有其他的提示消息。果断换64bit的Python。","text":"在用Python处理大数据时，本来16G的内存，内存还没使用四分之一就开始报MemoryError的错误，后来才知道32bit的Python使用内存超过2G之后，就报这个错误，还没有其他的提示消息。果断换64bit的Python。一开始安装32bit的Python，是因为numpy和scipy官方版本只支持32bit的，后来又找到了非官方的版本http://www.lfd.uci.edu/~gohlke/pythonlibs/#numpywheel文件安装时出现：Fatal error in launcher: Unable to create process using ‘“”C:\\Program Files (x86)\\Python33\\python.exe“” “C:\\Program Files (x86)\\Python33\\pip.exe”在stackoverflow上找到解决方法：1$python -m pip install XXX","categories":[{"name":"python","slug":"python","permalink":"http://wzhongke.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://wzhongke.github.io/tags/python/"}]},{"title":"pycurl https error: unable to get local issuer certificate ","slug":"python/pycurl-https-error-unable-to-get-local-issuer-certificate","date":"2014-12-28T19:45:33.000Z","updated":"2017-08-04T05:51:58.080Z","comments":true,"path":"2014/12/29/python/pycurl-https-error-unable-to-get-local-issuer-certificate/","link":"","permalink":"http://wzhongke.github.io/2014/12/29/python/pycurl-https-error-unable-to-get-local-issuer-certificate/","excerpt":"","text":"在 pycurl 访问 https 链接时可能会报： pycurl.error: (60, ‘SSL certificate problem: unable to get local issuer certificate’) 错误一个比较好的解决方法是：1234567import pycurlimport certificurl = pycurl.Curl()curl.setopt(pycurl.CAINFO, certifi.where())curl.setopt(pycurl.URL, 'https://www.quora.com')curl.perform()","categories":[{"name":"python","slug":"python","permalink":"http://wzhongke.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://wzhongke.github.io/tags/python/"}]},{"title":"pycurl 快速开始指南","slug":"python/pycurl-快速开始指南","date":"2014-12-20T11:37:28.000Z","updated":"2017-08-04T05:51:58.080Z","comments":true,"path":"2014/12/20/python/pycurl-快速开始指南/","link":"","permalink":"http://wzhongke.github.io/2014/12/20/python/pycurl-快速开始指南/","excerpt":"获取网络资源安装好PycURL之后，我们就可以执行一些网络操作了。最简单的是通过一个网站的URL获取它的相关资源。使用PycURL执行一个网络请求，需要以下步骤： 创建一个pucurl.Curl的实例。 使用 setopt 来设置一些请求选项。 调用 perform 来执行请求。","text":"获取网络资源安装好PycURL之后，我们就可以执行一些网络操作了。最简单的是通过一个网站的URL获取它的相关资源。使用PycURL执行一个网络请求，需要以下步骤： 创建一个pucurl.Curl的实例。 使用 setopt 来设置一些请求选项。 调用 perform 来执行请求。 在python2 中，我们采用以下的方法获取网络资源：1234567891011121314import pycurlfrom StringIO import StringIObuffer = StringIO()c = pycurl.Curl()c.setopt(c.URL, 'http://pycurl.sourceforge.net/')c.setopt(c.WRITEDATA, buffer)c.perform()c.close()body = buffer.getvalue()# Body is a string in some encoding.# In Python 2, we can print it without knowing what the encoding is.print(body) PycURL没有对网络的响应提供存贮机制。因此，我们必须提供一个缓存（以StringIO的形式）并且让PycURL将内容写入这个缓存。现有的大多数PycURL代码使用 WRITEFUNCTION 而不是WRITEDATA：1c.setopt(c.WRITEFUNCTION, buffer.write) 虽然 WRITEFUNCTION 还能继续使用，但是没有必要了。因为PycURL 7.19.3版本中的WRITEDATA 可以使用任何具有write方法的Python类。123456789101112131415import pycurlfrom io import BytesIObuffer = BytesIO()c = pycurl.Curl()c.setopt(c.URL, 'http://pycurl.sourceforge.net/')c.setopt(c.WRITEDATA, buffer)c.perform()c.close()body = buffer.getvalue()# Body is a byte string.# We have to know the encoding in order to print it to a text file# such as standard output.print(body.decode('iso-8859-1')) 在Python 3 中，PycURL的响应是字节串。字节串对于我们下载二进制文件是比较方便的，但是我们处理文本内容时必须对字节串解码。在上面的例子中，我们假设内容是以iso-8859-1编码的。检查响应头在现实中，我们希望使用服务器指定的编码格式对响应解码而不是假设一个编码格式解码。我们需要检查响应头来提取服务器指定的编码格式：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364import pycurlimport retry: from io import BytesIOexcept ImportError: from StringIO import StringIO as BytesIOheaders = &#123;&#125;def header_function(header_line): # HTTP standard specifies that headers are encoded in iso-8859-1. # On Python 2, decoding step can be skipped. # On Python 3, decoding step is required. header_line = header_line.decode('iso-8859-1') # Header lines include the first status line (HTTP/1.x ...). # We are going to ignore all lines that don't have a colon in them. # This will botch headers that are split on multiple lines... if ':' not in header_line: return # Break the header line into header name and value. name, value = header_line.split(':', 1) # Remove whitespace that may be present. # Header lines include the trailing newline, and there may be whitespace # around the colon. name = name.strip() value = value.strip() # Header names are case insensitive. # Lowercase name here. name = name.lower() # Now we can actually record the header name and value. headers[name] = valuebuffer = BytesIO()c = pycurl.Curl()c.setopt(c.URL, 'http://pycurl.sourceforge.net')c.setopt(c.WRITEFUNCTION, buffer.write)# Set our header function.c.setopt(c.HEADERFUNCTION, header_function)c.perform()c.close()# Figure out what encoding was sent with the response, if any.# Check against lowercased header name.encoding = Noneif 'content-type' in headers: content_type = headers['content-type'].lower() match = re.search('charset=(\\S+)', content_type) if match: encoding = match.group(1) print('Decoding using %s' % encoding)if encoding is None: # Default encoding for HTML is iso-8859-1. # Other content types may have different default encoding, # or in case of binary data, may have no encoding at all. encoding = 'iso-8859-1' print('Assuming encoding is %s' % encoding)body = buffer.getvalue()# Decode using the encoding we figured out.print(body.decode(encoding)) 不得不说，完成一个非常简单的提取编码格式的工作需要大量的代码。不幸的是，因为libcurl 限制了分配给响应数据的内存，所以只能依赖我的程序来执行这个枯燥乏味的工作。写入文件: 如果我们要将响应数据存入文件，只要稍作改变就可以了：12345678910import pycurl# As long as the file is opened in binary mode, both Python 2 and Python 3# can write response body to it without decoding.with open('out.html', 'wb') as f: c = pycurl.Curl() c.setopt(c.URL, 'http://pycurl.sourceforge.net/') c.setopt(c.WRITEDATA, f) c.perform() c.close() 最重要的是以二进制方式打开文件，响应内容不需要编码或者解码就可以直接写入文件。 ##跟随重定向默认情况下，libcurl和PycURL都不会跟随重定向的内容。我们可以通过 setopt 来设置跟随重定向：123456789import pycurlc = pycurl.Curl()# Redirects to https://www.python.org/.c.setopt(c.URL, 'http://www.python.org/')# Follow redirect.c.setopt(c.FOLLOWLOCATION, True)c.perform()c.close() 正如我们没有设置一个写的回调函数一样，默认的libcurl和PycURL将响应体输出到标准输出上。（使用Python 3.4.1 报错：pycurl.error: (23, ‘Failed writing body (0 != 7219)’)） ##设置选项跟随重定向只是libcurl提供的一个选项。还有好多其他的选项，点击这里查看。除了少数例外，PycURL选项的名字都是从libcurl中通过去掉CURLOPT_前缀得来的。因此CURLOPT_URL就成了简单的URL。 ##检测响应我们已经介绍了检测响应头。其他的响应信息可以通过 getinfo 获得，如下所示：12345678910111213141516171819import pycurltry: from io import BytesIOexcept ImportError: from StringIO import StringIO as BytesIObuffer = BytesIO()c = pycurl.Curl()c.setopt(c.URL, 'http://pycurl.sourceforge.net/')c.setopt(c.WRITEDATA, buffer)c.perform()# HTTP response code, e.g. 200.print('Status: %d' % c.getinfo(c.RESPONSE_CODE))# Elapsed time for the transfer.print('Status: %f' % c.getinfo(c.TOTAL_TIME))# getinfo must be called before close.c.close() 在此，我们将响应内容写到缓存，避免在标准输出中输出不感兴趣的内容。响应信息都在libcurl的相关文档上有展示。除了少数例外，PycURL的常量都是通过去掉libcurl常量的前缀 CURLINFO_来命名的。因此CURLINFO_RESPONSE_CODE变为RESPONSE_CODE ##提交数据使用POSTFIELDS选项来提交数据。提交的数据必须先经过URL编码格式编码：123456789101112131415161718192021import pycurltry: # python 3 from urllib.parse import urlencodeexcept ImportError: # python 2 from urllib import urlencodec = pycurl.Curl()c.setopt(c.URL, 'http://pycurl.sourceforge.net/tests/testpostvars.php')post_data = &#123;'field': 'value'&#125;# Form data must be provided already urlencoded.postfields = urlencode(post_data)# Sets request method to POST,# Content-Type header to application/x-www-form-urlencoded# and data to send in request body.c.setopt(c.POSTFIELDS, postfields)c.perform()c.close() POSTFIELDS自动将HTTP请求方式设置为POST方式。其他的请求方式可以通过CUSTOMREQUEST选项设置：1c.setopt(c.CUSTOMREQUEST, 'PATCH')","categories":[{"name":"python","slug":"python","permalink":"http://wzhongke.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://wzhongke.github.io/tags/python/"}]}]}